{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13129961,"sourceType":"datasetVersion","datasetId":8317787},{"sourceId":13130019,"sourceType":"datasetVersion","datasetId":8317829},{"sourceId":13130089,"sourceType":"datasetVersion","datasetId":8317879},{"sourceId":13131066,"sourceType":"datasetVersion","datasetId":8318470},{"sourceId":13141883,"sourceType":"datasetVersion","datasetId":8326018},{"sourceId":13150117,"sourceType":"datasetVersion","datasetId":8331708}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\nimport numpy as np\nfrom typing import Any, List, Dict\n\n# --- Copy collision meshes ---\nsource_path = \"/kaggle/input/collmesh/collision_meshes\"\ndestination_path = \"./collision_meshes\"\n\nif not os.path.exists(destination_path):\n    print(f\"Copying collision meshes from '{source_path}' to '{destination_path}'...\")\n    shutil.copytree(source_path, destination_path)\n    print(\"Collision meshes copied successfully.\")\nelse:\n    print(\"Collision meshes already exist in the correct location.\")\n\n# --- modern_coyote.py content ---\nmodern_coyote_code = r\"\"\"\nimport numpy as np\nfrom typing import Any, List, Tuple\nfrom rlgym_sim.utils import common_values\nfrom rlgym_sim.utils.gamestates import PlayerData, GameState\nfrom rlgym_sim.utils.obs_builders import ObsBuilder\nfrom rlgym_sim.utils.action_parsers import ActionParser\nfrom gym.spaces import Discrete, Box\n\n# -------------------- ACTION PARSER --------------------\nclass ModernCoyoteAction(ActionParser):\n    def __init__(self, version=None):\n        super().__init__()\n        self._lookup_table = self.make_lookup_table(version)\n\n    def get_action_space(self) -> Discrete:\n        return Discrete(len(self._lookup_table))\n\n    def parse_actions(self, actions: Any, state: GameState) -> np.ndarray:\n        parsed_actions = []\n        for action in actions:\n            raw_action = action[0] if isinstance(action, np.ndarray) and action.ndim > 0 else action\n            action_index = int(raw_action)\n            parsed_actions.append(self._lookup_table[action_index])\n        return np.array(parsed_actions)\n\n    @staticmethod\n    def make_lookup_table(version=None):\n        actions = []\n        if version is None or version == \"Normal\":\n            for throttle in (-1, 0, 0.5, 1):\n                for steer in (-1, -0.5, 0, 0.5, 1):\n                    for boost in (0, 1):\n                        for handbrake in (0, 1):\n                            if boost == 1 and throttle != 1: continue\n                            actions.append([throttle or boost, steer, 0, steer, 0, 0, boost, handbrake])\n            for pitch in (-1, -0.75, -0.5, 0, 0.5, 0.75, 1):\n                for yaw in (-1, -0.75, -0.5, 0, 0.5, 0.75, 1):\n                    for roll in (-1, 0, 1):\n                        for jump in (0, 1):\n                            for boost in (0, 1):\n                                if jump == 1 and yaw != 0: continue\n                                if pitch == roll == jump == 0: continue\n                                handbrake = jump == 1 and (pitch != 0 or yaw != 0 or roll != 0)\n                                actions.append([boost, yaw, pitch, yaw, roll, jump, boost, handbrake])\n            actions.append([0, 1, 0, 0, -1, 1, 0, 0])\n            actions = np.array(actions, dtype=np.float32)\n        else:\n            raise NotImplementedError(f\"Version '{version}' not implemented.\")\n        return actions\n\nclass ModernCoyoteObsBuilder(ObsBuilder):\n    def __init__(self, team_size=1, tick_skip=8):\n        super().__init__()\n        self.team_size = team_size\n        self.tick_skip = tick_skip\n        self.POS_STD, self.VEL_STD, self.ANG_STD = 2300, 2300, 5.5\n        self.boost_pad_timers = None\n        self.demo_timers = None\n        self.prev_boost_pads = None\n        self.is_big_pad = np.array([loc[2] > 72 for loc in common_values.BOOST_LOCATIONS])\n        self.car_id_to_idx = {}\n        self.dummy_player_obs = [0] * 36\n\n    def get_obs_space(self) -> Box:\n        return Box(low=-np.inf, high=np.inf, shape=(116,), dtype=np.float32)\n\n    def reset(self, initial_state: GameState):\n        self.prev_boost_pads = np.copy(initial_state.boost_pads)\n        self.boost_pad_timers = np.zeros(len(common_values.BOOST_LOCATIONS))\n        self.demo_timers = np.zeros(len(initial_state.players))\n        self.car_id_to_idx = {p.car_id: i for i, p in enumerate(initial_state.players)}\n\n    def pre_step(self, state: GameState):\n        time_delta = self.tick_skip / 120.0\n        newly_collected = (self.prev_boost_pads == 1) & (state.boost_pads == 0)\n        self.boost_pad_timers[newly_collected & self.is_big_pad] = 10.0\n        self.boost_pad_timers[newly_collected & ~self.is_big_pad] = 4.0\n        self.boost_pad_timers = np.maximum(0, self.boost_pad_timers - time_delta)\n        self.prev_boost_pads = np.copy(state.boost_pads)\n        self.car_id_to_idx = {p.car_id: i for i, p in enumerate(state.players)}\n        for i, player in enumerate(state.players):\n            self.demo_timers[i] = 3.0 if player.is_demoed else max(0.0, self.demo_timers[i] - time_delta)\n\n    def build_obs(self, player: PlayerData, state: GameState, previous_action: np.ndarray) -> np.ndarray:\n        if player.team_num == common_values.ORANGE_TEAM:\n            own_car_physics, ball, boost_timers = player.inverted_car_data, state.inverted_ball, self.boost_pad_timers[::-1]\n        else:\n            own_car_physics, ball, boost_timers = player.car_data, state.ball, self.boost_pad_timers\n        player_idx = self.car_id_to_idx.get(player.car_id)\n        pos_diff, vel_diff = ball.position - own_car_physics.position, ball.linear_velocity - own_car_physics.linear_velocity\n        player_obs = [*own_car_physics.position/self.POS_STD, *own_car_physics.linear_velocity/self.VEL_STD, *own_car_physics.angular_velocity/self.ANG_STD, *pos_diff/self.POS_STD, *vel_diff/self.VEL_STD, *own_car_physics.forward(), *own_car_physics.up(), np.linalg.norm(own_car_physics.linear_velocity)/self.VEL_STD, player.boost_amount, float(player.on_ground), float(player.has_flip), float(player.is_demoed), float(player.on_ground or player.has_jump), self.demo_timers[player_idx]/3.0 if player_idx is not None else 0.0, *previous_action]\n        ball_obs = [*ball.position/self.POS_STD, *ball.linear_velocity/self.VEL_STD, *ball.angular_velocity/self.ANG_STD, np.linalg.norm(ball.linear_velocity)/self.VEL_STD, float(ball.position[2] <= 100)]\n        allies, opponents = [], []\n        for other_player in state.players:\n            if other_player.car_id == player.car_id: continue\n            target_list, is_teammate = (allies, 1) if other_player.team_num == player.team_num else (opponents, 0)\n            other_car_physics = other_player.inverted_car_data if player.team_num == common_values.ORANGE_TEAM else other_player.car_data\n            other_idx, diff = self.car_id_to_idx.get(other_player.car_id), other_car_physics.position - own_car_physics.position\n            other_car_obs = [*other_car_physics.position/self.POS_STD, *other_car_physics.linear_velocity/self.VEL_STD, *other_car_physics.angular_velocity/self.ANG_STD, *diff/self.POS_STD, *(other_car_physics.linear_velocity-own_car_physics.linear_velocity)/self.VEL_STD, *(ball.position-other_car_physics.position)/self.POS_STD, *(ball.linear_velocity-other_car_physics.linear_velocity)/self.VEL_STD, *other_car_physics.forward(), *other_car_physics.up(), other_player.boost_amount, float(other_player.on_ground), float(other_player.has_flip), float(other_player.is_demoed), float(other_player.on_ground or other_player.has_jump), np.linalg.norm(diff)/self.POS_STD, is_teammate, self.demo_timers[other_idx]/3.0 if other_idx is not None else 0.0]\n            target_list.append(other_car_obs)\n        max_allies, max_opps = self.team_size - 1, self.team_size\n        while len(allies) < max_allies: allies.append(self.dummy_player_obs)\n        while len(opponents) < max_opps: opponents.append(self.dummy_player_obs)\n        if allies: allies.sort(key=lambda x: x[-3]);\n        if opponents: opponents.sort(key=lambda x: x[-3])\n        final_obs = player_obs + ball_obs\n        for lst in (allies[:max_allies] + opponents[:max_opps]): final_obs.extend(lst)\n        final_obs.extend(boost_timers / 10.0)\n        return np.asarray(final_obs, dtype=np.float32)\n\n\n\n\"\"\"\n\nwith open(\"modern_coyote.py\", \"w\") as f:\n    f.write(modern_coyote_code)\n\nprint(\"Updated 'modern_coyote.py' with proper flip support written successfully!\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-23T18:41:22.491230Z","iopub.execute_input":"2025-09-23T18:41:22.491664Z","iopub.status.idle":"2025-09-23T18:41:22.806241Z","shell.execute_reply.started":"2025-09-23T18:41:22.491624Z","shell.execute_reply":"2025-09-23T18:41:22.805149Z"}},"outputs":[{"name":"stdout","text":"Copying collision meshes from '/kaggle/input/collmesh/collision_meshes' to './collision_meshes'...\nCollision meshes copied successfully.\nUpdated 'modern_coyote.py' with proper flip support written successfully!\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"agent_env_code = r\"\"\"\nimport os\nimport numpy as np\nfrom rlgym_sim import make\nfrom rlgym_sim.utils.gamestates import GameState, PlayerData\nfrom rlgym_sim.utils.reward_functions import RewardFunction\nfrom rlgym_sim.utils.state_setters import StateSetter, DefaultState, StateWrapper\nfrom rlgym_sim.utils.terminal_conditions.common_conditions import GoalScoredCondition, TimeoutCondition\nfrom rlgym_sim.utils import common_values, math as rlgym_math\n\n# --- Import from the file we just created ---\nfrom modern_coyote import ModernCoyoteObsBuilder, ModernCoyoteAction\n\nimport random\n\n# ==================================================================\n# === REWARD FUNCTIONS ===\n# ==================================================================\n\nclass CombinedReward(RewardFunction):\n    def __init__(self, reward_functions, reward_weights=None):\n        super().__init__()\n        self.reward_functions = reward_functions\n        self.reward_weights = reward_weights or np.ones(len(reward_functions))\n        if len(self.reward_functions) != len(self.reward_weights):\n            raise ValueError(\"Reward functions and weights must have the same length.\")\n\n    def reset(self, initial_state: GameState):\n        for func in self.reward_functions:\n            func.reset(initial_state)\n\n    def pre_step(self, state: GameState):\n        for func in self.reward_functions:\n            func.pre_step(state)\n\n    def get_reward(self, player: PlayerData, state: GameState, previous_action: np.ndarray) -> float:\n        rewards = [func.get_reward(player, state, previous_action) for func in self.reward_functions]\n        return float(np.dot(self.reward_weights, rewards))\n\n# ----------------------------\n# AdvancedDribbleReward\n# ----------------------------\nclass AdvancedDribbleReward(RewardFunction):\n    def __init__(self):\n        super().__init__()\n        self.last_player_touch = {}\n        self.flick_in_progress = {}\n        self.last_state: GameState = None\n        self.weights = {\n            \"goal_reward\": 15.0, \"demo_reward\": 15.0, \"save_reward\": 3.0,\n            \"touch_reward\": 0.01, \"dribble_proximity_reward\": 0.01,\n            \"dribble_sustain_reward\": 0.1, \"flick_initiation_reward\": 4.0,\n            \"dist_to_ball_exp\": 0.15, \"closer_to_ball_reward\": 0.3,\n            \"turtling_penalty\": -2.0, \"wrong_way_penalty\": -0.1,\n            \"boost_waste_penalty\": -0.4\n        }\n\n    def reset(self, initial_state: GameState):\n        self.last_state = initial_state\n        for player in initial_state.players:\n            self.last_player_touch[player.car_id] = False\n            self.flick_in_progress[player.car_id] = False\n\n    def get_reward(self, player: PlayerData, state: GameState, previous_action: np.ndarray) -> float:\n        if self.last_state is None: return 0.0\n        reward = 0.0\n        opponent = next((p for p in state.players if p.team_num != player.team_num), None)\n        if opponent is None: return 0.0\n        \n        last_player = next((p for p in self.last_state.players if p.car_id == player.car_id), None)\n        if last_player is None: return 0.0\n\n        if player.match_goals > last_player.match_goals: reward += self.weights[\"goal_reward\"]\n        if player.match_demolishes > last_player.match_demolishes: reward += self.weights[\"demo_reward\"]\n        if player.match_saves > last_player.match_saves: reward += self.weights[\"save_reward\"]\n        if player.ball_touched and not self.last_player_touch.get(player.car_id, False):\n            reward += self.weights[\"touch_reward\"]\n        self.last_player_touch[player.car_id] = player.ball_touched\n\n        player_to_ball = state.ball.position - player.car_data.position\n        dist_to_ball = np.linalg.norm(player_to_ball)\n        is_on_hood = 100 < state.ball.position[2] < 350\n        is_close = dist_to_ball < 150\n        is_dribbling = is_on_hood and is_close\n        if is_dribbling:\n            reward += self.weights[\"dribble_proximity_reward\"] * (1 - (dist_to_ball / 150))\n            reward += self.weights[\"dribble_sustain_reward\"]\n            ball_vel = state.ball.linear_velocity\n            if ball_vel[2] > 400 and np.linalg.norm(ball_vel[:2]) > 300 and not self.flick_in_progress.get(player.car_id, False):\n                reward += self.weights[\"flick_initiation_reward\"]\n                self.flick_in_progress[player.car_id] = True\n        if not is_dribbling or state.ball.linear_velocity[2] < 0:\n            self.flick_in_progress[player.car_id] = False\n\n        last_dist_to_ball = np.linalg.norm(self.last_state.ball.position - last_player.car_data.position)\n        reward += self.weights[\"dist_to_ball_exp\"] * (last_dist_to_ball - dist_to_ball)\n\n        opp_dist_to_ball = np.linalg.norm(state.ball.position - opponent.car_data.position)\n        if dist_to_ball < opp_dist_to_ball: reward += self.weights[\"closer_to_ball_reward\"]\n        if player.on_ground and player.car_data.up()[2] < -0.8: reward += self.weights[\"turtling_penalty\"]\n\n        orange_goal_back_np = np.array(common_values.ORANGE_GOAL_BACK)\n        blue_goal_back_np = np.array(common_values.BLUE_GOAL_BACK)\n        own_goal_dir = -orange_goal_back_np if player.team_num == common_values.BLUE_TEAM else -blue_goal_back_np\n        car_forward = player.car_data.forward()\n        if is_dribbling and np.dot(car_forward, own_goal_dir) > 0.5:\n            reward += self.weights[\"wrong_way_penalty\"]\n        if player.boost_amount < last_player.boost_amount:\n            reward += self.weights[\"boost_waste_penalty\"]\n        return reward\n\n    def pre_step(self, state: GameState): self.last_state = state\n\n# ----------------------------\n# ZeroSumReward\n# ----------------------------\nclass ZeroSumReward(RewardFunction):\n    def __init__(self, goal_w=10, velocity_bg_w=0.09, acel_ball_w=0.1,\n                 boost_gain_w=1, jump_touch_w=3, cons_air_touches_w=8,\n                 demo_w=6, kickoff_w=0.1, tick_skip=8, team_spirit=1):\n        self.goal_w = goal_w\n        self.velocity_bg_w = velocity_bg_w * (tick_skip / 8)\n        self.acel_ball_w = acel_ball_w\n        self.boost_gain_w = boost_gain_w\n        self.boost_spend_w = 1.5 * self.boost_gain_w * ((33.3334 / (120 / tick_skip)) * 0.01)\n        self.jump_touch_w = jump_touch_w\n        self.cons_air_touches_w = cons_air_touches_w\n        self.demo_w = demo_w\n        self.kickoff_w = kickoff_w * (tick_skip / 8)\n        self.rewards = None\n        self.last_state: GameState = None\n        self.touch_timeout = 8 * 120 // tick_skip\n        self.kickoff_timeout = 5 * 120 // tick_skip\n        self.kickoff_timer = 0\n        self.closest_reset_blue = -1\n        self.closest_reset_orange = -1\n        self.blue_touch_timer = self.touch_timeout + 1\n        self.orange_touch_timer = self.touch_timeout + 1\n        self.blue_toucher = None\n        self.orange_toucher = None\n        self.team_spirit = team_spirit\n        self.n = 0\n        self.cons_touches = 0\n\n    def pre_step(self, state: GameState):\n        if self.last_state is None:\n            self.last_state = state\n\n        self.n = 0\n        self.blue_touch_timer += 1\n        self.orange_touch_timer += 1\n        self.kickoff_timer += 1\n\n        player_rewards = np.zeros(len(state.players))\n\n        for i, player in enumerate(state.players):\n            last = self.last_state.players[i]\n\n            # Ball touches\n            if player.ball_touched:\n                if player.team_num == common_values.BLUE_TEAM:\n                    self.blue_toucher = i\n                    self.blue_touch_timer = 0\n                else:\n                    self.orange_toucher = i\n                    self.orange_touch_timer = 0\n\n                # Small reward for touching\n                player_rewards[i] += 0.01\n\n                # Reward for ball speed change\n                vel_difference = abs(np.linalg.norm(self.last_state.ball.linear_velocity - state.ball.linear_velocity))\n                player_rewards[i] += vel_difference / 4600.0\n\n            # Reward for ball moving toward opponent goal\n            enemy_goal = (common_values.ORANGE_GOAL_BACK if player.team_num == common_values.BLUE_TEAM \n                          else common_values.BLUE_GOAL_BACK)\n            ball_dir = enemy_goal - state.ball.position\n            ball_speed_toward_goal = max(0, np.dot(state.ball.linear_velocity, ball_dir) / (np.linalg.norm(ball_dir)+1e-6))\n            player_rewards[i] += 0.01 * ball_speed_toward_goal / common_values.BALL_MAX_SPEED\n\n            # Demo reward\n            if player.match_demolishes > last.match_demolishes:\n                player_rewards[i] += self.demo_w\n\n            # Goal reward with ball speed factor\n            if player.match_goals > last.match_goals:\n                goal_speed = np.linalg.norm(self.last_state.ball.linear_velocity)\n                player_rewards[i] += self.goal_w * (goal_speed / common_values.CAR_MAX_SPEED)\n\n            # Kickoff reward (if applicable)\n            if self.kickoff_timer < self.kickoff_timeout:\n                player_rewards[i] += self.kickoff_w\n\n        # ------------------------\n        # ZERO-SUM ADJUSTMENT\n        # ------------------------\n        mid = len(player_rewards) // 2\n        blue_mean = np.mean(player_rewards[:mid])\n        orange_mean = np.mean(player_rewards[mid:])\n        player_rewards[:mid] -= orange_mean\n        player_rewards[mid:] -= blue_mean\n\n        self.rewards = player_rewards\n        self.last_state = state\n\n    def get_reward(self, player: PlayerData, state: GameState, previous_action: np.ndarray) -> float:\n        if self.rewards is None:\n            return 0.0\n        player_idx = next((i for i, p in enumerate(state.players) if p.car_id == player.car_id), None)\n        if player_idx is None:\n            return 0.0\n        return float(self.rewards[player_idx])\n\n    def reset(self, initial_state: GameState):\n        self.last_state = initial_state\n        self.rewards = np.zeros(len(initial_state.players))\n        self.kickoff_timer = 0\n        self.blue_touch_timer = self.orange_touch_timer = self.touch_timeout + 1\n        self.blue_toucher = self.orange_toucher = None\n        self.cons_touches = 0\n\n\n# ----------------------------\n# LowBoostVelocityReward\n# ----------------------------\nclass LowBoostVelocityReward(RewardFunction):\n    def __init__(self):\n        super().__init__()\n\n    def reset(self, initial_state: GameState): pass\n\n    def get_reward(self, player: PlayerData, state: GameState, previous_action: np.ndarray) -> float:\n        ball_vel_mag = np.linalg.norm(state.ball.linear_velocity)\n        if ball_vel_mag < 1 and player.boost_amount < 0.02:\n            player_vel = player.car_data.linear_velocity\n            player_to_ball = state.ball.position - player.car_data.position\n            dist_to_ball = np.linalg.norm(player_to_ball)\n            if dist_to_ball < 1.0: return 0.0\n            player_to_ball_unit = player_to_ball / dist_to_ball\n            player_vel_dot = np.dot(player_vel, player_to_ball_unit)\n            return max(0, player_vel_dot / common_values.CAR_MAX_SPEED)\n        return 0.0\n\n\n# ----------------------------\n# ----------------------------\n# DodgeReward (ignores normal jumps)\n# ----------------------------\nclass DodgeReward(RewardFunction):\n    def __init__(self, weight=1.0):\n        \n        super().__init__()\n        self.weight = weight\n        self.last_player_states = {}\n\n    def reset(self, initial_state: GameState):\n        \n        self.last_player_states = {}\n        for player in initial_state.players:\n            # Store a copy of the initial player data\n            self.last_player_states[player.car_id] = player\n\n    def get_reward(self, player: PlayerData, state: GameState, previous_action: np.ndarray) -> float:\n        \n        \n        \n        reward = 0.0\n        last_player = self.last_player_states.get(player.car_id)\n\n        if last_player is not None:\n            # A dodge/flip is used when has_flip goes from True to False and the car is not on the ground.\n            if last_player.has_flip and not player.has_flip and not player.on_ground:\n                reward = self.weight\n\n        # Update the stored state for the next step\n        self.last_player_states[player.car_id] = player\n        return reward\n\n\n# ----------------------------\n# FastShotReward\n# ----------------------------\nclass FastShotReward(RewardFunction):\n    def __init__(self, weight=1.0):\n        super().__init__()\n        self.weight = weight\n        self.last_state: GameState = None\n\n    def reset(self, initial_state: GameState):\n        self.last_state = initial_state\n\n    def pre_step(self, state: GameState):\n        self.last_state = state\n\n    def get_reward(self, player: PlayerData, state: GameState, previous_action: np.ndarray) -> float:\n        if self.last_state is None:\n            return 0.0\n\n        reward = 0.0\n        # Only reward if the player just touched the ball\n        last_player = next((p for p in self.last_state.players if p.car_id == player.car_id), None)\n        if last_player is None:\n            return 0.0\n\n        if player.ball_touched and not last_player.ball_touched:\n            # Direction toward opponent goal\n            enemy_goal = np.array(common_values.ORANGE_GOAL_BACK if player.team_num == common_values.BLUE_TEAM\n                                  else common_values.BLUE_GOAL_BACK)\n            ball_dir = enemy_goal - state.ball.position\n            ball_vel = state.ball.linear_velocity\n            ball_speed_toward_goal = max(0, np.dot(ball_vel, ball_dir) / (np.linalg.norm(ball_dir)+1e-6))\n            \n            # Reward proportional to speed toward opponent goal\n            reward += self.weight * ball_speed_toward_goal / common_values.BALL_MAX_SPEED\n\n        return reward\n\n# ----------------------------\n# FastGoalReward\n# ----------------------------\nclass FastGoalReward(RewardFunction):\n    def __init__(self, max_reward=20.0, match_time=900):  # match_time in ticks or seconds\n        \n        super().__init__()\n        self.max_reward = max_reward\n        self.match_time = match_time\n        self.start_tick = None\n        self.last_state: GameState = None\n\n    def reset(self, initial_state: GameState):\n        self.start_tick = 0\n        self.last_state = initial_state\n\n    def pre_step(self, state: GameState):\n        if self.start_tick is None:\n            self.start_tick = 0\n        else:\n            self.start_tick += 1  # Increment time per step\n        self.last_state = state\n\n    def get_reward(self, player: PlayerData, state: GameState, previous_action: np.ndarray) -> float:\n        if self.last_state is None:\n            return 0.0\n\n        last_player = next((p for p in self.last_state.players if p.car_id == player.car_id), None)\n        if last_player is None:\n            return 0.0\n\n        reward = 0.0\n        # Reward only when a new goal is scored by this player\n        if player.match_goals > last_player.match_goals:\n            # Scale reward based on how early the goal was scored\n            time_factor = max(0, 1.0 - self.start_tick / self.match_time)\n            reward += self.max_reward * time_factor\n\n        return reward\n\n\n# ==================================================================\n# === STATE SETTERS ===\n# ==================================================================\n\nclass ReplayStateSetter(StateSetter):\n    def __init__(self, states_dir: str):\n        super().__init__()\n        self.states_dir = states_dir\n        self.file_paths = []\n        self.file_lengths = []\n        self.total_states = 0\n        if not os.path.isdir(self.states_dir):\n            print(f\"[ReplayStateSetter] Directory {self.states_dir} does not exist!\")\n            return\n        print(f\"[ReplayStateSetter] Loading .npy files from {self.states_dir}...\")\n        for filename in os.listdir(self.states_dir):\n            if filename.endswith(\".npy\"):\n                filepath = os.path.join(self.states_dir, filename)\n                states = np.load(filepath, allow_pickle=True)\n                if len(states) > 0:\n                    self.file_paths.append(filepath)\n                    self.file_lengths.append(len(states))\n                    self.total_states += len(states)\n                    print(f\"[ReplayStateSetter] Loaded {len(states)} states from {filename}\")\n        print(f\"[ReplayStateSetter] Finished loading. Total states: {self.total_states}\")\n\n    def reset(self, state_wrapper: StateWrapper):\n        if self.total_states == 0:\n            print(\"[ReplayStateSetter] No states available to set.\")\n            return\n        chosen_path = random.choices(self.file_paths, weights=self.file_lengths, k=1)[0]\n        states_array = np.load(chosen_path, allow_pickle=True)\n        print(f\"[ReplayStateSetter] Sampling from file: {os.path.basename(chosen_path)} ({len(states_array)} states)\")\n\n        num_states_in_file = len(states_array)\n        if num_states_in_file > 300:\n            sampled_states = random.sample(list(states_array), 300)\n            chosen_state = random.choice(sampled_states)\n        else:\n            chosen_state = states_array[random.randint(0, num_states_in_file - 1)]\n        print(f\"[ReplayStateSetter] Chosen state index set in environment.\")\n\n        ball_state = chosen_state['ball']\n        state_wrapper.ball.set_pos(*ball_state['position'])\n        state_wrapper.ball.set_lin_vel(*ball_state['linear_velocity'])\n        state_wrapper.ball.set_ang_vel(*ball_state['angular_velocity'])\n        car_states = list(chosen_state['cars'].values())\n        for i in range(min(len(car_states), len(state_wrapper.cars))):\n            car_wrapper, car_state = state_wrapper.cars[i], car_states[i]\n            car_wrapper.set_pos(*car_state['position'])\n            euler_angles = rlgym_math.quat_to_euler(car_state['quaternion'])\n            car_wrapper.set_rot(pitch=-euler_angles[0], yaw=euler_angles[1], roll=-euler_angles[2])\n            car_wrapper.set_lin_vel(*car_state['linear_velocity'])\n            car_wrapper.set_ang_vel(*car_state['angular_velocity'])\n            car_wrapper.boost = car_state['boost_amount'] / 100.0\n\n\n\n\n# ==================================================================\n# === ENVIRONMENT BUILDER ===\n# ==================================================================\ndef build_env():\n    TICK_SKIP = 8\n    \n    reward_fn = CombinedReward(\n        reward_functions=(\n            AdvancedDribbleReward(),\n            ZeroSumReward(tick_skip=TICK_SKIP),\n            LowBoostVelocityReward(),\n            DodgeReward(),\n            FastShotReward(weight=1.5),\n            FastGoalReward()# <-- new fast shot reward added\n\n        ),\n        reward_weights=(1.0, 1.0, 1.0, 1.0, 1.0, 1.0)\n    )\n    \n    terminal_conditions = [TimeoutCondition(900), GoalScoredCondition()]\n    obs_builder = ModernCoyoteObsBuilder(tick_skip=TICK_SKIP, team_size=1)\n    action_parser = ModernCoyoteAction()\n    \n    replay_states_path = \"/kaggle/input/npy123\"\n    state_setter = ReplayStateSetter(replay_states_path)\n    \n    env = make(\n        team_size=1, spawn_opponents=True, tick_skip=TICK_SKIP,\n        reward_fn=reward_fn, terminal_conditions=terminal_conditions,\n        obs_builder=obs_builder, action_parser=action_parser, state_setter=state_setter\n    )\n   # import rocketsimvis_rlgym_sim_client as rsv\n    type(env).render = lambda self: rsv.send_state_to_rocketsimvis(self._prev_state)\n    return env\n\n\"\"\"\n\nwith open(\"agent_env.py\", \"w\") as f:\n    f.write(agent_env_code)\n\nprint(\"Updated 'agent_env.py' with your custom rewards and state setters successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T21:24:42.564868Z","iopub.execute_input":"2025-09-23T21:24:42.565233Z","iopub.status.idle":"2025-09-23T21:24:42.585783Z","shell.execute_reply.started":"2025-09-23T21:24:42.565209Z","shell.execute_reply":"2025-09-23T21:24:42.584869Z"}},"outputs":[{"name":"stdout","text":"Updated 'agent_env.py' with your custom rewards and state setters successfully!\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"\n#\n# CELL 3: Run the Main Training Script\n#\nimport json\nimport os\nimport random\nimport shutil\nimport time\nimport sys\nfrom typing import Union, Tuple\nfrom collections import OrderedDict\nimport numpy as np\nimport torch\nfrom rlgym_ppo.batched_agents import BatchedAgentManager\nfrom rlgym_ppo.ppo import ExperienceBuffer, PPOLearner\nfrom rlgym_ppo.util import WelfordRunningStat, reporting, torch_functions\n\n# --- Add current directory to path to find our custom files ---\nsys.path.insert(0, os.path.abspath('.'))\nfrom agent_env import build_env\n\n# --- FULLY MODIFIED LEARNER FOR KAGGLE & PRE-TRAINING ---\nclass KaggleLearner(object): # Renamed to avoid conflicts\n    def __init__(\n            # fmt: off\n            self, env_create_function, metrics_logger=None, n_proc: int = 8, min_inference_size: int = 80,\n            render: bool = False, render_delay: float = 0, timestep_limit: int = 5_000_000_000,\n            exp_buffer_size: int = 100000, ts_per_iteration: int = 50000, standardize_returns: bool = True,\n            standardize_obs: bool = True, max_returns_per_stats_increment: int = 150,\n            steps_per_obs_stats_increment: int = 5, policy_layer_sizes: Tuple[int, ...] = (256, 256, 256),\n            critic_layer_sizes: Tuple[int, ...] = (256, 256, 256), continuous_var_range: Tuple[float, ...] = (0.1, 1.0),\n            ppo_epochs: int = 10, ppo_batch_size: int = 50000, ppo_minibatch_size: Union[int, None] = None,\n            ppo_ent_coef: float = 0.005, ppo_clip_range: float = 0.2, gae_lambda: float = 0.95,\n            gae_gamma: float = 0.99, policy_lr: float = 3e-4, critic_lr: float = 3e-4, log_to_wandb: bool = False,\n            load_wandb: bool = True, wandb_run = None, wandb_project_name: Union[str, None] = None,\n            wandb_group_name: Union[str, None] = None, wandb_run_name: Union[str, None] = None,\n            checkpoints_save_folder: Union[str, None] = None, add_unix_timestamp: bool = True,\n            checkpoint_load_folder: Union[str, None] = \"latest\", pretrained_policy_path: Union[str, None] = None,\n            save_every_ts: int = 1_000_000, instance_launch_delay: Union[float, None] = None,\n            random_seed: int = 123, n_checkpoints_to_keep: int = 5, shm_buffer_size: int = 8192, device: str = \"auto\"):\n        # (Rest of __init__ is a direct copy of the provided learner.py)\n        assert (env_create_function is not None), \"MUST PROVIDE A FUNCTION TO CREATE RLGYM FUNCTIONS\"\n        if checkpoints_save_folder is None: checkpoints_save_folder = os.path.join(\"data\", \"checkpoints\", \"rlgym-ppo-run\")\n        self.add_unix_timestamp = add_unix_timestamp\n        if add_unix_timestamp: checkpoints_save_folder = f\"{checkpoints_save_folder}-{time.time_ns()}\"\n        torch.manual_seed(random_seed); np.random.seed(random_seed); random.seed(random_seed)\n        self.n_checkpoints_to_keep, self.checkpoints_save_folder = n_checkpoints_to_keep, checkpoints_save_folder\n        self.max_returns_per_stats_increment, self.metrics_logger = max_returns_per_stats_increment, metrics_logger\n        self.standardize_returns, self.save_every_ts, self.ts_since_last_save = standardize_returns, save_every_ts, 0\n        if device in {\"auto\", \"gpu\"} and torch.cuda.is_available(): self.device = \"cuda:0\"; torch.backends.cudnn.benchmark = True\n        elif device == \"auto\" and not torch.cuda.is_available(): self.device = \"cpu\"\n        else: self.device = device\n        print(f\"Using device {self.device}\")\n        self.exp_buffer_size, self.timestep_limit, self.ts_per_epoch = exp_buffer_size, timestep_limit, ts_per_iteration\n        self.gae_lambda, self.gae_gamma, self.return_stats, self.epoch = gae_lambda, gae_gamma, WelfordRunningStat(1), 0\n        self.experience_buffer = ExperienceBuffer(self.exp_buffer_size, seed=random_seed, device=\"cpu\")\n        print(\"Initializing processes...\"); collect_metrics_fn = None if metrics_logger is None else self.metrics_logger.collect_metrics\n        self.agent = BatchedAgentManager(None, min_inference_size=min_inference_size, seed=random_seed, standardize_obs=False, steps_per_obs_stats_increment=steps_per_obs_stats_increment)\n        obs_space_size, act_space_size, action_space_type = self.agent.init_processes(n_processes=n_proc, build_env_fn=env_create_function, collect_metrics_fn=collect_metrics_fn, spawn_delay=instance_launch_delay, render=render, render_delay=render_delay, shm_buffer_size=shm_buffer_size)\n        obs_space_size = np.prod(obs_space_size); print(\"Initializing PPO...\")\n        if ppo_minibatch_size is None: ppo_minibatch_size = ppo_batch_size\n        self.ppo_learner = PPOLearner(obs_space_size, act_space_size, device=self.device, batch_size=ppo_batch_size, mini_batch_size=ppo_minibatch_size, n_epochs=ppo_epochs, continuous_var_range=continuous_var_range, policy_type=action_space_type, policy_layer_sizes=policy_layer_sizes, critic_layer_sizes=critic_layer_sizes, policy_lr=policy_lr, critic_lr=critic_lr, clip_range=ppo_clip_range, ent_coef=ppo_ent_coef)\n        if pretrained_policy_path is not None and os.path.exists(pretrained_policy_path):\n            print(f\"Loading pre-trained model weights from: {pretrained_policy_path}\")\n            checkpoint = torch.load(pretrained_policy_path, map_location=self.device)\n            if 'model_state_dict' in checkpoint: pretrained_dict = checkpoint['model_state_dict']; print(\"Checkpoint dictionary found, extracting 'model_state_dict'.\")\n            else: pretrained_dict = checkpoint; print(\"Raw state_dict found.\")\n            is_data_parallel = any(key.startswith('module.') for key in pretrained_dict.keys())\n            if is_data_parallel:\n                print(\"DataParallel 'module.' prefix detected. Stripping prefix...\")\n                clean_state_dict = OrderedDict()\n                for k, v in pretrained_dict.items(): clean_state_dict[k[7:]] = v\n                pretrained_dict = clean_state_dict\n            if any(key.startswith('layers.') for key in pretrained_dict.keys()):\n                print(\"Renaming 'layers.' keys to 'model.' for compatibility...\")\n                renamed_dict = OrderedDict()\n                for k, v in pretrained_dict.items():\n                    if k.startswith('layers.'): renamed_dict['model.' + k[len('layers.'):]] = v\n                    else: renamed_dict[k] = v\n                pretrained_dict = renamed_dict\n            self.ppo_learner.policy.load_state_dict(pretrained_dict)\n            print(\"Successfully loaded pre-trained policy weights.\")\n        self.agent.policy = self.ppo_learner.policy\n        self.config = {\"n_proc\": n_proc, \"min_inference_size\": min_inference_size, \"timestep_limit\": timestep_limit, \"exp_buffer_size\": exp_buffer_size, \"ts_per_iteration\": ts_per_iteration, \"standardize_returns\": standardize_returns, \"standardize_obs\": standardize_obs, \"policy_layer_sizes\": policy_layer_sizes, \"critic_layer_sizes\": critic_layer_sizes, \"ppo_epochs\": ppo_epochs, \"ppo_batch_size\": ppo_batch_size, \"ppo_minibatch_size\": ppo_minibatch_size, \"ppo_ent_coef\": ppo_ent_coef, \"ppo_clip_range\": ppo_clip_range, \"gae_lambda\": gae_lambda, \"gae_gamma\": gae_gamma, \"policy_lr\": policy_lr, \"critic_lr\": critic_lr, \"shm_buffer_size\": shm_buffer_size}\n        self.wandb_run = wandb_run\n        wandb_loaded = checkpoint_load_folder is not None and self.load(checkpoint_load_folder, load_wandb, policy_lr, critic_lr)\n        if log_to_wandb and self.wandb_run is None and not wandb_loaded:\n            project = \"rlgym-ppo\" if wandb_project_name is None else wandb_project_name\n            group = \"unnamed-runs\" if wandb_group_name is None else wandb_group_name\n            run_name = \"rlgym-ppo-run\" if wandb_run_name is None else wandb_run_name\n            print(\"Wandb not supported in this Kaggle version.\")\n        print(\"Learner successfully initialized!\")\n    \n    # Notebook-safe learning loop\n    def _learn(self):\n        print(\"Starting training loop. This will run until the timestep limit is reached or the notebook is stopped.\\n\")\n        while self.agent.cumulative_timesteps < self.timestep_limit:\n            epoch_start = time.perf_counter()\n            report = {}\n            experience, collected_metrics, steps_collected, collection_time = self.agent.collect_timesteps(self.ts_per_epoch)\n            if self.metrics_logger is not None: self.metrics_logger.report_metrics(collected_metrics, self.wandb_run, self.agent.cumulative_timesteps)\n            self.add_new_experience(experience)\n            ppo_report = self.ppo_learner.learn(self.experience_buffer)\n            epoch_stop = time.perf_counter()\n            epoch_time = epoch_stop - epoch_start\n            report.update(ppo_report)\n            if self.epoch < 1: report[\"Value Function Loss\"] = np.nan\n            report[\"Cumulative Timesteps\"] = self.agent.cumulative_timesteps\n            report[\"Total Iteration Time\"] = epoch_time\n            report[\"Timesteps Collected\"] = steps_collected\n            report[\"Timestep Collection Time\"] = collection_time\n            report[\"Timestep Consumption Time\"] = epoch_time - collection_time\n            report[\"Collected Steps per Second\"] = steps_collected / collection_time\n            report[\"Overall Steps per Second\"] = steps_collected / epoch_time\n            self.ts_since_last_save += steps_collected\n            if self.agent.average_reward is not None: report[\"Policy Reward\"] = self.agent.average_reward\n            else: report[\"Policy Reward\"] = np.nan\n            reporting.report_metrics(loggable_metrics=report, debug_metrics=None, wandb_run=self.wandb_run)\n            report.clear(); ppo_report.clear()\n            if self.ts_since_last_save >= self.save_every_ts:\n                self.save(self.agent.cumulative_timesteps)\n                self.ts_since_last_save = 0\n            self.epoch += 1\n\n    # (Rest of methods are direct copies from provided learner.py)\n    def learn(self):\n        try: self._learn()\n        except Exception: import traceback; print(\"\\n\\nLEARNING LOOP ENCOUNTERED AN ERROR\\n\"); traceback.print_exc();\n        try: self.save(self.agent.cumulative_timesteps)\n        except: print(\"FAILED TO SAVE ON EXIT\")\n        finally: self.cleanup()\n    @torch.no_grad()\n    def add_new_experience(self, experience):\n        states, actions, log_probs, rewards, next_states, dones, truncated = experience\n        val_inp = np.zeros(shape=(states.shape[0] + 1, states.shape[1])); val_inp[:-1] = states; val_inp[-1] = next_states[-1]\n        val_preds = self.ppo_learner.value_net(val_inp).cpu().flatten().tolist(); torch.cuda.empty_cache()\n        ret_std = self.return_stats.std[0] if self.standardize_returns else None\n        value_targets, advantages, returns = torch_functions.compute_gae(rewards, dones, truncated, val_preds, gamma=self.gae_gamma, lmbda=self.gae_lambda, return_std=ret_std)\n        if self.standardize_returns: n_to_increment = min(self.max_returns_per_stats_increment, len(returns)); self.return_stats.increment(returns[:n_to_increment], n_to_increment)\n        self.experience_buffer.submit_experience(states, actions, log_probs, rewards, next_states, dones, truncated, value_targets, advantages)\n    def save(self, cumulative_timesteps):\n        folder_path = os.path.join(self.checkpoints_save_folder, str(cumulative_timesteps))\n        os.makedirs(folder_path, exist_ok=True); print(f\"Saving checkpoint {cumulative_timesteps}...\")\n        existing_checkpoints = [int(arg) for arg in os.listdir(self.checkpoints_save_folder)]\n        if len(existing_checkpoints) > self.n_checkpoints_to_keep:\n            existing_checkpoints.sort()\n            for checkpoint_name in existing_checkpoints[:-self.n_checkpoints_to_keep]: shutil.rmtree(os.path.join(self.checkpoints_save_folder, str(checkpoint_name)))\n        os.makedirs(folder_path, exist_ok=True); self.ppo_learner.save_to(folder_path)\n        book_keeping_vars = {\"cumulative_timesteps\": self.agent.cumulative_timesteps, \"cumulative_model_updates\": self.ppo_learner.cumulative_model_updates, \"policy_average_reward\": self.agent.average_reward, \"epoch\": self.epoch, \"ts_since_last_save\": self.ts_since_last_save, \"reward_running_stats\": self.return_stats.to_json()}\n        if self.agent.standardize_obs: book_keeping_vars[\"obs_running_stats\"] = self.agent.obs_stats.to_json()\n        if self.standardize_returns: book_keeping_vars[\"reward_running_stats\"] = self.return_stats.to_json()\n        if self.wandb_run is not None: book_keeping_vars[\"wandb_run_id\"] = self.wandb_run.id\n        with open(os.path.join(folder_path, \"BOOK_KEEPING_VARS.json\"), \"w\") as f: json.dump(book_keeping_vars, f, indent=4)\n        print(f\"Checkpoint {cumulative_timesteps} saved!\\n\")\n    def load(self, folder_path, load_wandb, new_policy_lr=None, new_critic_lr=None):\n        if folder_path == \"latest\":\n            save_folder = self.checkpoints_save_folder\n            if save_folder is None: return\n            if self.add_unix_timestamp:\n                base_save_folder = save_folder[:save_folder.rfind('-')]\n                save_path = os.path.dirname(base_save_folder)\n                if not os.path.exists(save_path): return\n                highest_timestamp = -1; best_folder = None\n                for filename in os.listdir(save_path):\n                    full_path = os.path.join(save_path, filename)\n                    if not os.path.isdir(full_path): continue\n                    if full_path.startswith(base_save_folder):\n                        unix_start_idx = full_path.rfind('-') + 1\n                        if unix_start_idx > 0:\n                            unix_time_str = filename[unix_start_idx:]\n                            if unix_time_str.isdigit():\n                                timestamp = int(unix_time_str)\n                                if timestamp > highest_timestamp: highest_timestamp = timestamp; best_folder = full_path\n                if not (best_folder is None): load_base_path = best_folder\n                else: return\n            else:\n                if os.path.exists(self.checkpoints_save_folder): load_base_path = self.checkpoints_save_folder\n                else: return\n            highest_ts = -1\n            for filename in os.listdir(load_base_path):\n                if not os.path.isdir(os.path.join(load_base_path, filename)): continue\n                if not filename.isdigit(): continue\n                highest_ts = max(highest_ts, int(filename))\n            if highest_ts != -1: folder_path = os.path.join(load_base_path, str(highest_ts)); print(f\"Auto-load path: {folder_path}\")\n            else: return\n        assert os.path.exists(folder_path), f\"UNABLE TO LOCATE FOLDER {folder_path}\"\n        print(f\"Loading from checkpoint at {folder_path}\"); self.ppo_learner.load_from(folder_path)\n        with open(os.path.join(folder_path, \"BOOK_KEEPING_VARS.json\"), \"r\") as f:\n            book_keeping_vars = dict(json.load(f)); self.agent.cumulative_timesteps = book_keeping_vars[\"cumulative_timesteps\"]\n            self.agent.average_reward = book_keeping_vars[\"policy_average_reward\"]; self.ppo_learner.cumulative_model_updates = book_keeping_vars[\"cumulative_model_updates\"]\n            self.return_stats.from_json(book_keeping_vars[\"reward_running_stats\"])\n            if self.agent.standardize_obs and \"obs_running_stats\" in book_keeping_vars.keys(): self.agent.obs_stats = WelfordRunningStat(1); self.agent.obs_stats.from_json(book_keeping_vars[\"obs_running_stats\"])\n            if self.standardize_returns and \"reward_running_stats\" in book_keeping_vars.keys(): self.return_stats.from_json(book_keeping_vars[\"reward_running_stats\"])\n            self.epoch = book_keeping_vars[\"epoch\"]\n        print(\"Checkpoint loaded!\")\n        return False\n    def cleanup(self):\n        if self.wandb_run is not None: self.wandb_run.finish()\n        if type(self.agent) == BatchedAgentManager: self.agent.cleanup()\n        self.experience_buffer.clear()\n\n\nif __name__ == '__main__':\n    # --- HYPERPARAMETERS ---\n    # Using the stable parameters from our previous successful run\n    HPARAMS = {\n        \"n_proc\": 4,  # Use 4 CPUs as requested\n        \"timestep_limit\": 500_000_000,  # Set a very high limit for a long run\n        \"ts_per_iteration\": 40_000,\n        \"exp_buffer_size\": 80_000,\n        \"ppo_batch_size\": 10_000,\n        \"ppo_epochs\": 1,\n        \"policy_lr\": 1e-5, # CRITICAL: Use the stable, low learning rate\n        \"critic_lr\": 1e-6, # CRITICAL: Use the stable, higher critic learning rate\n        \"gae_gamma\": 0.995,\n        \"ppo_ent_coef\": 0.01,\n        \"ppo_clip_range\": 0.1,\n        \"policy_layer_sizes\": (512, 512, 512, 512, 512, 512),\n        \"critic_layer_sizes\": (256, 256, 256),\n        \"checkpoints_save_folder\": \"/kaggle/working/models/coyote_long_run/\",\n        \"checkpoint_load_folder\": \"/kaggle/input/dribblegp2\",\n        \"save_every_ts\": 500_000, # Save progress more frequently\n        \"pretrained_policy_path\": \"/kaggle/input/botmodel/best_coyote_bot.pt\", # <--- PATH IS NOW CORRECT\n    }\n    \n    # --- START TRAINING ---\n    model_dir = HPARAMS[\"checkpoints_save_folder\"]\n    os.makedirs(model_dir, exist_ok=True)\n    \n    agent = KaggleLearner(\n        env_create_function=build_env,\n        **HPARAMS\n    )\n    \n    print(f\"Starting long-duration training for {os.path.basename(os.path.normpath(model_dir))}...\")\n    print(f\"Using {HPARAMS['n_proc']} CPUs.\")\n    \n    agent.learn()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T21:24:44.197589Z","iopub.execute_input":"2025-09-23T21:24:44.197962Z","iopub.status.idle":"2025-09-24T04:01:43.512332Z","shell.execute_reply.started":"2025-09-23T21:24:44.197905Z","shell.execute_reply":"2025-09-24T04:01:43.508022Z"}},"outputs":[{"name":"stdout","text":"Using device cpu\nInitializing processes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4/4 [00:00<00:00, 248.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Initializing PPO...\nTrainable Parameters:\nComponent  Count     \n--------------------\nPolicy     1564533   \nCritic     161793    \n--------------------\nTotal      1726326   \nCurrent Policy Learning Rate: 1e-05\nCurrent Critic Learning Rate: 1e-06\nLoading pre-trained model weights from: /kaggle/input/botmodel/best_coyote_bot.pt\nCheckpoint dictionary found, extracting 'model_state_dict'.\nRenaming 'layers.' keys to 'model.' for compatibility...\nSuccessfully loaded pre-trained policy weights.\nLoading from checkpoint at /kaggle/input/dribblegp2\nLOADED RUNNING STATS FROM JSON | Mean: [12.31835126] | Variance: [80634574.8673468] | Count: 337350\nLOADED RUNNING STATS FROM JSON | Mean: [12.31835126] | Variance: [80634574.8673468] | Count: 337350\nCheckpoint loaded!\nLearner successfully initialized!\nStarting long-duration training for coyote_long_run...\nUsing 4 CPUs.\nStarting training loop. This will run until the timestep limit is reached or the notebook is stopped.\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 104.93420\nPolicy Entropy: 5.24812\nValue Function Loss: 0.11338\n\nMean KL Divergence: 0.00045\nSB3 Clip Fraction: 0.01768\nPolicy Update Magnitude: 0.10068\nValue Function Update Magnitude: 0.04564\n\nCollected Steps per Second: 1,691.89549\nOverall Steps per Second: 1,395.51214\n\nTimestep Collection Time: 23.64330\nTimestep Consumption Time: 5.02144\nPPO Batch Consumption Time: 1.01588\nTotal Iteration Time: 28.66475\n\nCumulative Model Updates: 17,972\nCumulative Timesteps: 90,002,350\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 94.04797\nPolicy Entropy: 5.26291\nValue Function Loss: 0.11257\n\nMean KL Divergence: 0.00098\nSB3 Clip Fraction: 0.04033\nPolicy Update Magnitude: 0.20883\nValue Function Update Magnitude: 0.09668\n\nCollected Steps per Second: 1,648.42099\nOverall Steps per Second: 1,247.59323\n\nTimestep Collection Time: 24.26565\nTimestep Consumption Time: 7.79609\nPPO Batch Consumption Time: 0.98133\nTotal Iteration Time: 32.06173\n\nCumulative Model Updates: 17,979\nCumulative Timesteps: 90,042,350\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 97.71157\nPolicy Entropy: 5.27341\nValue Function Loss: 0.10938\n\nMean KL Divergence: 0.00121\nSB3 Clip Fraction: 0.05045\nPolicy Update Magnitude: 0.24123\nValue Function Update Magnitude: 0.11873\n\nCollected Steps per Second: 1,702.60464\nOverall Steps per Second: 1,235.81982\n\nTimestep Collection Time: 23.49459\nTimestep Consumption Time: 8.87421\nPPO Batch Consumption Time: 0.99210\nTotal Iteration Time: 32.36880\n\nCumulative Model Updates: 17,987\nCumulative Timesteps: 90,082,352\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 83.40954\nPolicy Entropy: 5.25919\nValue Function Loss: 0.10665\n\nMean KL Divergence: 0.00102\nSB3 Clip Fraction: 0.04201\nPolicy Update Magnitude: 0.23570\nValue Function Update Magnitude: 0.10533\n\nCollected Steps per Second: 1,679.18475\nOverall Steps per Second: 1,218.93448\n\nTimestep Collection Time: 23.82227\nTimestep Consumption Time: 8.99491\nPPO Batch Consumption Time: 1.00323\nTotal Iteration Time: 32.81719\n\nCumulative Model Updates: 17,995\nCumulative Timesteps: 90,122,354\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 79.41013\nPolicy Entropy: 5.23895\nValue Function Loss: 0.10002\n\nMean KL Divergence: 0.00101\nSB3 Clip Fraction: 0.04290\nPolicy Update Magnitude: 0.22777\nValue Function Update Magnitude: 0.09313\n\nCollected Steps per Second: 1,603.62221\nOverall Steps per Second: 1,183.51956\n\nTimestep Collection Time: 24.94353\nTimestep Consumption Time: 8.85397\nPPO Batch Consumption Time: 0.99307\nTotal Iteration Time: 33.79750\n\nCumulative Model Updates: 18,003\nCumulative Timesteps: 90,162,354\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 93.57997\nPolicy Entropy: 5.22904\nValue Function Loss: 0.09952\n\nMean KL Divergence: 0.00085\nSB3 Clip Fraction: 0.03442\nPolicy Update Magnitude: 0.22263\nValue Function Update Magnitude: 0.08559\n\nCollected Steps per Second: 1,715.82355\nOverall Steps per Second: 1,244.58238\n\nTimestep Collection Time: 23.31359\nTimestep Consumption Time: 8.82732\nPPO Batch Consumption Time: 0.98773\nTotal Iteration Time: 32.14090\n\nCumulative Model Updates: 18,011\nCumulative Timesteps: 90,202,356\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 108.18637\nPolicy Entropy: 5.25474\nValue Function Loss: 0.09713\n\nMean KL Divergence: 0.00093\nSB3 Clip Fraction: 0.03872\nPolicy Update Magnitude: 0.20958\nValue Function Update Magnitude: 0.07252\n\nCollected Steps per Second: 1,716.71450\nOverall Steps per Second: 1,245.76701\n\nTimestep Collection Time: 23.30032\nTimestep Consumption Time: 8.80841\nPPO Batch Consumption Time: 0.98215\nTotal Iteration Time: 32.10873\n\nCumulative Model Updates: 18,019\nCumulative Timesteps: 90,242,356\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n[ReplayStateSetter] Loading .npy files from /kaggle/input/npy123...\n[ReplayStateSetter] Loaded 58 states from dribbling.npy\n[ReplayStateSetter] Loaded 1423 states from no_boost.npy\n[ReplayStateSetter] Loaded 1050 states from saves.npy\n[ReplayStateSetter] Loaded 1711 states from ball_in_air.npy\n[ReplayStateSetter] Loaded 20 states from 50_50s.npy\n[ReplayStateSetter] Loaded 3787 states from open_nets.npy\n[ReplayStateSetter] Loaded 337 states from wall_plays.npy\n[ReplayStateSetter] Loaded 852 states from aerials.npy\n[ReplayStateSetter] Loaded 2252 states from defense.npy\n[ReplayStateSetter] Loaded 1889 states from challenging.npy\n[ReplayStateSetter] Loaded 750 states from boost_starved_defense.npy\n[ReplayStateSetter] Finished loading. Total states: 14129\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)[ReplayStateSetter] Loading .npy files from /kaggle/input/npy123...\n[ReplayStateSetter] Loaded 58 states from dribbling.npy\n[ReplayStateSetter] Loaded 1423 states from no_boost.npy\n[ReplayStateSetter] Loaded 1050 states from saves.npy\n[ReplayStateSetter] Loaded 1711 states from ball_in_air.npy\n[ReplayStateSetter] Loaded 20 states from 50_50s.npy\n[ReplayStateSetter] Loaded 3787 states from open_nets.npy\n[ReplayStateSetter] Loaded 337 states from wall_plays.npy\n[ReplayStateSetter] Loaded 852 states from aerials.npy\n[ReplayStateSetter] Loaded 2252 states from defense.npy\n[ReplayStateSetter] Loaded 1889 states from challenging.npy\n[ReplayStateSetter] Loaded 750 states from boost_starved_defense.npy\n[ReplayStateSetter] Finished loading. Total states: 14129\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\nReceived request for env shapes, returning:\n- Observations shape: (116,)\n- Number of actions: 373.0\n- Action space type: 0.0 (Discrete)\n--------------------\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.[ReplayStateSetter] Loading .npy files from /kaggle/input/npy123...\n[ReplayStateSetter] Loaded 58 states from dribbling.npy\n[ReplayStateSetter] Loaded 1423 states from no_boost.npy\n[ReplayStateSetter] Loaded 1050 states from saves.npy\n[ReplayStateSetter] Loaded 1711 states from ball_in_air.npy\n[ReplayStateSetter] Loaded 20 states from 50_50s.npy\n[ReplayStateSetter] Loaded 3787 states from open_nets.npy\n[ReplayStateSetter] Loaded 337 states from wall_plays.npy\n[ReplayStateSetter] Loaded 852 states from aerials.npy\n[ReplayStateSetter] Loaded 2252 states from defense.npy\n[ReplayStateSetter] Loaded 1889 states from challenging.npy\n[ReplayStateSetter] Loaded 750 states from boost_starved_defense.npy\n[ReplayStateSetter] Finished loading. Total states: 14129\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.[ReplayStateSetter] Loading .npy files from /kaggle/input/npy123...\n[ReplayStateSetter] Loaded 58 states from dribbling.npy\n[ReplayStateSetter] Loaded 1423 states from no_boost.npy\n[ReplayStateSetter] Loaded 1050 states from saves.npy\n[ReplayStateSetter] Loaded 1711 states from ball_in_air.npy\n[ReplayStateSetter] Loaded 20 states from 50_50s.npy\n[ReplayStateSetter] Loaded 3787 states from open_nets.npy\n[ReplayStateSetter] Loaded 337 states from wall_plays.npy\n[ReplayStateSetter] Loaded 852 states from aerials.npy\n[ReplayStateSetter] Loaded 2252 states from defense.npy\n[ReplayStateSetter] Loaded 1889 states from challenging.npy\n[ReplayStateSetter] Loaded 750 states from boost_starved_defense.npy\n[ReplayStateSetter] Finished loading. Total states: 14129\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 81.51205\nPolicy Entropy: 5.26194\nValue Function Loss: 0.09084\n\nMean KL Divergence: 0.00086\nSB3 Clip Fraction: 0.03376\nPolicy Update Magnitude: 0.20081\nValue Function Update Magnitude: 0.05648\n\nCollected Steps per Second: 1,644.03764\nOverall Steps per Second: 1,202.40359\n\nTimestep Collection Time: 24.33034\nTimestep Consumption Time: 8.93636\nPPO Batch Consumption Time: 0.99163\nTotal Iteration Time: 33.26670\n\nCumulative Model Updates: 18,027\nCumulative Timesteps: 90,282,356\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 63.99687\nPolicy Entropy: 5.24839\nValue Function Loss: 0.08952\n\nMean KL Divergence: 0.00081\nSB3 Clip Fraction: 0.03207\nPolicy Update Magnitude: 0.20219\nValue Function Update Magnitude: 0.04960\n\nCollected Steps per Second: 1,659.98292\nOverall Steps per Second: 1,212.94812\n\nTimestep Collection Time: 24.09663\nTimestep Consumption Time: 8.88087\nPPO Batch Consumption Time: 0.99537\nTotal Iteration Time: 32.97750\n\nCumulative Model Updates: 18,035\nCumulative Timesteps: 90,322,356\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 116.73742\nPolicy Entropy: 5.25152\nValue Function Loss: 0.08740\n\nMean KL Divergence: 0.00087\nSB3 Clip Fraction: 0.03632\nPolicy Update Magnitude: 0.21045\nValue Function Update Magnitude: 0.05242\n\nCollected Steps per Second: 1,638.51308\nOverall Steps per Second: 1,198.63413\n\nTimestep Collection Time: 24.41238\nTimestep Consumption Time: 8.95894\nPPO Batch Consumption Time: 0.99662\nTotal Iteration Time: 33.37132\n\nCumulative Model Updates: 18,043\nCumulative Timesteps: 90,362,356\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 106.54375\nPolicy Entropy: 5.25556\nValue Function Loss: 0.08640\n\nMean KL Divergence: 0.00086\nSB3 Clip Fraction: 0.03450\nPolicy Update Magnitude: 0.19937\nValue Function Update Magnitude: 0.04889\n\nCollected Steps per Second: 1,669.35343\nOverall Steps per Second: 1,204.72050\n\nTimestep Collection Time: 23.96137\nTimestep Consumption Time: 9.24135\nPPO Batch Consumption Time: 0.99584\nTotal Iteration Time: 33.20272\n\nCumulative Model Updates: 18,051\nCumulative Timesteps: 90,402,356\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 108.17146\nPolicy Entropy: 5.25722\nValue Function Loss: 0.08823\n\nMean KL Divergence: 0.00083\nSB3 Clip Fraction: 0.03391\nPolicy Update Magnitude: 0.19647\nValue Function Update Magnitude: 0.04358\n\nCollected Steps per Second: 1,750.74955\nOverall Steps per Second: 1,254.19182\n\nTimestep Collection Time: 22.84850\nTimestep Consumption Time: 9.04614\nPPO Batch Consumption Time: 0.97347\nTotal Iteration Time: 31.89464\n\nCumulative Model Updates: 18,059\nCumulative Timesteps: 90,442,358\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 83.14452\nPolicy Entropy: 5.25274\nValue Function Loss: 0.09006\n\nMean KL Divergence: 0.00096\nSB3 Clip Fraction: 0.03948\nPolicy Update Magnitude: 0.19699\nValue Function Update Magnitude: 0.04660\n\nCollected Steps per Second: 1,773.48779\nOverall Steps per Second: 1,260.72120\n\nTimestep Collection Time: 22.55443\nTimestep Consumption Time: 9.17344\nPPO Batch Consumption Time: 0.99476\nTotal Iteration Time: 31.72787\n\nCumulative Model Updates: 18,067\nCumulative Timesteps: 90,482,358\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 90482358...\nCheckpoint 90482358 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 98.73451\nPolicy Entropy: 5.26643\nValue Function Loss: 0.09236\n\nMean KL Divergence: 0.00099\nSB3 Clip Fraction: 0.04048\nPolicy Update Magnitude: 0.19292\nValue Function Update Magnitude: 0.04902\n\nCollected Steps per Second: 1,798.95803\nOverall Steps per Second: 1,275.28836\n\nTimestep Collection Time: 22.23509\nTimestep Consumption Time: 9.13036\nPPO Batch Consumption Time: 0.98651\nTotal Iteration Time: 31.36546\n\nCumulative Model Updates: 18,075\nCumulative Timesteps: 90,522,358\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 107.72821\nPolicy Entropy: 5.26515\nValue Function Loss: 0.09293\n\nMean KL Divergence: 0.00102\nSB3 Clip Fraction: 0.04291\nPolicy Update Magnitude: 0.19744\nValue Function Update Magnitude: 0.04734\n\nCollected Steps per Second: 1,722.86988\nOverall Steps per Second: 1,236.44879\n\nTimestep Collection Time: 23.21824\nTimestep Consumption Time: 9.13409\nPPO Batch Consumption Time: 0.97943\nTotal Iteration Time: 32.35233\n\nCumulative Model Updates: 18,083\nCumulative Timesteps: 90,562,360\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 66.95046\nPolicy Entropy: 5.27706\nValue Function Loss: 0.08786\n\nMean KL Divergence: 0.00101\nSB3 Clip Fraction: 0.04141\nPolicy Update Magnitude: 0.20460\nValue Function Update Magnitude: 0.04700\n\nCollected Steps per Second: 1,673.65386\nOverall Steps per Second: 1,211.18749\n\nTimestep Collection Time: 23.89980\nTimestep Consumption Time: 9.12564\nPPO Batch Consumption Time: 0.97831\nTotal Iteration Time: 33.02544\n\nCumulative Model Updates: 18,091\nCumulative Timesteps: 90,602,360\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 100.77832\nPolicy Entropy: 5.29234\nValue Function Loss: 0.08699\n\nMean KL Divergence: 0.00086\nSB3 Clip Fraction: 0.03373\nPolicy Update Magnitude: 0.21661\nValue Function Update Magnitude: 0.05301\n\nCollected Steps per Second: 1,649.26806\nOverall Steps per Second: 1,195.60505\n\nTimestep Collection Time: 24.25318\nTimestep Consumption Time: 9.20268\nPPO Batch Consumption Time: 0.98822\nTotal Iteration Time: 33.45586\n\nCumulative Model Updates: 18,099\nCumulative Timesteps: 90,642,360\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 103.92421\nPolicy Entropy: 5.28518\nValue Function Loss: 0.08556\n\nMean KL Divergence: 0.00092\nSB3 Clip Fraction: 0.03714\nPolicy Update Magnitude: 0.22151\nValue Function Update Magnitude: 0.05846\n\nCollected Steps per Second: 1,646.08668\nOverall Steps per Second: 1,203.09314\n\nTimestep Collection Time: 24.30127\nTimestep Consumption Time: 8.94802\nPPO Batch Consumption Time: 0.96103\nTotal Iteration Time: 33.24930\n\nCumulative Model Updates: 18,107\nCumulative Timesteps: 90,682,362\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 79.20037\nPolicy Entropy: 5.27737\nValue Function Loss: 0.08383\n\nMean KL Divergence: 0.00079\nSB3 Clip Fraction: 0.03196\nPolicy Update Magnitude: 0.20222\nValue Function Update Magnitude: 0.06198\n\nCollected Steps per Second: 1,651.66652\nOverall Steps per Second: 1,198.55292\n\nTimestep Collection Time: 24.21796\nTimestep Consumption Time: 9.15561\nPPO Batch Consumption Time: 0.97865\nTotal Iteration Time: 33.37358\n\nCumulative Model Updates: 18,115\nCumulative Timesteps: 90,722,362\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 106.86515\nPolicy Entropy: 5.28901\nValue Function Loss: 0.07779\n\nMean KL Divergence: 0.00086\nSB3 Clip Fraction: 0.03571\nPolicy Update Magnitude: 0.19765\nValue Function Update Magnitude: 0.08686\n\nCollected Steps per Second: 1,685.99618\nOverall Steps per Second: 1,217.21109\n\nTimestep Collection Time: 23.72485\nTimestep Consumption Time: 9.13716\nPPO Batch Consumption Time: 0.98407\nTotal Iteration Time: 32.86201\n\nCumulative Model Updates: 18,123\nCumulative Timesteps: 90,762,362\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 99.44970\nPolicy Entropy: 5.28974\nValue Function Loss: 0.07981\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02831\nPolicy Update Magnitude: 0.20271\nValue Function Update Magnitude: 0.09147\n\nCollected Steps per Second: 1,659.82157\nOverall Steps per Second: 1,206.53593\n\nTimestep Collection Time: 24.10018\nTimestep Consumption Time: 9.05424\nPPO Batch Consumption Time: 0.97751\nTotal Iteration Time: 33.15442\n\nCumulative Model Updates: 18,131\nCumulative Timesteps: 90,802,364\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 93.70957\nPolicy Entropy: 5.30382\nValue Function Loss: 0.08399\n\nMean KL Divergence: 0.00070\nSB3 Clip Fraction: 0.02668\nPolicy Update Magnitude: 0.20863\nValue Function Update Magnitude: 0.10297\n\nCollected Steps per Second: 1,721.22066\nOverall Steps per Second: 1,241.83727\n\nTimestep Collection Time: 23.23932\nTimestep Consumption Time: 8.97102\nPPO Batch Consumption Time: 0.96506\nTotal Iteration Time: 32.21034\n\nCumulative Model Updates: 18,139\nCumulative Timesteps: 90,842,364\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 67.83934\nPolicy Entropy: 5.28787\nValue Function Loss: 0.07940\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.02999\nPolicy Update Magnitude: 0.20195\nValue Function Update Magnitude: 0.10177\n\nCollected Steps per Second: 1,755.58209\nOverall Steps per Second: 1,252.66345\n\nTimestep Collection Time: 22.78447\nTimestep Consumption Time: 9.14750\nPPO Batch Consumption Time: 0.98628\nTotal Iteration Time: 31.93196\n\nCumulative Model Updates: 18,147\nCumulative Timesteps: 90,882,364\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 104.90859\nPolicy Entropy: 5.28694\nValue Function Loss: 0.07858\n\nMean KL Divergence: 0.00083\nSB3 Clip Fraction: 0.03350\nPolicy Update Magnitude: 0.19863\nValue Function Update Magnitude: 0.08898\n\nCollected Steps per Second: 1,737.47251\nOverall Steps per Second: 1,242.93647\n\nTimestep Collection Time: 23.02195\nTimestep Consumption Time: 9.15991\nPPO Batch Consumption Time: 0.98991\nTotal Iteration Time: 32.18185\n\nCumulative Model Updates: 18,155\nCumulative Timesteps: 90,922,364\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 70.33676\nPolicy Entropy: 5.27501\nValue Function Loss: 0.07957\n\nMean KL Divergence: 0.00076\nSB3 Clip Fraction: 0.02944\nPolicy Update Magnitude: 0.20082\nValue Function Update Magnitude: 0.08657\n\nCollected Steps per Second: 1,705.80021\nOverall Steps per Second: 1,223.56390\n\nTimestep Collection Time: 23.44941\nTimestep Consumption Time: 9.24198\nPPO Batch Consumption Time: 0.99186\nTotal Iteration Time: 32.69139\n\nCumulative Model Updates: 18,163\nCumulative Timesteps: 90,962,364\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 101.87556\nPolicy Entropy: 5.30991\nValue Function Loss: 0.07767\n\nMean KL Divergence: 0.00068\nSB3 Clip Fraction: 0.02549\nPolicy Update Magnitude: 0.19663\nValue Function Update Magnitude: 0.10422\n\nCollected Steps per Second: 1,627.25823\nOverall Steps per Second: 1,184.88082\n\nTimestep Collection Time: 24.58122\nTimestep Consumption Time: 9.17744\nPPO Batch Consumption Time: 0.98737\nTotal Iteration Time: 33.75867\n\nCumulative Model Updates: 18,171\nCumulative Timesteps: 91,002,364\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 91002364...\nCheckpoint 91002364 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 103.29005\nPolicy Entropy: 5.31408\nValue Function Loss: 0.07876\n\nMean KL Divergence: 0.00076\nSB3 Clip Fraction: 0.02899\nPolicy Update Magnitude: 0.19954\nValue Function Update Magnitude: 0.11595\n\nCollected Steps per Second: 1,648.78602\nOverall Steps per Second: 1,194.27900\n\nTimestep Collection Time: 24.26149\nTimestep Consumption Time: 9.23320\nPPO Batch Consumption Time: 0.99678\nTotal Iteration Time: 33.49469\n\nCumulative Model Updates: 18,179\nCumulative Timesteps: 91,042,366\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 93.81515\nPolicy Entropy: 5.27960\nValue Function Loss: 0.08122\n\nMean KL Divergence: 0.00084\nSB3 Clip Fraction: 0.03384\nPolicy Update Magnitude: 0.19500\nValue Function Update Magnitude: 0.11031\n\nCollected Steps per Second: 1,630.49519\nOverall Steps per Second: 1,202.67767\n\nTimestep Collection Time: 24.53365\nTimestep Consumption Time: 8.72713\nPPO Batch Consumption Time: 0.96786\nTotal Iteration Time: 33.26078\n\nCumulative Model Updates: 18,187\nCumulative Timesteps: 91,082,368\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 114.29872\nPolicy Entropy: 5.28348\nValue Function Loss: 0.08045\n\nMean KL Divergence: 0.00084\nSB3 Clip Fraction: 0.03317\nPolicy Update Magnitude: 0.19264\nValue Function Update Magnitude: 0.10774\n\nCollected Steps per Second: 1,637.33708\nOverall Steps per Second: 1,203.26892\n\nTimestep Collection Time: 24.43113\nTimestep Consumption Time: 8.81331\nPPO Batch Consumption Time: 0.98459\nTotal Iteration Time: 33.24444\n\nCumulative Model Updates: 18,195\nCumulative Timesteps: 91,122,370\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 99.85983\nPolicy Entropy: 5.28518\nValue Function Loss: 0.08122\n\nMean KL Divergence: 0.00079\nSB3 Clip Fraction: 0.03165\nPolicy Update Magnitude: 0.20989\nValue Function Update Magnitude: 0.09214\n\nCollected Steps per Second: 1,626.17312\nOverall Steps per Second: 1,198.39158\n\nTimestep Collection Time: 24.59886\nTimestep Consumption Time: 8.78088\nPPO Batch Consumption Time: 0.97900\nTotal Iteration Time: 33.37974\n\nCumulative Model Updates: 18,203\nCumulative Timesteps: 91,162,372\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 100.56004\nPolicy Entropy: 5.28789\nValue Function Loss: 0.08025\n\nMean KL Divergence: 0.00075\nSB3 Clip Fraction: 0.02311\nPolicy Update Magnitude: 0.21220\nValue Function Update Magnitude: 0.09089\n\nCollected Steps per Second: 1,648.81503\nOverall Steps per Second: 1,211.02055\n\nTimestep Collection Time: 24.26106\nTimestep Consumption Time: 8.77058\nPPO Batch Consumption Time: 0.98341\nTotal Iteration Time: 33.03164\n\nCumulative Model Updates: 18,211\nCumulative Timesteps: 91,202,374\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 95.18421\nPolicy Entropy: 5.28700\nValue Function Loss: 0.07496\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.02701\nPolicy Update Magnitude: 0.20740\nValue Function Update Magnitude: 0.09626\n\nCollected Steps per Second: 1,684.63701\nOverall Steps per Second: 1,226.48477\n\nTimestep Collection Time: 23.74517\nTimestep Consumption Time: 8.86999\nPPO Batch Consumption Time: 0.99367\nTotal Iteration Time: 32.61516\n\nCumulative Model Updates: 18,219\nCumulative Timesteps: 91,242,376\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 70.37064\nPolicy Entropy: 5.29656\nValue Function Loss: 0.07419\n\nMean KL Divergence: 0.00099\nSB3 Clip Fraction: 0.04175\nPolicy Update Magnitude: 0.19346\nValue Function Update Magnitude: 0.09387\n\nCollected Steps per Second: 1,650.98052\nOverall Steps per Second: 1,205.19427\n\nTimestep Collection Time: 24.22803\nTimestep Consumption Time: 8.96164\nPPO Batch Consumption Time: 0.99847\nTotal Iteration Time: 33.18967\n\nCumulative Model Updates: 18,227\nCumulative Timesteps: 91,282,376\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 70.70934\nPolicy Entropy: 5.30747\nValue Function Loss: 0.07612\n\nMean KL Divergence: 0.00073\nSB3 Clip Fraction: 0.02790\nPolicy Update Magnitude: 0.19617\nValue Function Update Magnitude: 0.10028\n\nCollected Steps per Second: 1,631.40023\nOverall Steps per Second: 1,197.23640\n\nTimestep Collection Time: 24.52004\nTimestep Consumption Time: 8.89191\nPPO Batch Consumption Time: 0.99275\nTotal Iteration Time: 33.41195\n\nCumulative Model Updates: 18,235\nCumulative Timesteps: 91,322,378\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 92.98662\nPolicy Entropy: 5.30525\nValue Function Loss: 0.07838\n\nMean KL Divergence: 0.00079\nSB3 Clip Fraction: 0.03191\nPolicy Update Magnitude: 0.19745\nValue Function Update Magnitude: 0.09488\n\nCollected Steps per Second: 1,671.21615\nOverall Steps per Second: 1,225.07675\n\nTimestep Collection Time: 23.93467\nTimestep Consumption Time: 8.71635\nPPO Batch Consumption Time: 0.96581\nTotal Iteration Time: 32.65102\n\nCumulative Model Updates: 18,243\nCumulative Timesteps: 91,362,378\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 132.70151\nPolicy Entropy: 5.29858\nValue Function Loss: 0.07950\n\nMean KL Divergence: 0.00066\nSB3 Clip Fraction: 0.02541\nPolicy Update Magnitude: 0.19437\nValue Function Update Magnitude: 0.09988\n\nCollected Steps per Second: 1,673.92456\nOverall Steps per Second: 1,221.23928\n\nTimestep Collection Time: 23.89594\nTimestep Consumption Time: 8.85767\nPPO Batch Consumption Time: 0.97521\nTotal Iteration Time: 32.75361\n\nCumulative Model Updates: 18,251\nCumulative Timesteps: 91,402,378\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 99.02558\nPolicy Entropy: 5.31425\nValue Function Loss: 0.08041\n\nMean KL Divergence: 0.00073\nSB3 Clip Fraction: 0.02865\nPolicy Update Magnitude: 0.19685\nValue Function Update Magnitude: 0.09815\n\nCollected Steps per Second: 1,641.29235\nOverall Steps per Second: 1,205.67129\n\nTimestep Collection Time: 24.37226\nTimestep Consumption Time: 8.80594\nPPO Batch Consumption Time: 0.97891\nTotal Iteration Time: 33.17820\n\nCumulative Model Updates: 18,259\nCumulative Timesteps: 91,442,380\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 110.55183\nPolicy Entropy: 5.30314\nValue Function Loss: 0.07530\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02830\nPolicy Update Magnitude: 0.20675\nValue Function Update Magnitude: 0.09843\n\nCollected Steps per Second: 1,613.94296\nOverall Steps per Second: 1,187.38278\n\nTimestep Collection Time: 24.78526\nTimestep Consumption Time: 8.90396\nPPO Batch Consumption Time: 0.99294\nTotal Iteration Time: 33.68922\n\nCumulative Model Updates: 18,267\nCumulative Timesteps: 91,482,382\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 96.25051\nPolicy Entropy: 5.29332\nValue Function Loss: 0.07142\n\nMean KL Divergence: 0.00076\nSB3 Clip Fraction: 0.02968\nPolicy Update Magnitude: 0.20915\nValue Function Update Magnitude: 0.08867\n\nCollected Steps per Second: 1,587.74783\nOverall Steps per Second: 1,176.19848\n\nTimestep Collection Time: 25.19418\nTimestep Consumption Time: 8.81539\nPPO Batch Consumption Time: 0.98465\nTotal Iteration Time: 34.00957\n\nCumulative Model Updates: 18,275\nCumulative Timesteps: 91,522,384\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 91522384...\nCheckpoint 91522384 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 118.18513\nPolicy Entropy: 5.29645\nValue Function Loss: 0.07347\n\nMean KL Divergence: 0.00068\nSB3 Clip Fraction: 0.02627\nPolicy Update Magnitude: 0.20105\nValue Function Update Magnitude: 0.08499\n\nCollected Steps per Second: 1,576.58048\nOverall Steps per Second: 1,162.02950\n\nTimestep Collection Time: 25.37137\nTimestep Consumption Time: 9.05117\nPPO Batch Consumption Time: 1.01267\nTotal Iteration Time: 34.42253\n\nCumulative Model Updates: 18,283\nCumulative Timesteps: 91,562,384\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 77.26775\nPolicy Entropy: 5.31599\nValue Function Loss: 0.07253\n\nMean KL Divergence: 0.00084\nSB3 Clip Fraction: 0.03312\nPolicy Update Magnitude: 0.19649\nValue Function Update Magnitude: 0.09639\n\nCollected Steps per Second: 1,550.70485\nOverall Steps per Second: 1,136.73665\n\nTimestep Collection Time: 25.79601\nTimestep Consumption Time: 9.39420\nPPO Batch Consumption Time: 1.00523\nTotal Iteration Time: 35.19021\n\nCumulative Model Updates: 18,291\nCumulative Timesteps: 91,602,386\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 110.60693\nPolicy Entropy: 5.32514\nValue Function Loss: 0.07238\n\nMean KL Divergence: 0.00056\nSB3 Clip Fraction: 0.02000\nPolicy Update Magnitude: 0.20461\nValue Function Update Magnitude: 0.09603\n\nCollected Steps per Second: 1,617.06182\nOverall Steps per Second: 1,161.69329\n\nTimestep Collection Time: 24.73622\nTimestep Consumption Time: 9.69627\nPPO Batch Consumption Time: 1.04764\nTotal Iteration Time: 34.43250\n\nCumulative Model Updates: 18,299\nCumulative Timesteps: 91,642,386\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 85.26300\nPolicy Entropy: 5.32885\nValue Function Loss: 0.07196\n\nMean KL Divergence: 0.00067\nSB3 Clip Fraction: 0.02491\nPolicy Update Magnitude: 0.20811\nValue Function Update Magnitude: 0.09088\n\nCollected Steps per Second: 1,625.57999\nOverall Steps per Second: 1,179.37516\n\nTimestep Collection Time: 24.60783\nTimestep Consumption Time: 9.31013\nPPO Batch Consumption Time: 0.99101\nTotal Iteration Time: 33.91796\n\nCumulative Model Updates: 18,307\nCumulative Timesteps: 91,682,388\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 100.89400\nPolicy Entropy: 5.31362\nValue Function Loss: 0.07675\n\nMean KL Divergence: 0.00062\nSB3 Clip Fraction: 0.02126\nPolicy Update Magnitude: 0.19767\nValue Function Update Magnitude: 0.08430\n\nCollected Steps per Second: 1,571.48669\nOverall Steps per Second: 1,153.84076\n\nTimestep Collection Time: 25.45360\nTimestep Consumption Time: 9.21322\nPPO Batch Consumption Time: 0.99004\nTotal Iteration Time: 34.66683\n\nCumulative Model Updates: 18,315\nCumulative Timesteps: 91,722,388\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 109.90249\nPolicy Entropy: 5.31581\nValue Function Loss: 0.07837\n\nMean KL Divergence: 0.00062\nSB3 Clip Fraction: 0.02281\nPolicy Update Magnitude: 0.19184\nValue Function Update Magnitude: 0.08247\n\nCollected Steps per Second: 1,635.21783\nOverall Steps per Second: 1,192.39926\n\nTimestep Collection Time: 24.46280\nTimestep Consumption Time: 9.08469\nPPO Batch Consumption Time: 0.97646\nTotal Iteration Time: 33.54749\n\nCumulative Model Updates: 18,323\nCumulative Timesteps: 91,762,390\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 108.34177\nPolicy Entropy: 5.31532\nValue Function Loss: 0.07565\n\nMean KL Divergence: 0.00069\nSB3 Clip Fraction: 0.02536\nPolicy Update Magnitude: 0.19043\nValue Function Update Magnitude: 0.08592\n\nCollected Steps per Second: 1,668.88540\nOverall Steps per Second: 1,208.85015\n\nTimestep Collection Time: 23.96929\nTimestep Consumption Time: 9.12166\nPPO Batch Consumption Time: 0.97548\nTotal Iteration Time: 33.09095\n\nCumulative Model Updates: 18,331\nCumulative Timesteps: 91,802,392\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 101.82927\nPolicy Entropy: 5.31221\nValue Function Loss: 0.07620\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.02803\nPolicy Update Magnitude: 0.19265\nValue Function Update Magnitude: 0.09238\n\nCollected Steps per Second: 1,743.81198\nOverall Steps per Second: 1,253.63868\n\nTimestep Collection Time: 22.93940\nTimestep Consumption Time: 8.96932\nPPO Batch Consumption Time: 0.96466\nTotal Iteration Time: 31.90872\n\nCumulative Model Updates: 18,339\nCumulative Timesteps: 91,842,394\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 119.18420\nPolicy Entropy: 5.30238\nValue Function Loss: 0.07667\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.02796\nPolicy Update Magnitude: 0.18947\nValue Function Update Magnitude: 0.08727\n\nCollected Steps per Second: 1,668.28891\nOverall Steps per Second: 1,209.04625\n\nTimestep Collection Time: 23.97786\nTimestep Consumption Time: 9.10772\nPPO Batch Consumption Time: 0.98218\nTotal Iteration Time: 33.08558\n\nCumulative Model Updates: 18,347\nCumulative Timesteps: 91,882,396\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 115.23089\nPolicy Entropy: 5.31189\nValue Function Loss: 0.07468\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02734\nPolicy Update Magnitude: 0.18472\nValue Function Update Magnitude: 0.08198\n\nCollected Steps per Second: 1,707.86722\nOverall Steps per Second: 1,231.96226\n\nTimestep Collection Time: 23.42220\nTimestep Consumption Time: 9.04795\nPPO Batch Consumption Time: 0.97321\nTotal Iteration Time: 32.47015\n\nCumulative Model Updates: 18,355\nCumulative Timesteps: 91,922,398\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 101.79670\nPolicy Entropy: 5.32240\nValue Function Loss: 0.07286\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.02777\nPolicy Update Magnitude: 0.19284\nValue Function Update Magnitude: 0.08614\n\nCollected Steps per Second: 1,642.72705\nOverall Steps per Second: 1,195.57753\n\nTimestep Collection Time: 24.34975\nTimestep Consumption Time: 9.10688\nPPO Batch Consumption Time: 0.98377\nTotal Iteration Time: 33.45663\n\nCumulative Model Updates: 18,363\nCumulative Timesteps: 91,962,398\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 119.30001\nPolicy Entropy: 5.31349\nValue Function Loss: 0.07366\n\nMean KL Divergence: 0.00082\nSB3 Clip Fraction: 0.03080\nPolicy Update Magnitude: 0.19059\nValue Function Update Magnitude: 0.08675\n\nCollected Steps per Second: 1,684.16920\nOverall Steps per Second: 1,220.66987\n\nTimestep Collection Time: 23.75058\nTimestep Consumption Time: 9.01831\nPPO Batch Consumption Time: 0.96734\nTotal Iteration Time: 32.76889\n\nCumulative Model Updates: 18,371\nCumulative Timesteps: 92,002,398\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 86.40270\nPolicy Entropy: 5.30937\nValue Function Loss: 0.07311\n\nMean KL Divergence: 0.00080\nSB3 Clip Fraction: 0.03131\nPolicy Update Magnitude: 0.18781\nValue Function Update Magnitude: 0.07925\n\nCollected Steps per Second: 1,695.52348\nOverall Steps per Second: 1,209.99753\n\nTimestep Collection Time: 23.59271\nTimestep Consumption Time: 9.46686\nPPO Batch Consumption Time: 1.02143\nTotal Iteration Time: 33.05957\n\nCumulative Model Updates: 18,379\nCumulative Timesteps: 92,042,400\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 92042400...\nCheckpoint 92042400 saved!\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 100.65468\nPolicy Entropy: 5.33081\nValue Function Loss: 0.07418\n\nMean KL Divergence: 0.00058\nSB3 Clip Fraction: 0.02044\nPolicy Update Magnitude: 0.19579\nValue Function Update Magnitude: 0.08124\n\nCollected Steps per Second: 1,693.28881\nOverall Steps per Second: 1,209.29896\n\nTimestep Collection Time: 23.62267\nTimestep Consumption Time: 9.45435\nPPO Batch Consumption Time: 1.01329\nTotal Iteration Time: 33.07702\n\nCumulative Model Updates: 18,387\nCumulative Timesteps: 92,082,400\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 112.34836\nPolicy Entropy: 5.31076\nValue Function Loss: 0.07360\n\nMean KL Divergence: 0.00081\nSB3 Clip Fraction: 0.03234\nPolicy Update Magnitude: 0.20131\nValue Function Update Magnitude: 0.08918\n\nCollected Steps per Second: 1,600.49075\nOverall Steps per Second: 1,170.23498\n\nTimestep Collection Time: 24.99358\nTimestep Consumption Time: 9.18929\nPPO Batch Consumption Time: 0.99068\nTotal Iteration Time: 34.18288\n\nCumulative Model Updates: 18,395\nCumulative Timesteps: 92,122,402\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 103.27438\nPolicy Entropy: 5.30988\nValue Function Loss: 0.07131\n\nMean KL Divergence: 0.00082\nSB3 Clip Fraction: 0.03080\nPolicy Update Magnitude: 0.20322\nValue Function Update Magnitude: 0.08655\n\nCollected Steps per Second: 1,625.20392\nOverall Steps per Second: 1,177.73194\n\nTimestep Collection Time: 24.61230\nTimestep Consumption Time: 9.35129\nPPO Batch Consumption Time: 1.00629\nTotal Iteration Time: 33.96359\n\nCumulative Model Updates: 18,403\nCumulative Timesteps: 92,162,402\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 88.87982\nPolicy Entropy: 5.30204\nValue Function Loss: 0.07547\n\nMean KL Divergence: 0.00076\nSB3 Clip Fraction: 0.02795\nPolicy Update Magnitude: 0.19635\nValue Function Update Magnitude: 0.08091\n\nCollected Steps per Second: 1,640.96574\nOverall Steps per Second: 1,189.45510\n\nTimestep Collection Time: 24.37589\nTimestep Consumption Time: 9.25295\nPPO Batch Consumption Time: 0.99846\nTotal Iteration Time: 33.62884\n\nCumulative Model Updates: 18,411\nCumulative Timesteps: 92,202,402\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 107.14951\nPolicy Entropy: 5.31266\nValue Function Loss: 0.07294\n\nMean KL Divergence: 0.00066\nSB3 Clip Fraction: 0.02466\nPolicy Update Magnitude: 0.19745\nValue Function Update Magnitude: 0.08672\n\nCollected Steps per Second: 1,507.15507\nOverall Steps per Second: 1,126.18757\n\nTimestep Collection Time: 26.54140\nTimestep Consumption Time: 8.97844\nPPO Batch Consumption Time: 0.99632\nTotal Iteration Time: 35.51984\n\nCumulative Model Updates: 18,419\nCumulative Timesteps: 92,242,404\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 106.46135\nPolicy Entropy: 5.31445\nValue Function Loss: 0.07028\n\nMean KL Divergence: 0.00068\nSB3 Clip Fraction: 0.02559\nPolicy Update Magnitude: 0.20549\nValue Function Update Magnitude: 0.08783\n\nCollected Steps per Second: 1,612.70145\nOverall Steps per Second: 1,182.37456\n\nTimestep Collection Time: 24.80558\nTimestep Consumption Time: 9.02803\nPPO Batch Consumption Time: 0.99862\nTotal Iteration Time: 33.83361\n\nCumulative Model Updates: 18,427\nCumulative Timesteps: 92,282,408\n\nTimesteps Collected: 40,004\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 76.32657\nPolicy Entropy: 5.32150\nValue Function Loss: 0.07270\n\nMean KL Divergence: 0.00099\nSB3 Clip Fraction: 0.02651\nPolicy Update Magnitude: 0.21559\nValue Function Update Magnitude: 0.08862\n\nCollected Steps per Second: 1,620.99552\nOverall Steps per Second: 1,190.55811\n\nTimestep Collection Time: 24.67743\nTimestep Consumption Time: 8.92194\nPPO Batch Consumption Time: 0.98768\nTotal Iteration Time: 33.59937\n\nCumulative Model Updates: 18,435\nCumulative Timesteps: 92,322,410\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 83.34903\nPolicy Entropy: 5.34893\nValue Function Loss: 0.07314\n\nMean KL Divergence: 0.00059\nSB3 Clip Fraction: 0.02029\nPolicy Update Magnitude: 0.20830\nValue Function Update Magnitude: 0.09139\n\nCollected Steps per Second: 1,668.81968\nOverall Steps per Second: 1,220.89814\n\nTimestep Collection Time: 23.97023\nTimestep Consumption Time: 8.79417\nPPO Batch Consumption Time: 0.97780\nTotal Iteration Time: 32.76440\n\nCumulative Model Updates: 18,443\nCumulative Timesteps: 92,362,412\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 102.56192\nPolicy Entropy: 5.35202\nValue Function Loss: 0.07182\n\nMean KL Divergence: 0.00067\nSB3 Clip Fraction: 0.02491\nPolicy Update Magnitude: 0.20324\nValue Function Update Magnitude: 0.09431\n\nCollected Steps per Second: 1,654.08520\nOverall Steps per Second: 1,212.87831\n\nTimestep Collection Time: 24.18376\nTimestep Consumption Time: 8.79729\nPPO Batch Consumption Time: 0.98372\nTotal Iteration Time: 32.98105\n\nCumulative Model Updates: 18,451\nCumulative Timesteps: 92,402,414\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 126.54968\nPolicy Entropy: 5.32665\nValue Function Loss: 0.07343\n\nMean KL Divergence: 0.00067\nSB3 Clip Fraction: 0.02399\nPolicy Update Magnitude: 0.19848\nValue Function Update Magnitude: 0.08517\n\nCollected Steps per Second: 1,671.02519\nOverall Steps per Second: 1,223.38228\n\nTimestep Collection Time: 23.93740\nTimestep Consumption Time: 8.75884\nPPO Batch Consumption Time: 0.98003\nTotal Iteration Time: 32.69624\n\nCumulative Model Updates: 18,459\nCumulative Timesteps: 92,442,414\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 107.99596\nPolicy Entropy: 5.32570\nValue Function Loss: 0.07788\n\nMean KL Divergence: 0.00076\nSB3 Clip Fraction: 0.02971\nPolicy Update Magnitude: 0.20599\nValue Function Update Magnitude: 0.09612\n\nCollected Steps per Second: 1,642.36987\nOverall Steps per Second: 1,198.74159\n\nTimestep Collection Time: 24.35627\nTimestep Consumption Time: 9.01373\nPPO Batch Consumption Time: 1.00544\nTotal Iteration Time: 33.36999\n\nCumulative Model Updates: 18,467\nCumulative Timesteps: 92,482,416\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 101.40226\nPolicy Entropy: 5.31728\nValue Function Loss: 0.07532\n\nMean KL Divergence: 0.00078\nSB3 Clip Fraction: 0.03114\nPolicy Update Magnitude: 0.20499\nValue Function Update Magnitude: 0.09030\n\nCollected Steps per Second: 1,651.58777\nOverall Steps per Second: 1,207.73081\n\nTimestep Collection Time: 24.22033\nTimestep Consumption Time: 8.90129\nPPO Batch Consumption Time: 0.98550\nTotal Iteration Time: 33.12162\n\nCumulative Model Updates: 18,475\nCumulative Timesteps: 92,522,418\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 104.14992\nPolicy Entropy: 5.33311\nValue Function Loss: 0.07248\n\nMean KL Divergence: 0.00084\nSB3 Clip Fraction: 0.03216\nPolicy Update Magnitude: 0.20377\nValue Function Update Magnitude: 0.08532\n\nCollected Steps per Second: 1,474.55767\nOverall Steps per Second: 1,095.64314\n\nTimestep Collection Time: 27.12678\nTimestep Consumption Time: 9.38146\nPPO Batch Consumption Time: 1.05031\nTotal Iteration Time: 36.50824\n\nCumulative Model Updates: 18,483\nCumulative Timesteps: 92,562,418\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 92562418...\nCheckpoint 92562418 saved!\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 106.40650\nPolicy Entropy: 5.30829\nValue Function Loss: 0.07191\n\nMean KL Divergence: 0.00068\nSB3 Clip Fraction: 0.02350\nPolicy Update Magnitude: 0.19939\nValue Function Update Magnitude: 0.08000\n\nCollected Steps per Second: 1,461.44409\nOverall Steps per Second: 1,096.13309\n\nTimestep Collection Time: 27.37156\nTimestep Consumption Time: 9.12219\nPPO Batch Consumption Time: 1.01695\nTotal Iteration Time: 36.49374\n\nCumulative Model Updates: 18,491\nCumulative Timesteps: 92,602,420\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 74.30309\nPolicy Entropy: 5.31555\nValue Function Loss: 0.07063\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02766\nPolicy Update Magnitude: 0.19452\nValue Function Update Magnitude: 0.07872\n\nCollected Steps per Second: 1,557.33490\nOverall Steps per Second: 1,151.68175\n\nTimestep Collection Time: 25.68619\nTimestep Consumption Time: 9.04736\nPPO Batch Consumption Time: 1.00701\nTotal Iteration Time: 34.73355\n\nCumulative Model Updates: 18,499\nCumulative Timesteps: 92,642,422\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 87.21350\nPolicy Entropy: 5.32250\nValue Function Loss: 0.07462\n\nMean KL Divergence: 0.00064\nSB3 Clip Fraction: 0.02284\nPolicy Update Magnitude: 0.19944\nValue Function Update Magnitude: 0.08410\n\nCollected Steps per Second: 1,677.92919\nOverall Steps per Second: 1,224.29525\n\nTimestep Collection Time: 23.83891\nTimestep Consumption Time: 8.83295\nPPO Batch Consumption Time: 0.98045\nTotal Iteration Time: 32.67186\n\nCumulative Model Updates: 18,507\nCumulative Timesteps: 92,682,422\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 115.33175\nPolicy Entropy: 5.32220\nValue Function Loss: 0.07369\n\nMean KL Divergence: 0.00066\nSB3 Clip Fraction: 0.02428\nPolicy Update Magnitude: 0.19923\nValue Function Update Magnitude: 0.08440\n\nCollected Steps per Second: 1,639.49400\nOverall Steps per Second: 1,202.01775\n\nTimestep Collection Time: 24.39777\nTimestep Consumption Time: 8.87961\nPPO Batch Consumption Time: 0.99181\nTotal Iteration Time: 33.27738\n\nCumulative Model Updates: 18,515\nCumulative Timesteps: 92,722,422\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 119.34460\nPolicy Entropy: 5.34814\nValue Function Loss: 0.06846\n\nMean KL Divergence: 0.00068\nSB3 Clip Fraction: 0.02525\nPolicy Update Magnitude: 0.19169\nValue Function Update Magnitude: 0.08578\n\nCollected Steps per Second: 1,658.08669\nOverall Steps per Second: 1,198.61923\n\nTimestep Collection Time: 24.12419\nTimestep Consumption Time: 9.24754\nPPO Batch Consumption Time: 0.99801\nTotal Iteration Time: 33.37173\n\nCumulative Model Updates: 18,523\nCumulative Timesteps: 92,762,422\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 108.59878\nPolicy Entropy: 5.37103\nValue Function Loss: 0.06788\n\nMean KL Divergence: 0.00053\nSB3 Clip Fraction: 0.01827\nPolicy Update Magnitude: 0.18566\nValue Function Update Magnitude: 0.07991\n\nCollected Steps per Second: 1,732.09798\nOverall Steps per Second: 1,247.41196\n\nTimestep Collection Time: 23.09454\nTimestep Consumption Time: 8.97346\nPPO Batch Consumption Time: 0.97116\nTotal Iteration Time: 32.06799\n\nCumulative Model Updates: 18,531\nCumulative Timesteps: 92,802,424\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 94.40576\nPolicy Entropy: 5.35572\nValue Function Loss: 0.06961\n\nMean KL Divergence: 0.00059\nSB3 Clip Fraction: 0.02169\nPolicy Update Magnitude: 0.19964\nValue Function Update Magnitude: 0.08285\n\nCollected Steps per Second: 1,661.72984\nOverall Steps per Second: 1,203.14926\n\nTimestep Collection Time: 24.07250\nTimestep Consumption Time: 9.17524\nPPO Batch Consumption Time: 0.98560\nTotal Iteration Time: 33.24775\n\nCumulative Model Updates: 18,539\nCumulative Timesteps: 92,842,426\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 74.79730\nPolicy Entropy: 5.35015\nValue Function Loss: 0.06982\n\nMean KL Divergence: 0.00063\nSB3 Clip Fraction: 0.02156\nPolicy Update Magnitude: 0.20746\nValue Function Update Magnitude: 0.08521\n\nCollected Steps per Second: 1,674.36515\nOverall Steps per Second: 1,209.18777\n\nTimestep Collection Time: 23.89085\nTimestep Consumption Time: 9.19086\nPPO Batch Consumption Time: 0.99096\nTotal Iteration Time: 33.08171\n\nCumulative Model Updates: 18,547\nCumulative Timesteps: 92,882,428\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 91.87519\nPolicy Entropy: 5.35067\nValue Function Loss: 0.07145\n\nMean KL Divergence: 0.00064\nSB3 Clip Fraction: 0.02465\nPolicy Update Magnitude: 0.20269\nValue Function Update Magnitude: 0.08803\n\nCollected Steps per Second: 1,700.80318\nOverall Steps per Second: 1,222.82154\n\nTimestep Collection Time: 23.51830\nTimestep Consumption Time: 9.19293\nPPO Batch Consumption Time: 0.99195\nTotal Iteration Time: 32.71123\n\nCumulative Model Updates: 18,555\nCumulative Timesteps: 92,922,428\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 92.89246\nPolicy Entropy: 5.34163\nValue Function Loss: 0.07285\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.03139\nPolicy Update Magnitude: 0.20162\nValue Function Update Magnitude: 0.09155\n\nCollected Steps per Second: 1,702.31584\nOverall Steps per Second: 1,227.82302\n\nTimestep Collection Time: 23.49740\nTimestep Consumption Time: 9.08058\nPPO Batch Consumption Time: 0.97907\nTotal Iteration Time: 32.57799\n\nCumulative Model Updates: 18,563\nCumulative Timesteps: 92,962,428\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 119.69381\nPolicy Entropy: 5.33669\nValue Function Loss: 0.07223\n\nMean KL Divergence: 0.00070\nSB3 Clip Fraction: 0.02637\nPolicy Update Magnitude: 0.19648\nValue Function Update Magnitude: 0.08793\n\nCollected Steps per Second: 1,698.81269\nOverall Steps per Second: 1,234.49392\n\nTimestep Collection Time: 23.54586\nTimestep Consumption Time: 8.85609\nPPO Batch Consumption Time: 0.99199\nTotal Iteration Time: 32.40194\n\nCumulative Model Updates: 18,571\nCumulative Timesteps: 93,002,428\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 88.90542\nPolicy Entropy: 5.36652\nValue Function Loss: 0.06911\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.02969\nPolicy Update Magnitude: 0.19590\nValue Function Update Magnitude: 0.09506\n\nCollected Steps per Second: 1,709.22929\nOverall Steps per Second: 1,237.91527\n\nTimestep Collection Time: 23.40236\nTimestep Consumption Time: 8.91003\nPPO Batch Consumption Time: 0.99736\nTotal Iteration Time: 32.31239\n\nCumulative Model Updates: 18,579\nCumulative Timesteps: 93,042,428\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 101.35303\nPolicy Entropy: 5.37888\nValue Function Loss: 0.07012\n\nMean KL Divergence: 0.00067\nSB3 Clip Fraction: 0.02480\nPolicy Update Magnitude: 0.20493\nValue Function Update Magnitude: 0.09972\n\nCollected Steps per Second: 1,724.05218\nOverall Steps per Second: 1,259.01195\n\nTimestep Collection Time: 23.20231\nTimestep Consumption Time: 8.57022\nPPO Batch Consumption Time: 0.94932\nTotal Iteration Time: 31.77253\n\nCumulative Model Updates: 18,587\nCumulative Timesteps: 93,082,430\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 93082430...\nCheckpoint 93082430 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 130.54782\nPolicy Entropy: 5.37554\nValue Function Loss: 0.07443\n\nMean KL Divergence: 0.00075\nSB3 Clip Fraction: 0.02493\nPolicy Update Magnitude: 0.21272\nValue Function Update Magnitude: 0.10453\n\nCollected Steps per Second: 1,709.27379\nOverall Steps per Second: 1,243.13741\n\nTimestep Collection Time: 23.40292\nTimestep Consumption Time: 8.77534\nPPO Batch Consumption Time: 0.97842\nTotal Iteration Time: 32.17826\n\nCumulative Model Updates: 18,595\nCumulative Timesteps: 93,122,432\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 47.26565\nPolicy Entropy: 5.38196\nValue Function Loss: 0.07432\n\nMean KL Divergence: 0.00063\nSB3 Clip Fraction: 0.02227\nPolicy Update Magnitude: 0.20673\nValue Function Update Magnitude: 0.09585\n\nCollected Steps per Second: 1,680.64118\nOverall Steps per Second: 1,226.75824\n\nTimestep Collection Time: 23.80044\nTimestep Consumption Time: 8.80582\nPPO Batch Consumption Time: 0.98119\nTotal Iteration Time: 32.60626\n\nCumulative Model Updates: 18,603\nCumulative Timesteps: 93,162,432\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 119.77184\nPolicy Entropy: 5.37418\nValue Function Loss: 0.07178\n\nMean KL Divergence: 0.00067\nSB3 Clip Fraction: 0.02456\nPolicy Update Magnitude: 0.20653\nValue Function Update Magnitude: 0.08721\n\nCollected Steps per Second: 1,665.34517\nOverall Steps per Second: 1,217.59014\n\nTimestep Collection Time: 24.02025\nTimestep Consumption Time: 8.83317\nPPO Batch Consumption Time: 0.98110\nTotal Iteration Time: 32.85342\n\nCumulative Model Updates: 18,611\nCumulative Timesteps: 93,202,434\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 112.27795\nPolicy Entropy: 5.36459\nValue Function Loss: 0.07294\n\nMean KL Divergence: 0.00068\nSB3 Clip Fraction: 0.02689\nPolicy Update Magnitude: 0.20899\nValue Function Update Magnitude: 0.08944\n\nCollected Steps per Second: 1,664.98045\nOverall Steps per Second: 1,212.78248\n\nTimestep Collection Time: 24.02551\nTimestep Consumption Time: 8.95815\nPPO Batch Consumption Time: 0.99847\nTotal Iteration Time: 32.98366\n\nCumulative Model Updates: 18,619\nCumulative Timesteps: 93,242,436\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 114.54166\nPolicy Entropy: 5.35437\nValue Function Loss: 0.07544\n\nMean KL Divergence: 0.00081\nSB3 Clip Fraction: 0.03207\nPolicy Update Magnitude: 0.20335\nValue Function Update Magnitude: 0.08697\n\nCollected Steps per Second: 1,663.37929\nOverall Steps per Second: 1,218.51943\n\nTimestep Collection Time: 24.04863\nTimestep Consumption Time: 8.77973\nPPO Batch Consumption Time: 0.97911\nTotal Iteration Time: 32.82836\n\nCumulative Model Updates: 18,627\nCumulative Timesteps: 93,282,438\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 123.33531\nPolicy Entropy: 5.33914\nValue Function Loss: 0.07301\n\nMean KL Divergence: 0.00083\nSB3 Clip Fraction: 0.03385\nPolicy Update Magnitude: 0.19703\nValue Function Update Magnitude: 0.08611\n\nCollected Steps per Second: 1,660.24087\nOverall Steps per Second: 1,222.81338\n\nTimestep Collection Time: 24.09409\nTimestep Consumption Time: 8.61899\nPPO Batch Consumption Time: 0.96206\nTotal Iteration Time: 32.71309\n\nCumulative Model Updates: 18,635\nCumulative Timesteps: 93,322,440\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 132.01089\nPolicy Entropy: 5.34637\nValue Function Loss: 0.06983\n\nMean KL Divergence: 0.00073\nSB3 Clip Fraction: 0.02856\nPolicy Update Magnitude: 0.19191\nValue Function Update Magnitude: 0.08616\n\nCollected Steps per Second: 1,682.44803\nOverall Steps per Second: 1,233.68027\n\nTimestep Collection Time: 23.77607\nTimestep Consumption Time: 8.64886\nPPO Batch Consumption Time: 0.96738\nTotal Iteration Time: 32.42493\n\nCumulative Model Updates: 18,643\nCumulative Timesteps: 93,362,442\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 105.11331\nPolicy Entropy: 5.35208\nValue Function Loss: 0.07163\n\nMean KL Divergence: 0.00064\nSB3 Clip Fraction: 0.02419\nPolicy Update Magnitude: 0.19819\nValue Function Update Magnitude: 0.08673\n\nCollected Steps per Second: 1,710.33837\nOverall Steps per Second: 1,242.79771\n\nTimestep Collection Time: 23.38835\nTimestep Consumption Time: 8.79870\nPPO Batch Consumption Time: 0.98209\nTotal Iteration Time: 32.18706\n\nCumulative Model Updates: 18,651\nCumulative Timesteps: 93,402,444\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 108.70355\nPolicy Entropy: 5.35762\nValue Function Loss: 0.07120\n\nMean KL Divergence: 0.00057\nSB3 Clip Fraction: 0.01960\nPolicy Update Magnitude: 0.19740\nValue Function Update Magnitude: 0.08904\n\nCollected Steps per Second: 1,693.93261\nOverall Steps per Second: 1,230.72812\n\nTimestep Collection Time: 23.61369\nTimestep Consumption Time: 8.88740\nPPO Batch Consumption Time: 0.98645\nTotal Iteration Time: 32.50109\n\nCumulative Model Updates: 18,659\nCumulative Timesteps: 93,442,444\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 82.30125\nPolicy Entropy: 5.36537\nValue Function Loss: 0.07392\n\nMean KL Divergence: 0.00070\nSB3 Clip Fraction: 0.02663\nPolicy Update Magnitude: 0.20064\nValue Function Update Magnitude: 0.08645\n\nCollected Steps per Second: 1,629.67489\nOverall Steps per Second: 1,197.10567\n\nTimestep Collection Time: 24.54477\nTimestep Consumption Time: 8.86915\nPPO Batch Consumption Time: 0.99648\nTotal Iteration Time: 33.41393\n\nCumulative Model Updates: 18,667\nCumulative Timesteps: 93,482,444\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 101.42274\nPolicy Entropy: 5.36032\nValue Function Loss: 0.07425\n\nMean KL Divergence: 0.00076\nSB3 Clip Fraction: 0.02961\nPolicy Update Magnitude: 0.19963\nValue Function Update Magnitude: 0.09255\n\nCollected Steps per Second: 1,605.75400\nOverall Steps per Second: 1,180.84208\n\nTimestep Collection Time: 24.91166\nTimestep Consumption Time: 8.96416\nPPO Batch Consumption Time: 1.00545\nTotal Iteration Time: 33.87583\n\nCumulative Model Updates: 18,675\nCumulative Timesteps: 93,522,446\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 70.57699\nPolicy Entropy: 5.35006\nValue Function Loss: 0.07183\n\nMean KL Divergence: 0.00075\nSB3 Clip Fraction: 0.02853\nPolicy Update Magnitude: 0.19746\nValue Function Update Magnitude: 0.09382\n\nCollected Steps per Second: 1,659.67614\nOverall Steps per Second: 1,215.79643\n\nTimestep Collection Time: 24.10109\nTimestep Consumption Time: 8.79916\nPPO Batch Consumption Time: 0.98460\nTotal Iteration Time: 32.90024\n\nCumulative Model Updates: 18,683\nCumulative Timesteps: 93,562,446\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 114.69739\nPolicy Entropy: 5.33547\nValue Function Loss: 0.07103\n\nMean KL Divergence: 0.00075\nSB3 Clip Fraction: 0.02900\nPolicy Update Magnitude: 0.19544\nValue Function Update Magnitude: 0.08978\n\nCollected Steps per Second: 1,650.93513\nOverall Steps per Second: 1,193.36517\n\nTimestep Collection Time: 24.22990\nTimestep Consumption Time: 9.29043\nPPO Batch Consumption Time: 1.00236\nTotal Iteration Time: 33.52033\n\nCumulative Model Updates: 18,691\nCumulative Timesteps: 93,602,448\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 93602448...\nCheckpoint 93602448 saved!\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 118.20206\nPolicy Entropy: 5.34629\nValue Function Loss: 0.06941\n\nMean KL Divergence: 0.00089\nSB3 Clip Fraction: 0.03615\nPolicy Update Magnitude: 0.19128\nValue Function Update Magnitude: 0.08927\n\nCollected Steps per Second: 1,608.31803\nOverall Steps per Second: 1,166.41909\n\nTimestep Collection Time: 24.87070\nTimestep Consumption Time: 9.42229\nPPO Batch Consumption Time: 1.01716\nTotal Iteration Time: 34.29299\n\nCumulative Model Updates: 18,699\nCumulative Timesteps: 93,642,448\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 102.65514\nPolicy Entropy: 5.34334\nValue Function Loss: 0.06883\n\nMean KL Divergence: 0.00066\nSB3 Clip Fraction: 0.02069\nPolicy Update Magnitude: 0.19663\nValue Function Update Magnitude: 0.08652\n\nCollected Steps per Second: 1,501.94821\nOverall Steps per Second: 1,116.10505\n\nTimestep Collection Time: 26.63341\nTimestep Consumption Time: 9.20730\nPPO Batch Consumption Time: 0.99450\nTotal Iteration Time: 35.84071\n\nCumulative Model Updates: 18,707\nCumulative Timesteps: 93,682,450\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 79.10249\nPolicy Entropy: 5.33709\nValue Function Loss: 0.06895\n\nMean KL Divergence: 0.00106\nSB3 Clip Fraction: 0.02706\nPolicy Update Magnitude: 0.20911\nValue Function Update Magnitude: 0.08693\n\nCollected Steps per Second: 1,567.13679\nOverall Steps per Second: 1,140.01401\n\nTimestep Collection Time: 25.52553\nTimestep Consumption Time: 9.56351\nPPO Batch Consumption Time: 1.01786\nTotal Iteration Time: 35.08904\n\nCumulative Model Updates: 18,715\nCumulative Timesteps: 93,722,452\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 81.06383\nPolicy Entropy: 5.34426\nValue Function Loss: 0.07020\n\nMean KL Divergence: 0.00390\nSB3 Clip Fraction: 0.02118\nPolicy Update Magnitude: 0.20708\nValue Function Update Magnitude: 0.09859\n\nCollected Steps per Second: 1,665.78029\nOverall Steps per Second: 1,207.09403\n\nTimestep Collection Time: 24.01397\nTimestep Consumption Time: 9.12512\nPPO Batch Consumption Time: 0.97907\nTotal Iteration Time: 33.13909\n\nCumulative Model Updates: 18,723\nCumulative Timesteps: 93,762,454\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 94.73406\nPolicy Entropy: 5.34392\nValue Function Loss: 0.07109\n\nMean KL Divergence: 0.00056\nSB3 Clip Fraction: 0.01959\nPolicy Update Magnitude: 0.20364\nValue Function Update Magnitude: 0.09709\n\nCollected Steps per Second: 1,741.42875\nOverall Steps per Second: 1,247.98561\n\nTimestep Collection Time: 22.96964\nTimestep Consumption Time: 9.08201\nPPO Batch Consumption Time: 0.98075\nTotal Iteration Time: 32.05165\n\nCumulative Model Updates: 18,731\nCumulative Timesteps: 93,802,454\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 107.06022\nPolicy Entropy: 5.32843\nValue Function Loss: 0.07201\n\nMean KL Divergence: 0.00056\nSB3 Clip Fraction: 0.01887\nPolicy Update Magnitude: 0.19733\nValue Function Update Magnitude: 0.09065\n\nCollected Steps per Second: 1,681.41532\nOverall Steps per Second: 1,215.94200\n\nTimestep Collection Time: 23.79067\nTimestep Consumption Time: 9.10728\nPPO Batch Consumption Time: 0.98196\nTotal Iteration Time: 32.89795\n\nCumulative Model Updates: 18,739\nCumulative Timesteps: 93,842,456\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 117.62079\nPolicy Entropy: 5.32363\nValue Function Loss: 0.07075\n\nMean KL Divergence: 0.00060\nSB3 Clip Fraction: 0.02114\nPolicy Update Magnitude: 0.19676\nValue Function Update Magnitude: 0.08715\n\nCollected Steps per Second: 1,719.74286\nOverall Steps per Second: 1,246.59197\n\nTimestep Collection Time: 23.25929\nTimestep Consumption Time: 8.82819\nPPO Batch Consumption Time: 0.98644\nTotal Iteration Time: 32.08748\n\nCumulative Model Updates: 18,747\nCumulative Timesteps: 93,882,456\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 114.84428\nPolicy Entropy: 5.33055\nValue Function Loss: 0.07021\n\nMean KL Divergence: 0.00063\nSB3 Clip Fraction: 0.02306\nPolicy Update Magnitude: 0.18690\nValue Function Update Magnitude: 0.08345\n\nCollected Steps per Second: 1,671.38012\nOverall Steps per Second: 1,221.14143\n\nTimestep Collection Time: 23.93232\nTimestep Consumption Time: 8.82392\nPPO Batch Consumption Time: 0.98443\nTotal Iteration Time: 32.75624\n\nCumulative Model Updates: 18,755\nCumulative Timesteps: 93,922,456\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 112.37106\nPolicy Entropy: 5.35728\nValue Function Loss: 0.06989\n\nMean KL Divergence: 0.00053\nSB3 Clip Fraction: 0.01779\nPolicy Update Magnitude: 0.18919\nValue Function Update Magnitude: 0.08677\n\nCollected Steps per Second: 1,652.34975\nOverall Steps per Second: 1,212.87471\n\nTimestep Collection Time: 24.20916\nTimestep Consumption Time: 8.77199\nPPO Batch Consumption Time: 0.97805\nTotal Iteration Time: 32.98115\n\nCumulative Model Updates: 18,763\nCumulative Timesteps: 93,962,458\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 104.86257\nPolicy Entropy: 5.36678\nValue Function Loss: 0.06822\n\nMean KL Divergence: 0.00054\nSB3 Clip Fraction: 0.01827\nPolicy Update Magnitude: 0.19856\nValue Function Update Magnitude: 0.08327\n\nCollected Steps per Second: 1,680.00679\nOverall Steps per Second: 1,232.52366\n\nTimestep Collection Time: 23.81062\nTimestep Consumption Time: 8.64474\nPPO Batch Consumption Time: 0.96475\nTotal Iteration Time: 32.45536\n\nCumulative Model Updates: 18,771\nCumulative Timesteps: 94,002,460\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 110.24601\nPolicy Entropy: 5.36024\nValue Function Loss: 0.06893\n\nMean KL Divergence: 0.00068\nSB3 Clip Fraction: 0.02535\nPolicy Update Magnitude: 0.19673\nValue Function Update Magnitude: 0.09012\n\nCollected Steps per Second: 1,608.84301\nOverall Steps per Second: 1,188.66924\n\nTimestep Collection Time: 24.86259\nTimestep Consumption Time: 8.78849\nPPO Batch Consumption Time: 0.97714\nTotal Iteration Time: 33.65108\n\nCumulative Model Updates: 18,779\nCumulative Timesteps: 94,042,460\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 115.77411\nPolicy Entropy: 5.36071\nValue Function Loss: 0.06843\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02797\nPolicy Update Magnitude: 0.20040\nValue Function Update Magnitude: 0.09224\n\nCollected Steps per Second: 1,644.93200\nOverall Steps per Second: 1,204.38133\n\nTimestep Collection Time: 24.31711\nTimestep Consumption Time: 8.89496\nPPO Batch Consumption Time: 0.99283\nTotal Iteration Time: 33.21207\n\nCumulative Model Updates: 18,787\nCumulative Timesteps: 94,082,460\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 64.07443\nPolicy Entropy: 5.35545\nValue Function Loss: 0.06793\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.03146\nPolicy Update Magnitude: 0.20203\nValue Function Update Magnitude: 0.08727\n\nCollected Steps per Second: 1,666.83433\nOverall Steps per Second: 1,220.91124\n\nTimestep Collection Time: 23.99759\nTimestep Consumption Time: 8.76483\nPPO Batch Consumption Time: 0.97562\nTotal Iteration Time: 32.76241\n\nCumulative Model Updates: 18,795\nCumulative Timesteps: 94,122,460\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 94122460...\nCheckpoint 94122460 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 98.61583\nPolicy Entropy: 5.35917\nValue Function Loss: 0.07032\n\nMean KL Divergence: 0.00088\nSB3 Clip Fraction: 0.03580\nPolicy Update Magnitude: 0.21041\nValue Function Update Magnitude: 0.08895\n\nCollected Steps per Second: 1,647.01756\nOverall Steps per Second: 1,207.85645\n\nTimestep Collection Time: 24.28632\nTimestep Consumption Time: 8.83020\nPPO Batch Consumption Time: 0.98197\nTotal Iteration Time: 33.11652\n\nCumulative Model Updates: 18,803\nCumulative Timesteps: 94,162,460\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 109.08704\nPolicy Entropy: 5.34523\nValue Function Loss: 0.07223\n\nMean KL Divergence: 0.00061\nSB3 Clip Fraction: 0.02115\nPolicy Update Magnitude: 0.21423\nValue Function Update Magnitude: 0.09613\n\nCollected Steps per Second: 1,677.34006\nOverall Steps per Second: 1,222.44047\n\nTimestep Collection Time: 23.84847\nTimestep Consumption Time: 8.87459\nPPO Batch Consumption Time: 0.98945\nTotal Iteration Time: 32.72307\n\nCumulative Model Updates: 18,811\nCumulative Timesteps: 94,202,462\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 128.39331\nPolicy Entropy: 5.34120\nValue Function Loss: 0.07010\n\nMean KL Divergence: 0.00071\nSB3 Clip Fraction: 0.02669\nPolicy Update Magnitude: 0.20743\nValue Function Update Magnitude: 0.10133\n\nCollected Steps per Second: 1,662.34983\nOverall Steps per Second: 1,215.68089\n\nTimestep Collection Time: 24.06232\nTimestep Consumption Time: 8.84105\nPPO Batch Consumption Time: 0.98595\nTotal Iteration Time: 32.90337\n\nCumulative Model Updates: 18,819\nCumulative Timesteps: 94,242,462\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 86.32169\nPolicy Entropy: 5.33855\nValue Function Loss: 0.07312\n\nMean KL Divergence: 0.00063\nSB3 Clip Fraction: 0.02216\nPolicy Update Magnitude: 0.20070\nValue Function Update Magnitude: 0.09917\n\nCollected Steps per Second: 1,657.50118\nOverall Steps per Second: 1,216.39277\n\nTimestep Collection Time: 24.13392\nTimestep Consumption Time: 8.75184\nPPO Batch Consumption Time: 0.97921\nTotal Iteration Time: 32.88576\n\nCumulative Model Updates: 18,827\nCumulative Timesteps: 94,282,464\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 103.85736\nPolicy Entropy: 5.35333\nValue Function Loss: 0.07336\n\nMean KL Divergence: 0.00057\nSB3 Clip Fraction: 0.02079\nPolicy Update Magnitude: 0.19308\nValue Function Update Magnitude: 0.09240\n\nCollected Steps per Second: 1,640.91930\nOverall Steps per Second: 1,203.12236\n\nTimestep Collection Time: 24.37780\nTimestep Consumption Time: 8.87069\nPPO Batch Consumption Time: 0.99049\nTotal Iteration Time: 33.24849\n\nCumulative Model Updates: 18,835\nCumulative Timesteps: 94,322,466\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 98.63032\nPolicy Entropy: 5.34195\nValue Function Loss: 0.06952\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.03001\nPolicy Update Magnitude: 0.18957\nValue Function Update Magnitude: 0.09133\n\nCollected Steps per Second: 1,672.48179\nOverall Steps per Second: 1,210.30514\n\nTimestep Collection Time: 23.91655\nTimestep Consumption Time: 9.13296\nPPO Batch Consumption Time: 0.97838\nTotal Iteration Time: 33.04952\n\nCumulative Model Updates: 18,843\nCumulative Timesteps: 94,362,466\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 123.87133\nPolicy Entropy: 5.34795\nValue Function Loss: 0.06841\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02686\nPolicy Update Magnitude: 0.19695\nValue Function Update Magnitude: 0.09416\n\nCollected Steps per Second: 1,698.34919\nOverall Steps per Second: 1,221.23819\n\nTimestep Collection Time: 23.55346\nTimestep Consumption Time: 9.20182\nPPO Batch Consumption Time: 0.99917\nTotal Iteration Time: 32.75528\n\nCumulative Model Updates: 18,851\nCumulative Timesteps: 94,402,468\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 121.53092\nPolicy Entropy: 5.34569\nValue Function Loss: 0.06886\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02549\nPolicy Update Magnitude: 0.20705\nValue Function Update Magnitude: 0.09121\n\nCollected Steps per Second: 1,708.36446\nOverall Steps per Second: 1,228.12366\n\nTimestep Collection Time: 23.41538\nTimestep Consumption Time: 9.15626\nPPO Batch Consumption Time: 0.98159\nTotal Iteration Time: 32.57164\n\nCumulative Model Updates: 18,859\nCumulative Timesteps: 94,442,470\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 104.03149\nPolicy Entropy: 5.32812\nValue Function Loss: 0.06691\n\nMean KL Divergence: 0.00063\nSB3 Clip Fraction: 0.02270\nPolicy Update Magnitude: 0.19838\nValue Function Update Magnitude: 0.08435\n\nCollected Steps per Second: 1,703.38367\nOverall Steps per Second: 1,226.39750\n\nTimestep Collection Time: 23.48385\nTimestep Consumption Time: 9.13364\nPPO Batch Consumption Time: 0.98545\nTotal Iteration Time: 32.61748\n\nCumulative Model Updates: 18,867\nCumulative Timesteps: 94,482,472\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 85.50709\nPolicy Entropy: 5.35641\nValue Function Loss: 0.06953\n\nMean KL Divergence: 0.00063\nSB3 Clip Fraction: 0.02198\nPolicy Update Magnitude: 0.18882\nValue Function Update Magnitude: 0.08426\n\nCollected Steps per Second: 1,712.11757\nOverall Steps per Second: 1,236.89970\n\nTimestep Collection Time: 23.36288\nTimestep Consumption Time: 8.97604\nPPO Batch Consumption Time: 0.96767\nTotal Iteration Time: 32.33892\n\nCumulative Model Updates: 18,875\nCumulative Timesteps: 94,522,472\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 107.84480\nPolicy Entropy: 5.35648\nValue Function Loss: 0.07256\n\nMean KL Divergence: 0.00071\nSB3 Clip Fraction: 0.02796\nPolicy Update Magnitude: 0.19083\nValue Function Update Magnitude: 0.08869\n\nCollected Steps per Second: 1,581.86606\nOverall Steps per Second: 1,160.82648\n\nTimestep Collection Time: 25.28659\nTimestep Consumption Time: 9.17162\nPPO Batch Consumption Time: 0.98534\nTotal Iteration Time: 34.45821\n\nCumulative Model Updates: 18,883\nCumulative Timesteps: 94,562,472\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 101.19211\nPolicy Entropy: 5.34832\nValue Function Loss: 0.07176\n\nMean KL Divergence: 0.00081\nSB3 Clip Fraction: 0.03090\nPolicy Update Magnitude: 0.21179\nValue Function Update Magnitude: 0.08261\n\nCollected Steps per Second: 1,677.97117\nOverall Steps per Second: 1,209.69120\n\nTimestep Collection Time: 23.83950\nTimestep Consumption Time: 9.22844\nPPO Batch Consumption Time: 0.98704\nTotal Iteration Time: 33.06794\n\nCumulative Model Updates: 18,891\nCumulative Timesteps: 94,602,474\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 95.28296\nPolicy Entropy: 5.33894\nValue Function Loss: 0.07165\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.02638\nPolicy Update Magnitude: 0.22944\nValue Function Update Magnitude: 0.08724\n\nCollected Steps per Second: 1,681.85568\nOverall Steps per Second: 1,210.56564\n\nTimestep Collection Time: 23.78325\nTimestep Consumption Time: 9.25915\nPPO Batch Consumption Time: 1.00425\nTotal Iteration Time: 33.04240\n\nCumulative Model Updates: 18,899\nCumulative Timesteps: 94,642,474\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 94642474...\nCheckpoint 94642474 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 95.94082\nPolicy Entropy: 5.34594\nValue Function Loss: 0.07100\n\nMean KL Divergence: 0.00071\nSB3 Clip Fraction: 0.02540\nPolicy Update Magnitude: 0.21387\nValue Function Update Magnitude: 0.08986\n\nCollected Steps per Second: 1,699.60158\nOverall Steps per Second: 1,219.59950\n\nTimestep Collection Time: 23.53493\nTimestep Consumption Time: 9.26272\nPPO Batch Consumption Time: 0.99102\nTotal Iteration Time: 32.79765\n\nCumulative Model Updates: 18,907\nCumulative Timesteps: 94,682,474\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 79.99194\nPolicy Entropy: 5.32568\nValue Function Loss: 0.06911\n\nMean KL Divergence: 0.00064\nSB3 Clip Fraction: 0.02328\nPolicy Update Magnitude: 0.19915\nValue Function Update Magnitude: 0.08470\n\nCollected Steps per Second: 1,690.04270\nOverall Steps per Second: 1,223.79457\n\nTimestep Collection Time: 23.66922\nTimestep Consumption Time: 9.01763\nPPO Batch Consumption Time: 0.96654\nTotal Iteration Time: 32.68686\n\nCumulative Model Updates: 18,915\nCumulative Timesteps: 94,722,476\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 122.18590\nPolicy Entropy: 5.31596\nValue Function Loss: 0.06673\n\nMean KL Divergence: 0.00071\nSB3 Clip Fraction: 0.02601\nPolicy Update Magnitude: 0.18656\nValue Function Update Magnitude: 0.08095\n\nCollected Steps per Second: 1,676.99649\nOverall Steps per Second: 1,218.44650\n\nTimestep Collection Time: 23.85217\nTimestep Consumption Time: 8.97652\nPPO Batch Consumption Time: 0.95758\nTotal Iteration Time: 32.82869\n\nCumulative Model Updates: 18,923\nCumulative Timesteps: 94,762,476\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 114.65575\nPolicy Entropy: 5.34257\nValue Function Loss: 0.06897\n\nMean KL Divergence: 0.00071\nSB3 Clip Fraction: 0.02635\nPolicy Update Magnitude: 0.17750\nValue Function Update Magnitude: 0.07757\n\nCollected Steps per Second: 1,668.29117\nOverall Steps per Second: 1,200.88739\n\nTimestep Collection Time: 23.97783\nTimestep Consumption Time: 9.33254\nPPO Batch Consumption Time: 1.00146\nTotal Iteration Time: 33.31037\n\nCumulative Model Updates: 18,931\nCumulative Timesteps: 94,802,478\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 76.33555\nPolicy Entropy: 5.35170\nValue Function Loss: 0.07218\n\nMean KL Divergence: 0.00071\nSB3 Clip Fraction: 0.02710\nPolicy Update Magnitude: 0.18703\nValue Function Update Magnitude: 0.08842\n\nCollected Steps per Second: 1,664.74549\nOverall Steps per Second: 1,213.01426\n\nTimestep Collection Time: 24.02890\nTimestep Consumption Time: 8.94846\nPPO Batch Consumption Time: 0.96686\nTotal Iteration Time: 32.97735\n\nCumulative Model Updates: 18,939\nCumulative Timesteps: 94,842,480\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 77.35393\nPolicy Entropy: 5.35995\nValue Function Loss: 0.07346\n\nMean KL Divergence: 0.00068\nSB3 Clip Fraction: 0.02615\nPolicy Update Magnitude: 0.19573\nValue Function Update Magnitude: 0.09768\n\nCollected Steps per Second: 1,744.84892\nOverall Steps per Second: 1,245.77404\n\nTimestep Collection Time: 22.92462\nTimestep Consumption Time: 9.18393\nPPO Batch Consumption Time: 0.99048\nTotal Iteration Time: 32.10855\n\nCumulative Model Updates: 18,947\nCumulative Timesteps: 94,882,480\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 98.51870\nPolicy Entropy: 5.36522\nValue Function Loss: 0.07150\n\nMean KL Divergence: 0.00061\nSB3 Clip Fraction: 0.02210\nPolicy Update Magnitude: 0.20055\nValue Function Update Magnitude: 0.09721\n\nCollected Steps per Second: 1,722.94626\nOverall Steps per Second: 1,236.91561\n\nTimestep Collection Time: 23.21605\nTimestep Consumption Time: 9.12246\nPPO Batch Consumption Time: 0.98369\nTotal Iteration Time: 32.33850\n\nCumulative Model Updates: 18,955\nCumulative Timesteps: 94,922,480\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 71.05620\nPolicy Entropy: 5.38363\nValue Function Loss: 0.06982\n\nMean KL Divergence: 0.00063\nSB3 Clip Fraction: 0.02361\nPolicy Update Magnitude: 0.19708\nValue Function Update Magnitude: 0.10244\n\nCollected Steps per Second: 1,716.80551\nOverall Steps per Second: 1,231.38238\n\nTimestep Collection Time: 23.29909\nTimestep Consumption Time: 9.18473\nPPO Batch Consumption Time: 0.99174\nTotal Iteration Time: 32.48382\n\nCumulative Model Updates: 18,963\nCumulative Timesteps: 94,962,480\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 80.00445\nPolicy Entropy: 5.38719\nValue Function Loss: 0.07132\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02770\nPolicy Update Magnitude: 0.19928\nValue Function Update Magnitude: 0.09514\n\nCollected Steps per Second: 1,745.80192\nOverall Steps per Second: 1,249.34249\n\nTimestep Collection Time: 22.91211\nTimestep Consumption Time: 9.10473\nPPO Batch Consumption Time: 0.98231\nTotal Iteration Time: 32.01684\n\nCumulative Model Updates: 18,971\nCumulative Timesteps: 95,002,480\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 86.10829\nPolicy Entropy: 5.35043\nValue Function Loss: 0.07241\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02701\nPolicy Update Magnitude: 0.19391\nValue Function Update Magnitude: 0.09310\n\nCollected Steps per Second: 1,705.40063\nOverall Steps per Second: 1,237.64833\n\nTimestep Collection Time: 23.45490\nTimestep Consumption Time: 8.86446\nPPO Batch Consumption Time: 0.98913\nTotal Iteration Time: 32.31936\n\nCumulative Model Updates: 18,979\nCumulative Timesteps: 95,042,480\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 94.75395\nPolicy Entropy: 5.33731\nValue Function Loss: 0.07168\n\nMean KL Divergence: 0.00067\nSB3 Clip Fraction: 0.02405\nPolicy Update Magnitude: 0.18741\nValue Function Update Magnitude: 0.09051\n\nCollected Steps per Second: 1,734.47030\nOverall Steps per Second: 1,256.49865\n\nTimestep Collection Time: 23.06295\nTimestep Consumption Time: 8.77314\nPPO Batch Consumption Time: 0.97784\nTotal Iteration Time: 31.83609\n\nCumulative Model Updates: 18,987\nCumulative Timesteps: 95,082,482\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 125.57772\nPolicy Entropy: 5.35829\nValue Function Loss: 0.07075\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.03029\nPolicy Update Magnitude: 0.19182\nValue Function Update Magnitude: 0.09246\n\nCollected Steps per Second: 1,722.89384\nOverall Steps per Second: 1,248.15296\n\nTimestep Collection Time: 23.21675\nTimestep Consumption Time: 8.83060\nPPO Batch Consumption Time: 0.98163\nTotal Iteration Time: 32.04735\n\nCumulative Model Updates: 18,995\nCumulative Timesteps: 95,122,482\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 97.26832\nPolicy Entropy: 5.37414\nValue Function Loss: 0.07012\n\nMean KL Divergence: 0.00092\nSB3 Clip Fraction: 0.03696\nPolicy Update Magnitude: 0.19770\nValue Function Update Magnitude: 0.08716\n\nCollected Steps per Second: 1,717.90574\nOverall Steps per Second: 1,242.77102\n\nTimestep Collection Time: 23.28416\nTimestep Consumption Time: 8.90197\nPPO Batch Consumption Time: 0.98748\nTotal Iteration Time: 32.18614\n\nCumulative Model Updates: 19,003\nCumulative Timesteps: 95,162,482\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 95162482...\nCheckpoint 95162482 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 111.84788\nPolicy Entropy: 5.34027\nValue Function Loss: 0.07000\n\nMean KL Divergence: 0.00091\nSB3 Clip Fraction: 0.03590\nPolicy Update Magnitude: 0.19583\nValue Function Update Magnitude: 0.08750\n\nCollected Steps per Second: 1,622.96432\nOverall Steps per Second: 1,185.90728\n\nTimestep Collection Time: 24.64749\nTimestep Consumption Time: 9.08364\nPPO Batch Consumption Time: 1.00886\nTotal Iteration Time: 33.73114\n\nCumulative Model Updates: 19,011\nCumulative Timesteps: 95,202,484\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 118.96688\nPolicy Entropy: 5.34363\nValue Function Loss: 0.07214\n\nMean KL Divergence: 0.00067\nSB3 Clip Fraction: 0.02379\nPolicy Update Magnitude: 0.18934\nValue Function Update Magnitude: 0.08635\n\nCollected Steps per Second: 1,587.96734\nOverall Steps per Second: 1,163.12671\n\nTimestep Collection Time: 25.19069\nTimestep Consumption Time: 9.20109\nPPO Batch Consumption Time: 1.03149\nTotal Iteration Time: 34.39178\n\nCumulative Model Updates: 19,019\nCumulative Timesteps: 95,242,486\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 125.01526\nPolicy Entropy: 5.37024\nValue Function Loss: 0.07201\n\nMean KL Divergence: 0.00078\nSB3 Clip Fraction: 0.03051\nPolicy Update Magnitude: 0.18284\nValue Function Update Magnitude: 0.08420\n\nCollected Steps per Second: 1,537.02300\nOverall Steps per Second: 1,147.77122\n\nTimestep Collection Time: 26.02564\nTimestep Consumption Time: 8.82626\nPPO Batch Consumption Time: 0.98081\nTotal Iteration Time: 34.85189\n\nCumulative Model Updates: 19,027\nCumulative Timesteps: 95,282,488\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 128.65920\nPolicy Entropy: 5.40364\nValue Function Loss: 0.07073\n\nMean KL Divergence: 0.00066\nSB3 Clip Fraction: 0.02517\nPolicy Update Magnitude: 0.18664\nValue Function Update Magnitude: 0.08626\n\nCollected Steps per Second: 1,666.62110\nOverall Steps per Second: 1,215.34156\n\nTimestep Collection Time: 24.00066\nTimestep Consumption Time: 8.91190\nPPO Batch Consumption Time: 0.99366\nTotal Iteration Time: 32.91256\n\nCumulative Model Updates: 19,035\nCumulative Timesteps: 95,322,488\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 111.58801\nPolicy Entropy: 5.40064\nValue Function Loss: 0.07135\n\nMean KL Divergence: 0.00069\nSB3 Clip Fraction: 0.02451\nPolicy Update Magnitude: 0.19617\nValue Function Update Magnitude: 0.08823\n\nCollected Steps per Second: 1,648.00772\nOverall Steps per Second: 1,202.73844\n\nTimestep Collection Time: 24.27294\nTimestep Consumption Time: 8.98616\nPPO Batch Consumption Time: 1.00164\nTotal Iteration Time: 33.25910\n\nCumulative Model Updates: 19,043\nCumulative Timesteps: 95,362,490\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 110.83055\nPolicy Entropy: 5.38057\nValue Function Loss: 0.07201\n\nMean KL Divergence: 0.00066\nSB3 Clip Fraction: 0.02345\nPolicy Update Magnitude: 0.19414\nValue Function Update Magnitude: 0.09105\n\nCollected Steps per Second: 1,653.43775\nOverall Steps per Second: 1,209.41427\n\nTimestep Collection Time: 24.19202\nTimestep Consumption Time: 8.88184\nPPO Batch Consumption Time: 0.98835\nTotal Iteration Time: 33.07386\n\nCumulative Model Updates: 19,051\nCumulative Timesteps: 95,402,490\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 93.34674\nPolicy Entropy: 5.37718\nValue Function Loss: 0.07255\n\nMean KL Divergence: 0.00070\nSB3 Clip Fraction: 0.02619\nPolicy Update Magnitude: 0.19195\nValue Function Update Magnitude: 0.09250\n\nCollected Steps per Second: 1,671.61762\nOverall Steps per Second: 1,222.36101\n\nTimestep Collection Time: 23.93011\nTimestep Consumption Time: 8.79508\nPPO Batch Consumption Time: 0.97613\nTotal Iteration Time: 32.72519\n\nCumulative Model Updates: 19,059\nCumulative Timesteps: 95,442,492\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 118.73216\nPolicy Entropy: 5.37160\nValue Function Loss: 0.07320\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.02821\nPolicy Update Magnitude: 0.19188\nValue Function Update Magnitude: 0.09180\n\nCollected Steps per Second: 1,703.82632\nOverall Steps per Second: 1,238.06260\n\nTimestep Collection Time: 23.47775\nTimestep Consumption Time: 8.83241\nPPO Batch Consumption Time: 0.98446\nTotal Iteration Time: 32.31016\n\nCumulative Model Updates: 19,067\nCumulative Timesteps: 95,482,494\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 118.10958\nPolicy Entropy: 5.35892\nValue Function Loss: 0.07430\n\nMean KL Divergence: 0.00084\nSB3 Clip Fraction: 0.03205\nPolicy Update Magnitude: 0.19271\nValue Function Update Magnitude: 0.09227\n\nCollected Steps per Second: 1,665.02484\nOverall Steps per Second: 1,215.55070\n\nTimestep Collection Time: 24.02367\nTimestep Consumption Time: 8.88323\nPPO Batch Consumption Time: 0.99166\nTotal Iteration Time: 32.90690\n\nCumulative Model Updates: 19,075\nCumulative Timesteps: 95,522,494\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 50.51564\nPolicy Entropy: 5.36839\nValue Function Loss: 0.07141\n\nMean KL Divergence: 0.00080\nSB3 Clip Fraction: 0.02596\nPolicy Update Magnitude: 0.20804\nValue Function Update Magnitude: 0.09656\n\nCollected Steps per Second: 1,672.75564\nOverall Steps per Second: 1,224.13036\n\nTimestep Collection Time: 23.91264\nTimestep Consumption Time: 8.76362\nPPO Batch Consumption Time: 0.97705\nTotal Iteration Time: 32.67626\n\nCumulative Model Updates: 19,083\nCumulative Timesteps: 95,562,494\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 106.89823\nPolicy Entropy: 5.38004\nValue Function Loss: 0.06961\n\nMean KL Divergence: 0.00066\nSB3 Clip Fraction: 0.02389\nPolicy Update Magnitude: 0.20533\nValue Function Update Magnitude: 0.09027\n\nCollected Steps per Second: 1,624.17958\nOverall Steps per Second: 1,184.00942\n\nTimestep Collection Time: 24.62905\nTimestep Consumption Time: 9.15615\nPPO Batch Consumption Time: 0.98843\nTotal Iteration Time: 33.78520\n\nCumulative Model Updates: 19,091\nCumulative Timesteps: 95,602,496\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 92.07386\nPolicy Entropy: 5.37908\nValue Function Loss: 0.07065\n\nMean KL Divergence: 0.00058\nSB3 Clip Fraction: 0.01980\nPolicy Update Magnitude: 0.20465\nValue Function Update Magnitude: 0.08958\n\nCollected Steps per Second: 1,653.88353\nOverall Steps per Second: 1,201.51867\n\nTimestep Collection Time: 24.18550\nTimestep Consumption Time: 9.10570\nPPO Batch Consumption Time: 0.97543\nTotal Iteration Time: 33.29120\n\nCumulative Model Updates: 19,099\nCumulative Timesteps: 95,642,496\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 92.73306\nPolicy Entropy: 5.36814\nValue Function Loss: 0.06957\n\nMean KL Divergence: 0.00063\nSB3 Clip Fraction: 0.02170\nPolicy Update Magnitude: 0.20388\nValue Function Update Magnitude: 0.08928\n\nCollected Steps per Second: 1,668.71336\nOverall Steps per Second: 1,208.66990\n\nTimestep Collection Time: 23.97056\nTimestep Consumption Time: 9.12367\nPPO Batch Consumption Time: 0.98601\nTotal Iteration Time: 33.09423\n\nCumulative Model Updates: 19,107\nCumulative Timesteps: 95,682,496\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 95682496...\nCheckpoint 95682496 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 128.72839\nPolicy Entropy: 5.34723\nValue Function Loss: 0.07100\n\nMean KL Divergence: 0.00071\nSB3 Clip Fraction: 0.02623\nPolicy Update Magnitude: 0.19853\nValue Function Update Magnitude: 0.08808\n\nCollected Steps per Second: 1,677.42332\nOverall Steps per Second: 1,212.23691\n\nTimestep Collection Time: 23.84610\nTimestep Consumption Time: 9.15075\nPPO Batch Consumption Time: 0.98133\nTotal Iteration Time: 32.99685\n\nCumulative Model Updates: 19,115\nCumulative Timesteps: 95,722,496\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 102.77914\nPolicy Entropy: 5.34472\nValue Function Loss: 0.07122\n\nMean KL Divergence: 0.00070\nSB3 Clip Fraction: 0.02662\nPolicy Update Magnitude: 0.19512\nValue Function Update Magnitude: 0.09312\n\nCollected Steps per Second: 1,692.55254\nOverall Steps per Second: 1,220.75910\n\nTimestep Collection Time: 23.63294\nTimestep Consumption Time: 9.13355\nPPO Batch Consumption Time: 0.98317\nTotal Iteration Time: 32.76650\n\nCumulative Model Updates: 19,123\nCumulative Timesteps: 95,762,496\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 102.67220\nPolicy Entropy: 5.32890\nValue Function Loss: 0.07168\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.02808\nPolicy Update Magnitude: 0.19228\nValue Function Update Magnitude: 0.08926\n\nCollected Steps per Second: 1,649.34294\nOverall Steps per Second: 1,215.45438\n\nTimestep Collection Time: 24.25329\nTimestep Consumption Time: 8.65785\nPPO Batch Consumption Time: 0.96107\nTotal Iteration Time: 32.91115\n\nCumulative Model Updates: 19,131\nCumulative Timesteps: 95,802,498\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 130.83771\nPolicy Entropy: 5.34848\nValue Function Loss: 0.07233\n\nMean KL Divergence: 0.00067\nSB3 Clip Fraction: 0.02476\nPolicy Update Magnitude: 0.19266\nValue Function Update Magnitude: 0.08549\n\nCollected Steps per Second: 1,655.81382\nOverall Steps per Second: 1,211.26157\n\nTimestep Collection Time: 24.15731\nTimestep Consumption Time: 8.86611\nPPO Batch Consumption Time: 0.98991\nTotal Iteration Time: 33.02342\n\nCumulative Model Updates: 19,139\nCumulative Timesteps: 95,842,498\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 83.06254\nPolicy Entropy: 5.36079\nValue Function Loss: 0.06843\n\nMean KL Divergence: 0.00075\nSB3 Clip Fraction: 0.02871\nPolicy Update Magnitude: 0.20160\nValue Function Update Magnitude: 0.08531\n\nCollected Steps per Second: 1,674.70995\nOverall Steps per Second: 1,224.62359\n\nTimestep Collection Time: 23.88712\nTimestep Consumption Time: 8.77924\nPPO Batch Consumption Time: 0.98385\nTotal Iteration Time: 32.66636\n\nCumulative Model Updates: 19,147\nCumulative Timesteps: 95,882,502\n\nTimesteps Collected: 40,004\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 60.98185\nPolicy Entropy: 5.34326\nValue Function Loss: 0.06864\n\nMean KL Divergence: 0.00079\nSB3 Clip Fraction: 0.03009\nPolicy Update Magnitude: 0.20125\nValue Function Update Magnitude: 0.08574\n\nCollected Steps per Second: 1,715.73412\nOverall Steps per Second: 1,248.17317\n\nTimestep Collection Time: 23.31364\nTimestep Consumption Time: 8.73320\nPPO Batch Consumption Time: 0.96620\nTotal Iteration Time: 32.04684\n\nCumulative Model Updates: 19,155\nCumulative Timesteps: 95,922,502\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 113.38446\nPolicy Entropy: 5.34186\nValue Function Loss: 0.07103\n\nMean KL Divergence: 0.00089\nSB3 Clip Fraction: 0.03675\nPolicy Update Magnitude: 0.19639\nValue Function Update Magnitude: 0.08802\n\nCollected Steps per Second: 1,689.43591\nOverall Steps per Second: 1,232.31101\n\nTimestep Collection Time: 23.67773\nTimestep Consumption Time: 8.78324\nPPO Batch Consumption Time: 0.97708\nTotal Iteration Time: 32.46096\n\nCumulative Model Updates: 19,163\nCumulative Timesteps: 95,962,504\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 106.18054\nPolicy Entropy: 5.37029\nValue Function Loss: 0.06988\n\nMean KL Divergence: 0.00080\nSB3 Clip Fraction: 0.02977\nPolicy Update Magnitude: 0.18811\nValue Function Update Magnitude: 0.08802\n\nCollected Steps per Second: 1,628.14003\nOverall Steps per Second: 1,195.07061\n\nTimestep Collection Time: 24.56914\nTimestep Consumption Time: 8.90336\nPPO Batch Consumption Time: 0.99083\nTotal Iteration Time: 33.47250\n\nCumulative Model Updates: 19,171\nCumulative Timesteps: 96,002,506\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 107.93024\nPolicy Entropy: 5.38001\nValue Function Loss: 0.06757\n\nMean KL Divergence: 0.00055\nSB3 Clip Fraction: 0.01899\nPolicy Update Magnitude: 0.18319\nValue Function Update Magnitude: 0.08752\n\nCollected Steps per Second: 1,569.13905\nOverall Steps per Second: 1,165.91657\n\nTimestep Collection Time: 25.49169\nTimestep Consumption Time: 8.81609\nPPO Batch Consumption Time: 0.98569\nTotal Iteration Time: 34.30777\n\nCumulative Model Updates: 19,179\nCumulative Timesteps: 96,042,506\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 87.77867\nPolicy Entropy: 5.38228\nValue Function Loss: 0.06946\n\nMean KL Divergence: 0.00057\nSB3 Clip Fraction: 0.01906\nPolicy Update Magnitude: 0.19033\nValue Function Update Magnitude: 0.09107\n\nCollected Steps per Second: 1,606.68038\nOverall Steps per Second: 1,189.97650\n\nTimestep Collection Time: 24.89605\nTimestep Consumption Time: 8.71806\nPPO Batch Consumption Time: 0.97141\nTotal Iteration Time: 33.61411\n\nCumulative Model Updates: 19,187\nCumulative Timesteps: 96,082,506\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 89.06265\nPolicy Entropy: 5.35576\nValue Function Loss: 0.07131\n\nMean KL Divergence: 0.00063\nSB3 Clip Fraction: 0.02241\nPolicy Update Magnitude: 0.19076\nValue Function Update Magnitude: 0.08851\n\nCollected Steps per Second: 1,656.24621\nOverall Steps per Second: 1,217.13603\n\nTimestep Collection Time: 24.15100\nTimestep Consumption Time: 8.71304\nPPO Batch Consumption Time: 0.97125\nTotal Iteration Time: 32.86403\n\nCumulative Model Updates: 19,195\nCumulative Timesteps: 96,122,506\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 122.99132\nPolicy Entropy: 5.34932\nValue Function Loss: 0.06904\n\nMean KL Divergence: 0.00069\nSB3 Clip Fraction: 0.02599\nPolicy Update Magnitude: 0.18481\nValue Function Update Magnitude: 0.08639\n\nCollected Steps per Second: 1,630.21847\nOverall Steps per Second: 1,204.84930\n\nTimestep Collection Time: 24.53782\nTimestep Consumption Time: 8.66302\nPPO Batch Consumption Time: 0.96427\nTotal Iteration Time: 33.20083\n\nCumulative Model Updates: 19,203\nCumulative Timesteps: 96,162,508\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 114.32950\nPolicy Entropy: 5.35416\nValue Function Loss: 0.06850\n\nMean KL Divergence: 0.00067\nSB3 Clip Fraction: 0.02502\nPolicy Update Magnitude: 0.18467\nValue Function Update Magnitude: 0.08548\n\nCollected Steps per Second: 1,670.29578\nOverall Steps per Second: 1,218.61882\n\nTimestep Collection Time: 23.94785\nTimestep Consumption Time: 8.87619\nPPO Batch Consumption Time: 0.98577\nTotal Iteration Time: 32.82405\n\nCumulative Model Updates: 19,211\nCumulative Timesteps: 96,202,508\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 96202508...\nCheckpoint 96202508 saved!\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 110.15118\nPolicy Entropy: 5.35745\nValue Function Loss: 0.06864\n\nMean KL Divergence: 0.00067\nSB3 Clip Fraction: 0.02320\nPolicy Update Magnitude: 0.19135\nValue Function Update Magnitude: 0.08362\n\nCollected Steps per Second: 1,665.67955\nOverall Steps per Second: 1,214.72490\n\nTimestep Collection Time: 24.01422\nTimestep Consumption Time: 8.91504\nPPO Batch Consumption Time: 0.99533\nTotal Iteration Time: 32.92927\n\nCumulative Model Updates: 19,219\nCumulative Timesteps: 96,242,508\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 106.89033\nPolicy Entropy: 5.36805\nValue Function Loss: 0.06813\n\nMean KL Divergence: 0.00056\nSB3 Clip Fraction: 0.01916\nPolicy Update Magnitude: 0.19160\nValue Function Update Magnitude: 0.08254\n\nCollected Steps per Second: 1,668.74976\nOverall Steps per Second: 1,217.68621\n\nTimestep Collection Time: 23.97004\nTimestep Consumption Time: 8.87914\nPPO Batch Consumption Time: 0.99223\nTotal Iteration Time: 32.84919\n\nCumulative Model Updates: 19,227\nCumulative Timesteps: 96,282,508\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 111.21469\nPolicy Entropy: 5.36964\nValue Function Loss: 0.06899\n\nMean KL Divergence: 0.00064\nSB3 Clip Fraction: 0.02271\nPolicy Update Magnitude: 0.20033\nValue Function Update Magnitude: 0.08737\n\nCollected Steps per Second: 1,654.84361\nOverall Steps per Second: 1,211.08617\n\nTimestep Collection Time: 24.17268\nTimestep Consumption Time: 8.85718\nPPO Batch Consumption Time: 0.99002\nTotal Iteration Time: 33.02985\n\nCumulative Model Updates: 19,235\nCumulative Timesteps: 96,322,510\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 104.67140\nPolicy Entropy: 5.36369\nValue Function Loss: 0.07221\n\nMean KL Divergence: 0.00071\nSB3 Clip Fraction: 0.02679\nPolicy Update Magnitude: 0.19598\nValue Function Update Magnitude: 0.08746\n\nCollected Steps per Second: 1,640.75909\nOverall Steps per Second: 1,188.16690\n\nTimestep Collection Time: 24.37896\nTimestep Consumption Time: 9.28634\nPPO Batch Consumption Time: 1.00152\nTotal Iteration Time: 33.66530\n\nCumulative Model Updates: 19,243\nCumulative Timesteps: 96,362,510\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 118.76076\nPolicy Entropy: 5.36127\nValue Function Loss: 0.07056\n\nMean KL Divergence: 0.00068\nSB3 Clip Fraction: 0.02450\nPolicy Update Magnitude: 0.19449\nValue Function Update Magnitude: 0.09106\n\nCollected Steps per Second: 1,663.65714\nOverall Steps per Second: 1,210.13027\n\nTimestep Collection Time: 24.04342\nTimestep Consumption Time: 9.01088\nPPO Batch Consumption Time: 0.97552\nTotal Iteration Time: 33.05429\n\nCumulative Model Updates: 19,251\nCumulative Timesteps: 96,402,510\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 67.93776\nPolicy Entropy: 5.36391\nValue Function Loss: 0.06507\n\nMean KL Divergence: 0.00069\nSB3 Clip Fraction: 0.02459\nPolicy Update Magnitude: 0.18606\nValue Function Update Magnitude: 0.09119\n\nCollected Steps per Second: 1,673.22773\nOverall Steps per Second: 1,214.64482\n\nTimestep Collection Time: 23.90589\nTimestep Consumption Time: 9.02555\nPPO Batch Consumption Time: 0.96759\nTotal Iteration Time: 32.93144\n\nCumulative Model Updates: 19,259\nCumulative Timesteps: 96,442,510\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 99.00875\nPolicy Entropy: 5.36440\nValue Function Loss: 0.06697\n\nMean KL Divergence: 0.00075\nSB3 Clip Fraction: 0.03000\nPolicy Update Magnitude: 0.17996\nValue Function Update Magnitude: 0.08744\n\nCollected Steps per Second: 1,683.86518\nOverall Steps per Second: 1,214.20351\n\nTimestep Collection Time: 23.75487\nTimestep Consumption Time: 9.18854\nPPO Batch Consumption Time: 0.99493\nTotal Iteration Time: 32.94341\n\nCumulative Model Updates: 19,267\nCumulative Timesteps: 96,482,510\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 97.51121\nPolicy Entropy: 5.37273\nValue Function Loss: 0.07089\n\nMean KL Divergence: 0.00070\nSB3 Clip Fraction: 0.02662\nPolicy Update Magnitude: 0.18807\nValue Function Update Magnitude: 0.08902\n\nCollected Steps per Second: 1,660.10916\nOverall Steps per Second: 1,202.33923\n\nTimestep Collection Time: 24.09480\nTimestep Consumption Time: 9.17368\nPPO Batch Consumption Time: 0.98642\nTotal Iteration Time: 33.26848\n\nCumulative Model Updates: 19,275\nCumulative Timesteps: 96,522,510\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 106.71845\nPolicy Entropy: 5.36760\nValue Function Loss: 0.06980\n\nMean KL Divergence: 0.00085\nSB3 Clip Fraction: 0.03164\nPolicy Update Magnitude: 0.19791\nValue Function Update Magnitude: 0.09233\n\nCollected Steps per Second: 1,670.68743\nOverall Steps per Second: 1,211.44014\n\nTimestep Collection Time: 23.94224\nTimestep Consumption Time: 9.07631\nPPO Batch Consumption Time: 0.97720\nTotal Iteration Time: 33.01855\n\nCumulative Model Updates: 19,283\nCumulative Timesteps: 96,562,510\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 87.53601\nPolicy Entropy: 5.37723\nValue Function Loss: 0.06977\n\nMean KL Divergence: 0.00066\nSB3 Clip Fraction: 0.02491\nPolicy Update Magnitude: 0.19450\nValue Function Update Magnitude: 0.09038\n\nCollected Steps per Second: 1,723.74174\nOverall Steps per Second: 1,236.54636\n\nTimestep Collection Time: 23.20533\nTimestep Consumption Time: 9.14283\nPPO Batch Consumption Time: 0.98160\nTotal Iteration Time: 32.34816\n\nCumulative Model Updates: 19,291\nCumulative Timesteps: 96,602,510\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 122.88879\nPolicy Entropy: 5.37361\nValue Function Loss: 0.07095\n\nMean KL Divergence: 0.00071\nSB3 Clip Fraction: 0.02966\nPolicy Update Magnitude: 0.19315\nValue Function Update Magnitude: 0.08400\n\nCollected Steps per Second: 1,742.59760\nOverall Steps per Second: 1,249.28714\n\nTimestep Collection Time: 22.95539\nTimestep Consumption Time: 9.06447\nPPO Batch Consumption Time: 0.97034\nTotal Iteration Time: 32.01986\n\nCumulative Model Updates: 19,299\nCumulative Timesteps: 96,642,512\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 98.09298\nPolicy Entropy: 5.35305\nValue Function Loss: 0.07191\n\nMean KL Divergence: 0.00082\nSB3 Clip Fraction: 0.03237\nPolicy Update Magnitude: 0.19184\nValue Function Update Magnitude: 0.08041\n\nCollected Steps per Second: 1,674.22241\nOverall Steps per Second: 1,207.03038\n\nTimestep Collection Time: 23.89169\nTimestep Consumption Time: 9.24749\nPPO Batch Consumption Time: 0.99469\nTotal Iteration Time: 33.13918\n\nCumulative Model Updates: 19,307\nCumulative Timesteps: 96,682,512\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 112.67738\nPolicy Entropy: 5.35178\nValue Function Loss: 0.07095\n\nMean KL Divergence: 0.00075\nSB3 Clip Fraction: 0.02910\nPolicy Update Magnitude: 0.18880\nValue Function Update Magnitude: 0.08192\n\nCollected Steps per Second: 1,663.57775\nOverall Steps per Second: 1,204.10145\n\nTimestep Collection Time: 24.04577\nTimestep Consumption Time: 9.17569\nPPO Batch Consumption Time: 0.99368\nTotal Iteration Time: 33.22145\n\nCumulative Model Updates: 19,315\nCumulative Timesteps: 96,722,514\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 96722514...\nCheckpoint 96722514 saved!\n\n\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 100.72092\nPolicy Entropy: 5.35326\nValue Function Loss: 0.07099\n\nMean KL Divergence: 0.00163\nSB3 Clip Fraction: 0.02802\nPolicy Update Magnitude: 0.21665\nValue Function Update Magnitude: 0.09061\n\nCollected Steps per Second: 1,687.67647\nOverall Steps per Second: 1,216.69669\n\nTimestep Collection Time: 23.70123\nTimestep Consumption Time: 9.17468\nPPO Batch Consumption Time: 0.98982\nTotal Iteration Time: 32.87590\n\nCumulative Model Updates: 19,323\nCumulative Timesteps: 96,762,514\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 108.37777\nPolicy Entropy: 5.38707\nValue Function Loss: 0.06867\n\nMean KL Divergence: 0.00562\nSB3 Clip Fraction: 0.03595\nPolicy Update Magnitude: 0.21606\nValue Function Update Magnitude: 0.09448\n\nCollected Steps per Second: 1,729.39429\nOverall Steps per Second: 1,244.27114\n\nTimestep Collection Time: 23.12949\nTimestep Consumption Time: 9.01785\nPPO Batch Consumption Time: 0.96952\nTotal Iteration Time: 32.14733\n\nCumulative Model Updates: 19,331\nCumulative Timesteps: 96,802,514\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 84.79937\nPolicy Entropy: 5.38755\nValue Function Loss: 0.07010\n\nMean KL Divergence: 0.00070\nSB3 Clip Fraction: 0.02655\nPolicy Update Magnitude: 0.21215\nValue Function Update Magnitude: 0.08946\n\nCollected Steps per Second: 1,722.58604\nOverall Steps per Second: 1,244.19558\n\nTimestep Collection Time: 23.22206\nTimestep Consumption Time: 8.92883\nPPO Batch Consumption Time: 0.96035\nTotal Iteration Time: 32.15089\n\nCumulative Model Updates: 19,339\nCumulative Timesteps: 96,842,516\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 119.44653\nPolicy Entropy: 5.35978\nValue Function Loss: 0.07025\n\nMean KL Divergence: 0.00079\nSB3 Clip Fraction: 0.03026\nPolicy Update Magnitude: 0.19053\nValue Function Update Magnitude: 0.09294\n\nCollected Steps per Second: 1,770.01968\nOverall Steps per Second: 1,257.96057\n\nTimestep Collection Time: 22.59975\nTimestep Consumption Time: 9.19934\nPPO Batch Consumption Time: 0.99361\nTotal Iteration Time: 31.79909\n\nCumulative Model Updates: 19,347\nCumulative Timesteps: 96,882,518\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 86.26214\nPolicy Entropy: 5.37587\nValue Function Loss: 0.06888\n\nMean KL Divergence: 0.00071\nSB3 Clip Fraction: 0.02665\nPolicy Update Magnitude: 0.19221\nValue Function Update Magnitude: 0.09203\n\nCollected Steps per Second: 1,731.21385\nOverall Steps per Second: 1,243.56471\n\nTimestep Collection Time: 23.10518\nTimestep Consumption Time: 9.06042\nPPO Batch Consumption Time: 0.96711\nTotal Iteration Time: 32.16560\n\nCumulative Model Updates: 19,355\nCumulative Timesteps: 96,922,518\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 98.95851\nPolicy Entropy: 5.38544\nValue Function Loss: 0.07224\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02695\nPolicy Update Magnitude: 0.20035\nValue Function Update Magnitude: 0.09642\n\nCollected Steps per Second: 1,729.51217\nOverall Steps per Second: 1,254.13558\n\nTimestep Collection Time: 23.12907\nTimestep Consumption Time: 8.76701\nPPO Batch Consumption Time: 0.94537\nTotal Iteration Time: 31.89607\n\nCumulative Model Updates: 19,363\nCumulative Timesteps: 96,962,520\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 127.29927\nPolicy Entropy: 5.35860\nValue Function Loss: 0.07142\n\nMean KL Divergence: 0.00080\nSB3 Clip Fraction: 0.03260\nPolicy Update Magnitude: 0.19740\nValue Function Update Magnitude: 0.09530\n\nCollected Steps per Second: 1,783.88364\nOverall Steps per Second: 1,276.31155\n\nTimestep Collection Time: 22.42411\nTimestep Consumption Time: 8.91777\nPPO Batch Consumption Time: 0.96502\nTotal Iteration Time: 31.34188\n\nCumulative Model Updates: 19,371\nCumulative Timesteps: 97,002,522\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 102.29038\nPolicy Entropy: 5.34989\nValue Function Loss: 0.06867\n\nMean KL Divergence: 0.00079\nSB3 Clip Fraction: 0.03234\nPolicy Update Magnitude: 0.19031\nValue Function Update Magnitude: 0.08420\n\nCollected Steps per Second: 1,696.81198\nOverall Steps per Second: 1,237.32917\n\nTimestep Collection Time: 23.57362\nTimestep Consumption Time: 8.75408\nPPO Batch Consumption Time: 0.98211\nTotal Iteration Time: 32.32770\n\nCumulative Model Updates: 19,379\nCumulative Timesteps: 97,042,522\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 110.38392\nPolicy Entropy: 5.35785\nValue Function Loss: 0.06985\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.02814\nPolicy Update Magnitude: 0.18520\nValue Function Update Magnitude: 0.08964\n\nCollected Steps per Second: 1,703.86146\nOverall Steps per Second: 1,243.91541\n\nTimestep Collection Time: 23.47726\nTimestep Consumption Time: 8.68087\nPPO Batch Consumption Time: 0.96785\nTotal Iteration Time: 32.15814\n\nCumulative Model Updates: 19,387\nCumulative Timesteps: 97,082,524\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 72.96535\nPolicy Entropy: 5.37392\nValue Function Loss: 0.07045\n\nMean KL Divergence: 0.00084\nSB3 Clip Fraction: 0.03401\nPolicy Update Magnitude: 0.20419\nValue Function Update Magnitude: 0.08742\n\nCollected Steps per Second: 1,709.54820\nOverall Steps per Second: 1,249.07864\n\nTimestep Collection Time: 23.39916\nTimestep Consumption Time: 8.62604\nPPO Batch Consumption Time: 0.95039\nTotal Iteration Time: 32.02521\n\nCumulative Model Updates: 19,395\nCumulative Timesteps: 97,122,526\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 111.30453\nPolicy Entropy: 5.35206\nValue Function Loss: 0.06739\n\nMean KL Divergence: 0.00068\nSB3 Clip Fraction: 0.02369\nPolicy Update Magnitude: 0.21668\nValue Function Update Magnitude: 0.08412\n\nCollected Steps per Second: 1,719.98079\nOverall Steps per Second: 1,242.33081\n\nTimestep Collection Time: 23.25607\nTimestep Consumption Time: 8.94147\nPPO Batch Consumption Time: 1.00247\nTotal Iteration Time: 32.19754\n\nCumulative Model Updates: 19,403\nCumulative Timesteps: 97,162,526\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 103.96932\nPolicy Entropy: 5.35040\nValue Function Loss: 0.06690\n\nMean KL Divergence: 0.00089\nSB3 Clip Fraction: 0.03572\nPolicy Update Magnitude: 0.19790\nValue Function Update Magnitude: 0.08045\n\nCollected Steps per Second: 1,596.53168\nOverall Steps per Second: 1,179.69241\n\nTimestep Collection Time: 25.05431\nTimestep Consumption Time: 8.85283\nPPO Batch Consumption Time: 0.98760\nTotal Iteration Time: 33.90714\n\nCumulative Model Updates: 19,411\nCumulative Timesteps: 97,202,526\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 127.24745\nPolicy Entropy: 5.35416\nValue Function Loss: 0.06870\n\nMean KL Divergence: 0.00085\nSB3 Clip Fraction: 0.03394\nPolicy Update Magnitude: 0.19943\nValue Function Update Magnitude: 0.08145\n\nCollected Steps per Second: 1,677.34762\nOverall Steps per Second: 1,227.26430\n\nTimestep Collection Time: 23.84837\nTimestep Consumption Time: 8.74608\nPPO Batch Consumption Time: 0.97363\nTotal Iteration Time: 32.59445\n\nCumulative Model Updates: 19,419\nCumulative Timesteps: 97,242,528\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 97242528...\nCheckpoint 97242528 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 100.92952\nPolicy Entropy: 5.38577\nValue Function Loss: 0.06991\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02753\nPolicy Update Magnitude: 0.20433\nValue Function Update Magnitude: 0.09378\n\nCollected Steps per Second: 1,616.59185\nOverall Steps per Second: 1,192.43620\n\nTimestep Collection Time: 24.74341\nTimestep Consumption Time: 8.80136\nPPO Batch Consumption Time: 0.98416\nTotal Iteration Time: 33.54477\n\nCumulative Model Updates: 19,427\nCumulative Timesteps: 97,282,528\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 99.43126\nPolicy Entropy: 5.38120\nValue Function Loss: 0.07024\n\nMean KL Divergence: 0.00068\nSB3 Clip Fraction: 0.02551\nPolicy Update Magnitude: 0.19828\nValue Function Update Magnitude: 0.08694\n\nCollected Steps per Second: 1,628.34979\nOverall Steps per Second: 1,199.01906\n\nTimestep Collection Time: 24.56475\nTimestep Consumption Time: 8.79586\nPPO Batch Consumption Time: 0.97895\nTotal Iteration Time: 33.36060\n\nCumulative Model Updates: 19,435\nCumulative Timesteps: 97,322,528\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 92.29454\nPolicy Entropy: 5.38279\nValue Function Loss: 0.06810\n\nMean KL Divergence: 0.00082\nSB3 Clip Fraction: 0.03301\nPolicy Update Magnitude: 0.19502\nValue Function Update Magnitude: 0.08626\n\nCollected Steps per Second: 1,629.46708\nOverall Steps per Second: 1,204.12561\n\nTimestep Collection Time: 24.54790\nTimestep Consumption Time: 8.67122\nPPO Batch Consumption Time: 0.96916\nTotal Iteration Time: 33.21913\n\nCumulative Model Updates: 19,443\nCumulative Timesteps: 97,362,528\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 116.26260\nPolicy Entropy: 5.38407\nValue Function Loss: 0.06857\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.02756\nPolicy Update Magnitude: 0.19678\nValue Function Update Magnitude: 0.08840\n\nCollected Steps per Second: 1,604.36201\nOverall Steps per Second: 1,179.96253\n\nTimestep Collection Time: 24.93203\nTimestep Consumption Time: 8.96735\nPPO Batch Consumption Time: 1.00011\nTotal Iteration Time: 33.89938\n\nCumulative Model Updates: 19,451\nCumulative Timesteps: 97,402,528\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 91.75971\nPolicy Entropy: 5.38300\nValue Function Loss: 0.07225\n\nMean KL Divergence: 0.00092\nSB3 Clip Fraction: 0.03726\nPolicy Update Magnitude: 0.19830\nValue Function Update Magnitude: 0.08581\n\nCollected Steps per Second: 1,544.03338\nOverall Steps per Second: 1,148.87593\n\nTimestep Collection Time: 25.90618\nTimestep Consumption Time: 8.91046\nPPO Batch Consumption Time: 0.99406\nTotal Iteration Time: 34.81664\n\nCumulative Model Updates: 19,459\nCumulative Timesteps: 97,442,528\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 91.13577\nPolicy Entropy: 5.35072\nValue Function Loss: 0.07496\n\nMean KL Divergence: 0.00080\nSB3 Clip Fraction: 0.02564\nPolicy Update Magnitude: 0.20729\nValue Function Update Magnitude: 0.09262\n\nCollected Steps per Second: 1,556.16510\nOverall Steps per Second: 1,149.80425\n\nTimestep Collection Time: 25.70550\nTimestep Consumption Time: 9.08477\nPPO Batch Consumption Time: 1.01223\nTotal Iteration Time: 34.79027\n\nCumulative Model Updates: 19,467\nCumulative Timesteps: 97,482,530\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 99.45721\nPolicy Entropy: 5.36828\nValue Function Loss: 0.07077\n\nMean KL Divergence: 0.00106\nSB3 Clip Fraction: 0.02977\nPolicy Update Magnitude: 0.21155\nValue Function Update Magnitude: 0.09576\n\nCollected Steps per Second: 1,585.86528\nOverall Steps per Second: 1,164.80808\n\nTimestep Collection Time: 25.22408\nTimestep Consumption Time: 9.11805\nPPO Batch Consumption Time: 1.01647\nTotal Iteration Time: 34.34214\n\nCumulative Model Updates: 19,475\nCumulative Timesteps: 97,522,532\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 76.99505\nPolicy Entropy: 5.39836\nValue Function Loss: 0.06701\n\nMean KL Divergence: 0.00056\nSB3 Clip Fraction: 0.01934\nPolicy Update Magnitude: 0.20652\nValue Function Update Magnitude: 0.09757\n\nCollected Steps per Second: 1,478.57332\nOverall Steps per Second: 1,113.72009\n\nTimestep Collection Time: 27.05446\nTimestep Consumption Time: 8.86300\nPPO Batch Consumption Time: 0.98842\nTotal Iteration Time: 35.91746\n\nCumulative Model Updates: 19,483\nCumulative Timesteps: 97,562,534\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 128.76650\nPolicy Entropy: 5.38189\nValue Function Loss: 0.06805\n\nMean KL Divergence: 0.00069\nSB3 Clip Fraction: 0.02541\nPolicy Update Magnitude: 0.20455\nValue Function Update Magnitude: 0.09437\n\nCollected Steps per Second: 1,561.38038\nOverall Steps per Second: 1,139.60385\n\nTimestep Collection Time: 25.61836\nTimestep Consumption Time: 9.48156\nPPO Batch Consumption Time: 1.03029\nTotal Iteration Time: 35.09992\n\nCumulative Model Updates: 19,491\nCumulative Timesteps: 97,602,534\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 99.17157\nPolicy Entropy: 5.38048\nValue Function Loss: 0.06959\n\nMean KL Divergence: 0.00073\nSB3 Clip Fraction: 0.02841\nPolicy Update Magnitude: 0.20024\nValue Function Update Magnitude: 0.09585\n\nCollected Steps per Second: 1,574.19170\nOverall Steps per Second: 1,139.37878\n\nTimestep Collection Time: 25.41114\nTimestep Consumption Time: 9.69747\nPPO Batch Consumption Time: 1.04114\nTotal Iteration Time: 35.10861\n\nCumulative Model Updates: 19,499\nCumulative Timesteps: 97,642,536\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 84.49403\nPolicy Entropy: 5.38769\nValue Function Loss: 0.07007\n\nMean KL Divergence: 0.00065\nSB3 Clip Fraction: 0.02341\nPolicy Update Magnitude: 0.19970\nValue Function Update Magnitude: 0.09419\n\nCollected Steps per Second: 1,409.24842\nOverall Steps per Second: 1,058.52104\n\nTimestep Collection Time: 28.38534\nTimestep Consumption Time: 9.40512\nPPO Batch Consumption Time: 1.00272\nTotal Iteration Time: 37.79046\n\nCumulative Model Updates: 19,507\nCumulative Timesteps: 97,682,538\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 102.67076\nPolicy Entropy: 5.37811\nValue Function Loss: 0.06995\n\nMean KL Divergence: 0.00065\nSB3 Clip Fraction: 0.02359\nPolicy Update Magnitude: 0.19491\nValue Function Update Magnitude: 0.09038\n\nCollected Steps per Second: 1,533.22398\nOverall Steps per Second: 1,130.97475\n\nTimestep Collection Time: 26.08882\nTimestep Consumption Time: 9.27890\nPPO Batch Consumption Time: 1.00801\nTotal Iteration Time: 35.36772\n\nCumulative Model Updates: 19,515\nCumulative Timesteps: 97,722,538\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 114.75463\nPolicy Entropy: 5.36607\nValue Function Loss: 0.07265\n\nMean KL Divergence: 0.00076\nSB3 Clip Fraction: 0.02968\nPolicy Update Magnitude: 0.19527\nValue Function Update Magnitude: 0.08970\n\nCollected Steps per Second: 1,626.75094\nOverall Steps per Second: 1,182.04187\n\nTimestep Collection Time: 24.59012\nTimestep Consumption Time: 9.25132\nPPO Batch Consumption Time: 0.99210\nTotal Iteration Time: 33.84144\n\nCumulative Model Updates: 19,523\nCumulative Timesteps: 97,762,540\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 97762540...\nCheckpoint 97762540 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 117.15891\nPolicy Entropy: 5.35703\nValue Function Loss: 0.07323\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.03006\nPolicy Update Magnitude: 0.20194\nValue Function Update Magnitude: 0.09362\n\nCollected Steps per Second: 1,613.50466\nOverall Steps per Second: 1,178.43662\n\nTimestep Collection Time: 24.79076\nTimestep Consumption Time: 9.15252\nPPO Batch Consumption Time: 0.98562\nTotal Iteration Time: 33.94328\n\nCumulative Model Updates: 19,531\nCumulative Timesteps: 97,802,540\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 109.84330\nPolicy Entropy: 5.36645\nValue Function Loss: 0.07030\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.02902\nPolicy Update Magnitude: 0.20284\nValue Function Update Magnitude: 0.08649\n\nCollected Steps per Second: 1,634.72081\nOverall Steps per Second: 1,184.95066\n\nTimestep Collection Time: 24.47023\nTimestep Consumption Time: 9.28813\nPPO Batch Consumption Time: 0.99488\nTotal Iteration Time: 33.75837\n\nCumulative Model Updates: 19,539\nCumulative Timesteps: 97,842,542\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 94.04710\nPolicy Entropy: 5.37006\nValue Function Loss: 0.06969\n\nMean KL Divergence: 0.00075\nSB3 Clip Fraction: 0.02800\nPolicy Update Magnitude: 0.19934\nValue Function Update Magnitude: 0.08068\n\nCollected Steps per Second: 1,570.12109\nOverall Steps per Second: 1,151.77664\n\nTimestep Collection Time: 25.47702\nTimestep Consumption Time: 9.25368\nPPO Batch Consumption Time: 1.00220\nTotal Iteration Time: 34.73069\n\nCumulative Model Updates: 19,547\nCumulative Timesteps: 97,882,544\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 91.49039\nPolicy Entropy: 5.39242\nValue Function Loss: 0.06897\n\nMean KL Divergence: 0.00081\nSB3 Clip Fraction: 0.03290\nPolicy Update Magnitude: 0.19905\nValue Function Update Magnitude: 0.08429\n\nCollected Steps per Second: 1,559.76343\nOverall Steps per Second: 1,156.16947\n\nTimestep Collection Time: 25.64491\nTimestep Consumption Time: 8.95209\nPPO Batch Consumption Time: 0.99245\nTotal Iteration Time: 34.59700\n\nCumulative Model Updates: 19,555\nCumulative Timesteps: 97,922,544\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 92.36118\nPolicy Entropy: 5.41031\nValue Function Loss: 0.07078\n\nMean KL Divergence: 0.00091\nSB3 Clip Fraction: 0.03730\nPolicy Update Magnitude: 0.20867\nValue Function Update Magnitude: 0.09233\n\nCollected Steps per Second: 1,602.82566\nOverall Steps per Second: 1,182.06089\n\nTimestep Collection Time: 24.95593\nTimestep Consumption Time: 8.88328\nPPO Batch Consumption Time: 0.98819\nTotal Iteration Time: 33.83920\n\nCumulative Model Updates: 19,563\nCumulative Timesteps: 97,962,544\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 83.92538\nPolicy Entropy: 5.39148\nValue Function Loss: 0.07313\n\nMean KL Divergence: 0.00076\nSB3 Clip Fraction: 0.02875\nPolicy Update Magnitude: 0.20422\nValue Function Update Magnitude: 0.09137\n\nCollected Steps per Second: 1,591.35219\nOverall Steps per Second: 1,180.53990\n\nTimestep Collection Time: 25.13711\nTimestep Consumption Time: 8.74738\nPPO Batch Consumption Time: 0.97203\nTotal Iteration Time: 33.88450\n\nCumulative Model Updates: 19,571\nCumulative Timesteps: 98,002,546\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 119.85952\nPolicy Entropy: 5.37046\nValue Function Loss: 0.07619\n\nMean KL Divergence: 0.00081\nSB3 Clip Fraction: 0.03211\nPolicy Update Magnitude: 0.21078\nValue Function Update Magnitude: 0.09350\n\nCollected Steps per Second: 1,610.84412\nOverall Steps per Second: 1,186.48524\n\nTimestep Collection Time: 24.83294\nTimestep Consumption Time: 8.88176\nPPO Batch Consumption Time: 0.98269\nTotal Iteration Time: 33.71471\n\nCumulative Model Updates: 19,579\nCumulative Timesteps: 98,042,548\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 105.82079\nPolicy Entropy: 5.35671\nValue Function Loss: 0.07566\n\nMean KL Divergence: 0.00090\nSB3 Clip Fraction: 0.03635\nPolicy Update Magnitude: 0.21020\nValue Function Update Magnitude: 0.09338\n\nCollected Steps per Second: 1,603.32128\nOverall Steps per Second: 1,182.91859\n\nTimestep Collection Time: 24.94946\nTimestep Consumption Time: 8.86690\nPPO Batch Consumption Time: 0.99212\nTotal Iteration Time: 33.81636\n\nCumulative Model Updates: 19,587\nCumulative Timesteps: 98,082,550\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 90.23427\nPolicy Entropy: 5.35709\nValue Function Loss: 0.07467\n\nMean KL Divergence: 0.00086\nSB3 Clip Fraction: 0.03337\nPolicy Update Magnitude: 0.21234\nValue Function Update Magnitude: 0.09296\n\nCollected Steps per Second: 1,605.02026\nOverall Steps per Second: 1,182.10890\n\nTimestep Collection Time: 24.92180\nTimestep Consumption Time: 8.91603\nPPO Batch Consumption Time: 0.99898\nTotal Iteration Time: 33.83783\n\nCumulative Model Updates: 19,595\nCumulative Timesteps: 98,122,550\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 73.09260\nPolicy Entropy: 5.38836\nValue Function Loss: 0.07284\n\nMean KL Divergence: 0.00089\nSB3 Clip Fraction: 0.02989\nPolicy Update Magnitude: 0.22646\nValue Function Update Magnitude: 0.09623\n\nCollected Steps per Second: 1,668.29977\nOverall Steps per Second: 1,223.45176\n\nTimestep Collection Time: 23.97771\nTimestep Consumption Time: 8.71831\nPPO Batch Consumption Time: 0.97414\nTotal Iteration Time: 32.69602\n\nCumulative Model Updates: 19,603\nCumulative Timesteps: 98,162,552\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 99.65957\nPolicy Entropy: 5.39012\nValue Function Loss: 0.07267\n\nMean KL Divergence: 0.00067\nSB3 Clip Fraction: 0.02376\nPolicy Update Magnitude: 0.22783\nValue Function Update Magnitude: 0.09247\n\nCollected Steps per Second: 1,731.05827\nOverall Steps per Second: 1,258.55742\n\nTimestep Collection Time: 23.10725\nTimestep Consumption Time: 8.67517\nPPO Batch Consumption Time: 0.96650\nTotal Iteration Time: 31.78242\n\nCumulative Model Updates: 19,611\nCumulative Timesteps: 98,202,552\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 94.03077\nPolicy Entropy: 5.37456\nValue Function Loss: 0.07438\n\nMean KL Divergence: 0.00070\nSB3 Clip Fraction: 0.02658\nPolicy Update Magnitude: 0.21410\nValue Function Update Magnitude: 0.09591\n\nCollected Steps per Second: 1,639.12724\nOverall Steps per Second: 1,199.47982\n\nTimestep Collection Time: 24.40445\nTimestep Consumption Time: 8.94501\nPPO Batch Consumption Time: 0.99324\nTotal Iteration Time: 33.34946\n\nCumulative Model Updates: 19,619\nCumulative Timesteps: 98,242,554\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 106.55742\nPolicy Entropy: 5.36205\nValue Function Loss: 0.07503\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.02984\nPolicy Update Magnitude: 0.20753\nValue Function Update Magnitude: 0.09322\n\nCollected Steps per Second: 1,621.39571\nOverall Steps per Second: 1,191.88663\n\nTimestep Collection Time: 24.67134\nTimestep Consumption Time: 8.89058\nPPO Batch Consumption Time: 0.98734\nTotal Iteration Time: 33.56192\n\nCumulative Model Updates: 19,627\nCumulative Timesteps: 98,282,556\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 98282556...\nCheckpoint 98282556 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 77.37790\nPolicy Entropy: 5.34115\nValue Function Loss: 0.07344\n\nMean KL Divergence: 0.00087\nSB3 Clip Fraction: 0.03366\nPolicy Update Magnitude: 0.21377\nValue Function Update Magnitude: 0.08888\n\nCollected Steps per Second: 1,608.30160\nOverall Steps per Second: 1,144.96462\n\nTimestep Collection Time: 24.87096\nTimestep Consumption Time: 10.06462\nPPO Batch Consumption Time: 1.00628\nTotal Iteration Time: 34.93558\n\nCumulative Model Updates: 19,635\nCumulative Timesteps: 98,322,556\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 71.81551\nPolicy Entropy: 5.36687\nValue Function Loss: 0.07330\n\nMean KL Divergence: 0.00085\nSB3 Clip Fraction: 0.03336\nPolicy Update Magnitude: 0.22311\nValue Function Update Magnitude: 0.09221\n\nCollected Steps per Second: 1,684.47825\nOverall Steps per Second: 1,214.83480\n\nTimestep Collection Time: 23.74741\nTimestep Consumption Time: 9.18052\nPPO Batch Consumption Time: 0.98972\nTotal Iteration Time: 32.92793\n\nCumulative Model Updates: 19,643\nCumulative Timesteps: 98,362,558\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 90.69074\nPolicy Entropy: 5.35505\nValue Function Loss: 0.07349\n\nMean KL Divergence: 0.00082\nSB3 Clip Fraction: 0.03217\nPolicy Update Magnitude: 0.21247\nValue Function Update Magnitude: 0.08888\n\nCollected Steps per Second: 1,673.38192\nOverall Steps per Second: 1,204.84989\n\nTimestep Collection Time: 23.90488\nTimestep Consumption Time: 9.29593\nPPO Batch Consumption Time: 0.99254\nTotal Iteration Time: 33.20082\n\nCumulative Model Updates: 19,651\nCumulative Timesteps: 98,402,560\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 127.00010\nPolicy Entropy: 5.36238\nValue Function Loss: 0.06985\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.02809\nPolicy Update Magnitude: 0.20428\nValue Function Update Magnitude: 0.09035\n\nCollected Steps per Second: 1,739.45044\nOverall Steps per Second: 1,249.52220\n\nTimestep Collection Time: 22.99692\nTimestep Consumption Time: 9.01692\nPPO Batch Consumption Time: 0.96994\nTotal Iteration Time: 32.01384\n\nCumulative Model Updates: 19,659\nCumulative Timesteps: 98,442,562\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 101.59570\nPolicy Entropy: 5.35048\nValue Function Loss: 0.07066\n\nMean KL Divergence: 0.00087\nSB3 Clip Fraction: 0.03493\nPolicy Update Magnitude: 0.19442\nValue Function Update Magnitude: 0.08868\n\nCollected Steps per Second: 1,729.36940\nOverall Steps per Second: 1,245.79223\n\nTimestep Collection Time: 23.12982\nTimestep Consumption Time: 8.97826\nPPO Batch Consumption Time: 0.97055\nTotal Iteration Time: 32.10808\n\nCumulative Model Updates: 19,667\nCumulative Timesteps: 98,482,562\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 96.24181\nPolicy Entropy: 5.36855\nValue Function Loss: 0.07393\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02540\nPolicy Update Magnitude: 0.19366\nValue Function Update Magnitude: 0.09001\n\nCollected Steps per Second: 1,732.75607\nOverall Steps per Second: 1,239.35971\n\nTimestep Collection Time: 23.08461\nTimestep Consumption Time: 9.19012\nPPO Batch Consumption Time: 0.99707\nTotal Iteration Time: 32.27473\n\nCumulative Model Updates: 19,675\nCumulative Timesteps: 98,522,562\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 92.91018\nPolicy Entropy: 5.37778\nValue Function Loss: 0.07154\n\nMean KL Divergence: 0.00063\nSB3 Clip Fraction: 0.02192\nPolicy Update Magnitude: 0.20146\nValue Function Update Magnitude: 0.08998\n\nCollected Steps per Second: 1,697.23730\nOverall Steps per Second: 1,240.10013\n\nTimestep Collection Time: 23.56889\nTimestep Consumption Time: 8.68818\nPPO Batch Consumption Time: 0.96977\nTotal Iteration Time: 32.25707\n\nCumulative Model Updates: 19,683\nCumulative Timesteps: 98,562,564\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 131.87031\nPolicy Entropy: 5.38108\nValue Function Loss: 0.06882\n\nMean KL Divergence: 0.00066\nSB3 Clip Fraction: 0.02361\nPolicy Update Magnitude: 0.20553\nValue Function Update Magnitude: 0.08832\n\nCollected Steps per Second: 1,726.80242\nOverall Steps per Second: 1,256.02028\n\nTimestep Collection Time: 23.16536\nTimestep Consumption Time: 8.68285\nPPO Batch Consumption Time: 0.96873\nTotal Iteration Time: 31.84821\n\nCumulative Model Updates: 19,691\nCumulative Timesteps: 98,602,566\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 110.93524\nPolicy Entropy: 5.35649\nValue Function Loss: 0.07060\n\nMean KL Divergence: 0.00061\nSB3 Clip Fraction: 0.02048\nPolicy Update Magnitude: 0.20216\nValue Function Update Magnitude: 0.08287\n\nCollected Steps per Second: 1,719.25901\nOverall Steps per Second: 1,258.94131\n\nTimestep Collection Time: 23.26700\nTimestep Consumption Time: 8.50732\nPPO Batch Consumption Time: 0.95251\nTotal Iteration Time: 31.77432\n\nCumulative Model Updates: 19,699\nCumulative Timesteps: 98,642,568\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 117.57668\nPolicy Entropy: 5.37042\nValue Function Loss: 0.06913\n\nMean KL Divergence: 0.00076\nSB3 Clip Fraction: 0.02910\nPolicy Update Magnitude: 0.19901\nValue Function Update Magnitude: 0.08914\n\nCollected Steps per Second: 1,717.93651\nOverall Steps per Second: 1,245.65530\n\nTimestep Collection Time: 23.28491\nTimestep Consumption Time: 8.82831\nPPO Batch Consumption Time: 0.98614\nTotal Iteration Time: 32.11322\n\nCumulative Model Updates: 19,707\nCumulative Timesteps: 98,682,570\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 110.77850\nPolicy Entropy: 5.36852\nValue Function Loss: 0.06968\n\nMean KL Divergence: 0.00073\nSB3 Clip Fraction: 0.02723\nPolicy Update Magnitude: 0.20345\nValue Function Update Magnitude: 0.08732\n\nCollected Steps per Second: 1,711.54120\nOverall Steps per Second: 1,249.79526\n\nTimestep Collection Time: 23.37192\nTimestep Consumption Time: 8.63492\nPPO Batch Consumption Time: 0.96499\nTotal Iteration Time: 32.00684\n\nCumulative Model Updates: 19,715\nCumulative Timesteps: 98,722,572\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 70.02277\nPolicy Entropy: 5.38680\nValue Function Loss: 0.07238\n\nMean KL Divergence: 0.00083\nSB3 Clip Fraction: 0.03330\nPolicy Update Magnitude: 0.20584\nValue Function Update Magnitude: 0.08677\n\nCollected Steps per Second: 1,717.94111\nOverall Steps per Second: 1,250.40460\n\nTimestep Collection Time: 23.28485\nTimestep Consumption Time: 8.70640\nPPO Batch Consumption Time: 0.97561\nTotal Iteration Time: 31.99124\n\nCumulative Model Updates: 19,723\nCumulative Timesteps: 98,762,574\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 101.55554\nPolicy Entropy: 5.38093\nValue Function Loss: 0.06849\n\nMean KL Divergence: 0.00090\nSB3 Clip Fraction: 0.03701\nPolicy Update Magnitude: 0.20554\nValue Function Update Magnitude: 0.08859\n\nCollected Steps per Second: 1,726.99776\nOverall Steps per Second: 1,249.74650\n\nTimestep Collection Time: 23.16274\nTimestep Consumption Time: 8.84535\nPPO Batch Consumption Time: 0.98869\nTotal Iteration Time: 32.00809\n\nCumulative Model Updates: 19,731\nCumulative Timesteps: 98,802,576\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 98802576...\nCheckpoint 98802576 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 80.51616\nPolicy Entropy: 5.35633\nValue Function Loss: 0.06829\n\nMean KL Divergence: 0.00083\nSB3 Clip Fraction: 0.03405\nPolicy Update Magnitude: 0.19785\nValue Function Update Magnitude: 0.08461\n\nCollected Steps per Second: 1,689.25112\nOverall Steps per Second: 1,233.15805\n\nTimestep Collection Time: 23.67913\nTimestep Consumption Time: 8.75791\nPPO Batch Consumption Time: 0.97970\nTotal Iteration Time: 32.43704\n\nCumulative Model Updates: 19,739\nCumulative Timesteps: 98,842,576\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 115.82325\nPolicy Entropy: 5.36628\nValue Function Loss: 0.07038\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02626\nPolicy Update Magnitude: 0.19612\nValue Function Update Magnitude: 0.08942\n\nCollected Steps per Second: 1,682.43688\nOverall Steps per Second: 1,219.09975\n\nTimestep Collection Time: 23.77504\nTimestep Consumption Time: 9.03606\nPPO Batch Consumption Time: 1.01179\nTotal Iteration Time: 32.81110\n\nCumulative Model Updates: 19,747\nCumulative Timesteps: 98,882,576\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 117.77407\nPolicy Entropy: 5.36793\nValue Function Loss: 0.06942\n\nMean KL Divergence: 0.00067\nSB3 Clip Fraction: 0.02532\nPolicy Update Magnitude: 0.19918\nValue Function Update Magnitude: 0.08834\n\nCollected Steps per Second: 1,496.19149\nOverall Steps per Second: 1,128.25403\n\nTimestep Collection Time: 26.73588\nTimestep Consumption Time: 8.71890\nPPO Batch Consumption Time: 0.96694\nTotal Iteration Time: 35.45478\n\nCumulative Model Updates: 19,755\nCumulative Timesteps: 98,922,578\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 117.27470\nPolicy Entropy: 5.35537\nValue Function Loss: 0.07130\n\nMean KL Divergence: 0.00071\nSB3 Clip Fraction: 0.02650\nPolicy Update Magnitude: 0.20053\nValue Function Update Magnitude: 0.08871\n\nCollected Steps per Second: 1,669.31632\nOverall Steps per Second: 1,222.63688\n\nTimestep Collection Time: 23.96310\nTimestep Consumption Time: 8.75471\nPPO Batch Consumption Time: 0.97703\nTotal Iteration Time: 32.71781\n\nCumulative Model Updates: 19,763\nCumulative Timesteps: 98,962,580\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 114.11785\nPolicy Entropy: 5.33304\nValue Function Loss: 0.07530\n\nMean KL Divergence: 0.00061\nSB3 Clip Fraction: 0.02112\nPolicy Update Magnitude: 0.20008\nValue Function Update Magnitude: 0.08874\n\nCollected Steps per Second: 1,669.19669\nOverall Steps per Second: 1,227.38934\n\nTimestep Collection Time: 23.96362\nTimestep Consumption Time: 8.62587\nPPO Batch Consumption Time: 0.96531\nTotal Iteration Time: 32.58950\n\nCumulative Model Updates: 19,771\nCumulative Timesteps: 99,002,580\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 105.39760\nPolicy Entropy: 5.35711\nValue Function Loss: 0.07282\n\nMean KL Divergence: 0.00068\nSB3 Clip Fraction: 0.02631\nPolicy Update Magnitude: 0.19927\nValue Function Update Magnitude: 0.09460\n\nCollected Steps per Second: 1,732.68139\nOverall Steps per Second: 1,242.69677\n\nTimestep Collection Time: 23.08561\nTimestep Consumption Time: 9.10246\nPPO Batch Consumption Time: 0.98259\nTotal Iteration Time: 32.18806\n\nCumulative Model Updates: 19,779\nCumulative Timesteps: 99,042,580\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 125.42819\nPolicy Entropy: 5.37105\nValue Function Loss: 0.07000\n\nMean KL Divergence: 0.00075\nSB3 Clip Fraction: 0.02904\nPolicy Update Magnitude: 0.20245\nValue Function Update Magnitude: 0.09442\n\nCollected Steps per Second: 1,685.37238\nOverall Steps per Second: 1,216.05797\n\nTimestep Collection Time: 23.73363\nTimestep Consumption Time: 9.15954\nPPO Batch Consumption Time: 0.98217\nTotal Iteration Time: 32.89317\n\nCumulative Model Updates: 19,787\nCumulative Timesteps: 99,082,580\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 81.84307\nPolicy Entropy: 5.34648\nValue Function Loss: 0.06878\n\nMean KL Divergence: 0.00075\nSB3 Clip Fraction: 0.02824\nPolicy Update Magnitude: 0.20182\nValue Function Update Magnitude: 0.09628\n\nCollected Steps per Second: 1,697.70770\nOverall Steps per Second: 1,222.74945\n\nTimestep Collection Time: 23.56236\nTimestep Consumption Time: 9.15244\nPPO Batch Consumption Time: 0.98636\nTotal Iteration Time: 32.71480\n\nCumulative Model Updates: 19,795\nCumulative Timesteps: 99,122,582\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 96.12779\nPolicy Entropy: 5.33941\nValue Function Loss: 0.06511\n\nMean KL Divergence: 0.00069\nSB3 Clip Fraction: 0.02618\nPolicy Update Magnitude: 0.19950\nValue Function Update Magnitude: 0.09319\n\nCollected Steps per Second: 1,734.46959\nOverall Steps per Second: 1,244.83848\n\nTimestep Collection Time: 23.06296\nTimestep Consumption Time: 9.07133\nPPO Batch Consumption Time: 0.97658\nTotal Iteration Time: 32.13429\n\nCumulative Model Updates: 19,803\nCumulative Timesteps: 99,162,584\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 98.46509\nPolicy Entropy: 5.34639\nValue Function Loss: 0.06784\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02676\nPolicy Update Magnitude: 0.20112\nValue Function Update Magnitude: 0.08837\n\nCollected Steps per Second: 1,746.49621\nOverall Steps per Second: 1,249.09284\n\nTimestep Collection Time: 22.90300\nTimestep Consumption Time: 9.12024\nPPO Batch Consumption Time: 0.98505\nTotal Iteration Time: 32.02324\n\nCumulative Model Updates: 19,811\nCumulative Timesteps: 99,202,584\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 89.57453\nPolicy Entropy: 5.36062\nValue Function Loss: 0.07179\n\nMean KL Divergence: 0.00064\nSB3 Clip Fraction: 0.02208\nPolicy Update Magnitude: 0.21084\nValue Function Update Magnitude: 0.09387\n\nCollected Steps per Second: 1,751.63463\nOverall Steps per Second: 1,250.98957\n\nTimestep Collection Time: 22.83581\nTimestep Consumption Time: 9.13887\nPPO Batch Consumption Time: 0.98871\nTotal Iteration Time: 31.97469\n\nCumulative Model Updates: 19,819\nCumulative Timesteps: 99,242,584\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 102.07143\nPolicy Entropy: 5.35761\nValue Function Loss: 0.07074\n\nMean KL Divergence: 0.00073\nSB3 Clip Fraction: 0.02826\nPolicy Update Magnitude: 0.20673\nValue Function Update Magnitude: 0.09192\n\nCollected Steps per Second: 1,645.32187\nOverall Steps per Second: 1,196.25231\n\nTimestep Collection Time: 24.31257\nTimestep Consumption Time: 9.12687\nPPO Batch Consumption Time: 0.98460\nTotal Iteration Time: 33.43943\n\nCumulative Model Updates: 19,827\nCumulative Timesteps: 99,282,586\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 98.67943\nPolicy Entropy: 5.36123\nValue Function Loss: 0.07015\n\nMean KL Divergence: 0.00062\nSB3 Clip Fraction: 0.02221\nPolicy Update Magnitude: 0.20794\nValue Function Update Magnitude: 0.09051\n\nCollected Steps per Second: 1,657.80665\nOverall Steps per Second: 1,209.61227\n\nTimestep Collection Time: 24.12947\nTimestep Consumption Time: 8.94063\nPPO Batch Consumption Time: 0.99761\nTotal Iteration Time: 33.07010\n\nCumulative Model Updates: 19,835\nCumulative Timesteps: 99,322,588\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 99322588...\nCheckpoint 99322588 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 74.19231\nPolicy Entropy: 5.36509\nValue Function Loss: 0.06772\n\nMean KL Divergence: 0.00069\nSB3 Clip Fraction: 0.02444\nPolicy Update Magnitude: 0.20582\nValue Function Update Magnitude: 0.09314\n\nCollected Steps per Second: 1,622.75160\nOverall Steps per Second: 1,189.06677\n\nTimestep Collection Time: 24.65072\nTimestep Consumption Time: 8.99079\nPPO Batch Consumption Time: 0.99851\nTotal Iteration Time: 33.64151\n\nCumulative Model Updates: 19,843\nCumulative Timesteps: 99,362,590\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 91.13461\nPolicy Entropy: 5.36310\nValue Function Loss: 0.06928\n\nMean KL Divergence: 0.00070\nSB3 Clip Fraction: 0.02648\nPolicy Update Magnitude: 0.20428\nValue Function Update Magnitude: 0.09148\n\nCollected Steps per Second: 1,612.09311\nOverall Steps per Second: 1,181.26932\n\nTimestep Collection Time: 24.81370\nTimestep Consumption Time: 9.04987\nPPO Batch Consumption Time: 1.00407\nTotal Iteration Time: 33.86357\n\nCumulative Model Updates: 19,851\nCumulative Timesteps: 99,402,592\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 82.14412\nPolicy Entropy: 5.36002\nValue Function Loss: 0.06880\n\nMean KL Divergence: 0.00079\nSB3 Clip Fraction: 0.03025\nPolicy Update Magnitude: 0.20853\nValue Function Update Magnitude: 0.09666\n\nCollected Steps per Second: 1,599.84631\nOverall Steps per Second: 1,177.56373\n\nTimestep Collection Time: 25.00240\nTimestep Consumption Time: 8.96604\nPPO Batch Consumption Time: 1.00250\nTotal Iteration Time: 33.96844\n\nCumulative Model Updates: 19,859\nCumulative Timesteps: 99,442,592\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 125.31426\nPolicy Entropy: 5.35672\nValue Function Loss: 0.06990\n\nMean KL Divergence: 0.00075\nSB3 Clip Fraction: 0.02910\nPolicy Update Magnitude: 0.20234\nValue Function Update Magnitude: 0.09218\n\nCollected Steps per Second: 1,568.22592\nOverall Steps per Second: 1,165.95621\n\nTimestep Collection Time: 25.50653\nTimestep Consumption Time: 8.80008\nPPO Batch Consumption Time: 0.98316\nTotal Iteration Time: 34.30661\n\nCumulative Model Updates: 19,867\nCumulative Timesteps: 99,482,592\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 76.46184\nPolicy Entropy: 5.33709\nValue Function Loss: 0.07199\n\nMean KL Divergence: 0.00101\nSB3 Clip Fraction: 0.04170\nPolicy Update Magnitude: 0.19953\nValue Function Update Magnitude: 0.09154\n\nCollected Steps per Second: 1,581.40416\nOverall Steps per Second: 1,174.90105\n\nTimestep Collection Time: 25.29524\nTimestep Consumption Time: 8.75188\nPPO Batch Consumption Time: 0.97531\nTotal Iteration Time: 34.04712\n\nCumulative Model Updates: 19,875\nCumulative Timesteps: 99,522,594\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 107.22932\nPolicy Entropy: 5.36863\nValue Function Loss: 0.07003\n\nMean KL Divergence: 0.00067\nSB3 Clip Fraction: 0.02435\nPolicy Update Magnitude: 0.21637\nValue Function Update Magnitude: 0.09810\n\nCollected Steps per Second: 1,606.52795\nOverall Steps per Second: 1,185.23723\n\nTimestep Collection Time: 24.89842\nTimestep Consumption Time: 8.85010\nPPO Batch Consumption Time: 0.98828\nTotal Iteration Time: 33.74852\n\nCumulative Model Updates: 19,883\nCumulative Timesteps: 99,562,594\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 108.25601\nPolicy Entropy: 5.35578\nValue Function Loss: 0.07035\n\nMean KL Divergence: 0.00084\nSB3 Clip Fraction: 0.03191\nPolicy Update Magnitude: 0.23127\nValue Function Update Magnitude: 0.09807\n\nCollected Steps per Second: 1,586.39383\nOverall Steps per Second: 1,174.71355\n\nTimestep Collection Time: 25.21442\nTimestep Consumption Time: 8.83643\nPPO Batch Consumption Time: 0.98518\nTotal Iteration Time: 34.05085\n\nCumulative Model Updates: 19,891\nCumulative Timesteps: 99,602,594\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 53.89065\nPolicy Entropy: 5.33838\nValue Function Loss: 0.07215\n\nMean KL Divergence: 0.00091\nSB3 Clip Fraction: 0.03532\nPolicy Update Magnitude: 0.22422\nValue Function Update Magnitude: 0.09953\n\nCollected Steps per Second: 1,576.50959\nOverall Steps per Second: 1,166.60867\n\nTimestep Collection Time: 25.37378\nTimestep Consumption Time: 8.91536\nPPO Batch Consumption Time: 0.99627\nTotal Iteration Time: 34.28913\n\nCumulative Model Updates: 19,899\nCumulative Timesteps: 99,642,596\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 91.90759\nPolicy Entropy: 5.33782\nValue Function Loss: 0.07422\n\nMean KL Divergence: 0.00080\nSB3 Clip Fraction: 0.03201\nPolicy Update Magnitude: 0.22210\nValue Function Update Magnitude: 0.09730\n\nCollected Steps per Second: 1,597.53231\nOverall Steps per Second: 1,178.42452\n\nTimestep Collection Time: 25.03987\nTimestep Consumption Time: 8.90545\nPPO Batch Consumption Time: 0.99179\nTotal Iteration Time: 33.94532\n\nCumulative Model Updates: 19,907\nCumulative Timesteps: 99,682,598\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 127.89004\nPolicy Entropy: 5.34339\nValue Function Loss: 0.07360\n\nMean KL Divergence: 0.00087\nSB3 Clip Fraction: 0.03425\nPolicy Update Magnitude: 0.21532\nValue Function Update Magnitude: 0.09393\n\nCollected Steps per Second: 1,621.41339\nOverall Steps per Second: 1,189.12119\n\nTimestep Collection Time: 24.67107\nTimestep Consumption Time: 8.96890\nPPO Batch Consumption Time: 0.99644\nTotal Iteration Time: 33.63997\n\nCumulative Model Updates: 19,915\nCumulative Timesteps: 99,722,600\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 97.37686\nPolicy Entropy: 5.36437\nValue Function Loss: 0.07122\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.02653\nPolicy Update Magnitude: 0.21945\nValue Function Update Magnitude: 0.09593\n\nCollected Steps per Second: 1,588.29893\nOverall Steps per Second: 1,169.29869\n\nTimestep Collection Time: 25.18544\nTimestep Consumption Time: 9.02481\nPPO Batch Consumption Time: 1.00622\nTotal Iteration Time: 34.21025\n\nCumulative Model Updates: 19,923\nCumulative Timesteps: 99,762,602\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 100.13074\nPolicy Entropy: 5.35203\nValue Function Loss: 0.07072\n\nMean KL Divergence: 0.00071\nSB3 Clip Fraction: 0.02677\nPolicy Update Magnitude: 0.21724\nValue Function Update Magnitude: 0.09138\n\nCollected Steps per Second: 1,613.45502\nOverall Steps per Second: 1,189.81806\n\nTimestep Collection Time: 24.79276\nTimestep Consumption Time: 8.82751\nPPO Batch Consumption Time: 0.98146\nTotal Iteration Time: 33.62027\n\nCumulative Model Updates: 19,931\nCumulative Timesteps: 99,802,604\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 103.15331\nPolicy Entropy: 5.33557\nValue Function Loss: 0.07232\n\nMean KL Divergence: 0.00079\nSB3 Clip Fraction: 0.03076\nPolicy Update Magnitude: 0.20252\nValue Function Update Magnitude: 0.09177\n\nCollected Steps per Second: 1,600.18048\nOverall Steps per Second: 1,162.05633\n\nTimestep Collection Time: 24.99718\nTimestep Consumption Time: 9.42456\nPPO Batch Consumption Time: 1.02166\nTotal Iteration Time: 34.42174\n\nCumulative Model Updates: 19,939\nCumulative Timesteps: 99,842,604\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 99842604...\nCheckpoint 99842604 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 106.82673\nPolicy Entropy: 5.35232\nValue Function Loss: 0.07219\n\nMean KL Divergence: 0.00066\nSB3 Clip Fraction: 0.02329\nPolicy Update Magnitude: 0.20702\nValue Function Update Magnitude: 0.09330\n\nCollected Steps per Second: 1,607.94603\nOverall Steps per Second: 1,169.24123\n\nTimestep Collection Time: 24.87770\nTimestep Consumption Time: 9.33423\nPPO Batch Consumption Time: 1.00014\nTotal Iteration Time: 34.21193\n\nCumulative Model Updates: 19,947\nCumulative Timesteps: 99,882,606\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 98.53120\nPolicy Entropy: 5.36709\nValue Function Loss: 0.06815\n\nMean KL Divergence: 0.00080\nSB3 Clip Fraction: 0.02986\nPolicy Update Magnitude: 0.21093\nValue Function Update Magnitude: 0.09419\n\nCollected Steps per Second: 1,672.92780\nOverall Steps per Second: 1,206.10161\n\nTimestep Collection Time: 23.91137\nTimestep Consumption Time: 9.25499\nPPO Batch Consumption Time: 0.99875\nTotal Iteration Time: 33.16636\n\nCumulative Model Updates: 19,955\nCumulative Timesteps: 99,922,608\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 99.33793\nPolicy Entropy: 5.37595\nValue Function Loss: 0.06894\n\nMean KL Divergence: 0.00075\nSB3 Clip Fraction: 0.02750\nPolicy Update Magnitude: 0.21122\nValue Function Update Magnitude: 0.09345\n\nCollected Steps per Second: 1,667.61432\nOverall Steps per Second: 1,200.79179\n\nTimestep Collection Time: 23.98756\nTimestep Consumption Time: 9.32546\nPPO Batch Consumption Time: 1.00535\nTotal Iteration Time: 33.31302\n\nCumulative Model Updates: 19,963\nCumulative Timesteps: 99,962,610\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 64.58135\nPolicy Entropy: 5.34741\nValue Function Loss: 0.07289\n\nMean KL Divergence: 0.00078\nSB3 Clip Fraction: 0.02751\nPolicy Update Magnitude: 0.20688\nValue Function Update Magnitude: 0.09813\n\nCollected Steps per Second: 1,604.67579\nOverall Steps per Second: 1,170.29269\n\nTimestep Collection Time: 24.92715\nTimestep Consumption Time: 9.25233\nPPO Batch Consumption Time: 0.99274\nTotal Iteration Time: 34.17948\n\nCumulative Model Updates: 19,971\nCumulative Timesteps: 100,002,610\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 107.46239\nPolicy Entropy: 5.35211\nValue Function Loss: 0.07100\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.03060\nPolicy Update Magnitude: 0.20351\nValue Function Update Magnitude: 0.09325\n\nCollected Steps per Second: 1,618.20918\nOverall Steps per Second: 1,175.96661\n\nTimestep Collection Time: 24.71868\nTimestep Consumption Time: 9.29589\nPPO Batch Consumption Time: 0.99936\nTotal Iteration Time: 34.01457\n\nCumulative Model Updates: 19,979\nCumulative Timesteps: 100,042,610\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 98.58237\nPolicy Entropy: 5.34995\nValue Function Loss: 0.07149\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02686\nPolicy Update Magnitude: 0.20514\nValue Function Update Magnitude: 0.09234\n\nCollected Steps per Second: 1,489.80926\nOverall Steps per Second: 1,110.02565\n\nTimestep Collection Time: 26.85042\nTimestep Consumption Time: 9.18659\nPPO Batch Consumption Time: 0.98305\nTotal Iteration Time: 36.03701\n\nCumulative Model Updates: 19,987\nCumulative Timesteps: 100,082,612\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 110.47243\nPolicy Entropy: 5.35306\nValue Function Loss: 0.07159\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02724\nPolicy Update Magnitude: 0.20591\nValue Function Update Magnitude: 0.08541\n\nCollected Steps per Second: 1,606.15613\nOverall Steps per Second: 1,181.39682\n\nTimestep Collection Time: 24.90542\nTimestep Consumption Time: 8.95449\nPPO Batch Consumption Time: 0.96361\nTotal Iteration Time: 33.85992\n\nCumulative Model Updates: 19,995\nCumulative Timesteps: 100,122,614\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 104.34995\nPolicy Entropy: 5.35072\nValue Function Loss: 0.07159\n\nMean KL Divergence: 0.00070\nSB3 Clip Fraction: 0.02654\nPolicy Update Magnitude: 0.20605\nValue Function Update Magnitude: 0.08660\n\nCollected Steps per Second: 1,690.99039\nOverall Steps per Second: 1,218.63265\n\nTimestep Collection Time: 23.65478\nTimestep Consumption Time: 9.16890\nPPO Batch Consumption Time: 0.98301\nTotal Iteration Time: 32.82367\n\nCumulative Model Updates: 20,003\nCumulative Timesteps: 100,162,614\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 100.31216\nPolicy Entropy: 5.36798\nValue Function Loss: 0.07268\n\nMean KL Divergence: 0.00070\nSB3 Clip Fraction: 0.02776\nPolicy Update Magnitude: 0.19969\nValue Function Update Magnitude: 0.09272\n\nCollected Steps per Second: 1,683.45035\nOverall Steps per Second: 1,221.35375\n\nTimestep Collection Time: 23.76191\nTimestep Consumption Time: 8.99027\nPPO Batch Consumption Time: 0.97293\nTotal Iteration Time: 32.75218\n\nCumulative Model Updates: 20,011\nCumulative Timesteps: 100,202,616\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 101.56772\nPolicy Entropy: 5.34760\nValue Function Loss: 0.07073\n\nMean KL Divergence: 0.00089\nSB3 Clip Fraction: 0.03578\nPolicy Update Magnitude: 0.19121\nValue Function Update Magnitude: 0.08874\n\nCollected Steps per Second: 1,599.93042\nOverall Steps per Second: 1,167.70514\n\nTimestep Collection Time: 25.00234\nTimestep Consumption Time: 9.25460\nPPO Batch Consumption Time: 0.99284\nTotal Iteration Time: 34.25694\n\nCumulative Model Updates: 20,019\nCumulative Timesteps: 100,242,618\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 87.69653\nPolicy Entropy: 5.34292\nValue Function Loss: 0.07031\n\nMean KL Divergence: 0.00056\nSB3 Clip Fraction: 0.01953\nPolicy Update Magnitude: 0.19208\nValue Function Update Magnitude: 0.09092\n\nCollected Steps per Second: 1,643.80989\nOverall Steps per Second: 1,199.01673\n\nTimestep Collection Time: 24.33371\nTimestep Consumption Time: 9.02695\nPPO Batch Consumption Time: 0.97113\nTotal Iteration Time: 33.36067\n\nCumulative Model Updates: 20,027\nCumulative Timesteps: 100,282,618\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 102.59824\nPolicy Entropy: 5.34612\nValue Function Loss: 0.06921\n\nMean KL Divergence: 0.00067\nSB3 Clip Fraction: 0.02536\nPolicy Update Magnitude: 0.19213\nValue Function Update Magnitude: 0.08959\n\nCollected Steps per Second: 1,673.84472\nOverall Steps per Second: 1,208.68993\n\nTimestep Collection Time: 23.89827\nTimestep Consumption Time: 9.19706\nPPO Batch Consumption Time: 0.99276\nTotal Iteration Time: 33.09534\n\nCumulative Model Updates: 20,035\nCumulative Timesteps: 100,322,620\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 125.14456\nPolicy Entropy: 5.35317\nValue Function Loss: 0.07072\n\nMean KL Divergence: 0.00076\nSB3 Clip Fraction: 0.02971\nPolicy Update Magnitude: 0.19537\nValue Function Update Magnitude: 0.09463\n\nCollected Steps per Second: 1,631.91662\nOverall Steps per Second: 1,183.73307\n\nTimestep Collection Time: 24.51228\nTimestep Consumption Time: 9.28081\nPPO Batch Consumption Time: 0.99663\nTotal Iteration Time: 33.79309\n\nCumulative Model Updates: 20,043\nCumulative Timesteps: 100,362,622\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 100362622...\nCheckpoint 100362622 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 76.47501\nPolicy Entropy: 5.32733\nValue Function Loss: 0.07069\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02725\nPolicy Update Magnitude: 0.19423\nValue Function Update Magnitude: 0.09551\n\nCollected Steps per Second: 1,599.28463\nOverall Steps per Second: 1,169.39868\n\nTimestep Collection Time: 25.01243\nTimestep Consumption Time: 9.19489\nPPO Batch Consumption Time: 0.98483\nTotal Iteration Time: 34.20732\n\nCumulative Model Updates: 20,051\nCumulative Timesteps: 100,402,624\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 117.15468\nPolicy Entropy: 5.33870\nValue Function Loss: 0.07080\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.02856\nPolicy Update Magnitude: 0.19425\nValue Function Update Magnitude: 0.08924\n\nCollected Steps per Second: 1,668.76355\nOverall Steps per Second: 1,209.75504\n\nTimestep Collection Time: 23.96984\nTimestep Consumption Time: 9.09470\nPPO Batch Consumption Time: 0.98528\nTotal Iteration Time: 33.06455\n\nCumulative Model Updates: 20,059\nCumulative Timesteps: 100,442,624\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 112.27976\nPolicy Entropy: 5.35302\nValue Function Loss: 0.07199\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.02789\nPolicy Update Magnitude: 0.20268\nValue Function Update Magnitude: 0.08749\n\nCollected Steps per Second: 1,683.19086\nOverall Steps per Second: 1,219.56662\n\nTimestep Collection Time: 23.76558\nTimestep Consumption Time: 9.03460\nPPO Batch Consumption Time: 0.97488\nTotal Iteration Time: 32.80018\n\nCumulative Model Updates: 20,067\nCumulative Timesteps: 100,482,626\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 112.65772\nPolicy Entropy: 5.35196\nValue Function Loss: 0.07114\n\nMean KL Divergence: 0.00063\nSB3 Clip Fraction: 0.02317\nPolicy Update Magnitude: 0.20314\nValue Function Update Magnitude: 0.08553\n\nCollected Steps per Second: 1,664.74060\nOverall Steps per Second: 1,216.62425\n\nTimestep Collection Time: 24.02897\nTimestep Consumption Time: 8.85053\nPPO Batch Consumption Time: 0.98664\nTotal Iteration Time: 32.87950\n\nCumulative Model Updates: 20,075\nCumulative Timesteps: 100,522,628\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 107.51447\nPolicy Entropy: 5.35554\nValue Function Loss: 0.07068\n\nMean KL Divergence: 0.00073\nSB3 Clip Fraction: 0.02723\nPolicy Update Magnitude: 0.20280\nValue Function Update Magnitude: 0.08986\n\nCollected Steps per Second: 1,613.79738\nOverall Steps per Second: 1,192.10179\n\nTimestep Collection Time: 24.78750\nTimestep Consumption Time: 8.76836\nPPO Batch Consumption Time: 0.97842\nTotal Iteration Time: 33.55586\n\nCumulative Model Updates: 20,083\nCumulative Timesteps: 100,562,630\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 93.90808\nPolicy Entropy: 5.34194\nValue Function Loss: 0.07272\n\nMean KL Divergence: 0.00079\nSB3 Clip Fraction: 0.03119\nPolicy Update Magnitude: 0.23145\nValue Function Update Magnitude: 0.09182\n\nCollected Steps per Second: 1,621.17989\nOverall Steps per Second: 1,184.23741\n\nTimestep Collection Time: 24.67462\nTimestep Consumption Time: 9.10408\nPPO Batch Consumption Time: 1.01827\nTotal Iteration Time: 33.77870\n\nCumulative Model Updates: 20,091\nCumulative Timesteps: 100,602,632\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 74.16526\nPolicy Entropy: 5.33952\nValue Function Loss: 0.07157\n\nMean KL Divergence: 0.00079\nSB3 Clip Fraction: 0.02946\nPolicy Update Magnitude: 0.23028\nValue Function Update Magnitude: 0.09458\n\nCollected Steps per Second: 1,615.02591\nOverall Steps per Second: 1,190.38890\n\nTimestep Collection Time: 24.76864\nTimestep Consumption Time: 8.83550\nPPO Batch Consumption Time: 0.98359\nTotal Iteration Time: 33.60414\n\nCumulative Model Updates: 20,099\nCumulative Timesteps: 100,642,634\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 83.45300\nPolicy Entropy: 5.34625\nValue Function Loss: 0.06885\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.02946\nPolicy Update Magnitude: 0.21264\nValue Function Update Magnitude: 0.09581\n\nCollected Steps per Second: 1,583.59919\nOverall Steps per Second: 1,165.78693\n\nTimestep Collection Time: 25.26018\nTimestep Consumption Time: 9.05312\nPPO Batch Consumption Time: 1.01338\nTotal Iteration Time: 34.31330\n\nCumulative Model Updates: 20,107\nCumulative Timesteps: 100,682,636\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 125.04647\nPolicy Entropy: 5.33014\nValue Function Loss: 0.06804\n\nMean KL Divergence: 0.00068\nSB3 Clip Fraction: 0.02517\nPolicy Update Magnitude: 0.20352\nValue Function Update Magnitude: 0.09203\n\nCollected Steps per Second: 1,604.37617\nOverall Steps per Second: 1,180.68117\n\nTimestep Collection Time: 24.93181\nTimestep Consumption Time: 8.94694\nPPO Batch Consumption Time: 0.99812\nTotal Iteration Time: 33.87875\n\nCumulative Model Updates: 20,115\nCumulative Timesteps: 100,722,636\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 90.55833\nPolicy Entropy: 5.33566\nValue Function Loss: 0.06844\n\nMean KL Divergence: 0.00068\nSB3 Clip Fraction: 0.02501\nPolicy Update Magnitude: 0.19898\nValue Function Update Magnitude: 0.09396\n\nCollected Steps per Second: 1,590.46717\nOverall Steps per Second: 1,179.12955\n\nTimestep Collection Time: 25.15110\nTimestep Consumption Time: 8.77392\nPPO Batch Consumption Time: 0.97713\nTotal Iteration Time: 33.92503\n\nCumulative Model Updates: 20,123\nCumulative Timesteps: 100,762,638\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 87.92078\nPolicy Entropy: 5.34028\nValue Function Loss: 0.06647\n\nMean KL Divergence: 0.00071\nSB3 Clip Fraction: 0.02594\nPolicy Update Magnitude: 0.19916\nValue Function Update Magnitude: 0.08825\n\nCollected Steps per Second: 1,623.87303\nOverall Steps per Second: 1,201.53686\n\nTimestep Collection Time: 24.63370\nTimestep Consumption Time: 8.65866\nPPO Batch Consumption Time: 0.96386\nTotal Iteration Time: 33.29236\n\nCumulative Model Updates: 20,131\nCumulative Timesteps: 100,802,640\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 100.03388\nPolicy Entropy: 5.34524\nValue Function Loss: 0.07040\n\nMean KL Divergence: 0.00076\nSB3 Clip Fraction: 0.03036\nPolicy Update Magnitude: 0.20448\nValue Function Update Magnitude: 0.08436\n\nCollected Steps per Second: 1,603.00706\nOverall Steps per Second: 1,181.37084\n\nTimestep Collection Time: 24.95435\nTimestep Consumption Time: 8.90631\nPPO Batch Consumption Time: 0.99941\nTotal Iteration Time: 33.86066\n\nCumulative Model Updates: 20,139\nCumulative Timesteps: 100,842,642\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 77.81159\nPolicy Entropy: 5.37326\nValue Function Loss: 0.07411\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.02905\nPolicy Update Magnitude: 0.21465\nValue Function Update Magnitude: 0.09799\n\nCollected Steps per Second: 1,612.06174\nOverall Steps per Second: 1,190.69653\n\nTimestep Collection Time: 24.81419\nTimestep Consumption Time: 8.78128\nPPO Batch Consumption Time: 0.97764\nTotal Iteration Time: 33.59546\n\nCumulative Model Updates: 20,147\nCumulative Timesteps: 100,882,644\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 100882644...\nCheckpoint 100882644 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 89.73494\nPolicy Entropy: 5.39807\nValue Function Loss: 0.07114\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.02879\nPolicy Update Magnitude: 0.22224\nValue Function Update Magnitude: 0.09983\n\nCollected Steps per Second: 1,601.11180\nOverall Steps per Second: 1,182.05281\n\nTimestep Collection Time: 24.98264\nTimestep Consumption Time: 8.85680\nPPO Batch Consumption Time: 0.99175\nTotal Iteration Time: 33.83944\n\nCumulative Model Updates: 20,155\nCumulative Timesteps: 100,922,644\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 97.02745\nPolicy Entropy: 5.38218\nValue Function Loss: 0.06909\n\nMean KL Divergence: 0.00071\nSB3 Clip Fraction: 0.02594\nPolicy Update Magnitude: 0.22758\nValue Function Update Magnitude: 0.09480\n\nCollected Steps per Second: 1,582.08746\nOverall Steps per Second: 1,161.13228\n\nTimestep Collection Time: 25.28305\nTimestep Consumption Time: 9.16608\nPPO Batch Consumption Time: 0.98716\nTotal Iteration Time: 34.44913\n\nCumulative Model Updates: 20,163\nCumulative Timesteps: 100,962,644\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 104.96549\nPolicy Entropy: 5.37447\nValue Function Loss: 0.07111\n\nMean KL Divergence: 0.00070\nSB3 Clip Fraction: 0.02529\nPolicy Update Magnitude: 0.21311\nValue Function Update Magnitude: 0.10098\n\nCollected Steps per Second: 1,557.24339\nOverall Steps per Second: 1,140.79869\n\nTimestep Collection Time: 25.68642\nTimestep Consumption Time: 9.37674\nPPO Batch Consumption Time: 1.01236\nTotal Iteration Time: 35.06315\n\nCumulative Model Updates: 20,171\nCumulative Timesteps: 101,002,644\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 120.48081\nPolicy Entropy: 5.40581\nValue Function Loss: 0.06966\n\nMean KL Divergence: 0.00068\nSB3 Clip Fraction: 0.02452\nPolicy Update Magnitude: 0.21249\nValue Function Update Magnitude: 0.10504\n\nCollected Steps per Second: 1,624.56778\nOverall Steps per Second: 1,179.14663\n\nTimestep Collection Time: 24.62316\nTimestep Consumption Time: 9.30137\nPPO Batch Consumption Time: 0.99619\nTotal Iteration Time: 33.92453\n\nCumulative Model Updates: 20,179\nCumulative Timesteps: 101,042,646\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 133.16959\nPolicy Entropy: 5.36305\nValue Function Loss: 0.06987\n\nMean KL Divergence: 0.00070\nSB3 Clip Fraction: 0.02505\nPolicy Update Magnitude: 0.21293\nValue Function Update Magnitude: 0.09847\n\nCollected Steps per Second: 1,629.98470\nOverall Steps per Second: 1,184.90826\n\nTimestep Collection Time: 24.54133\nTimestep Consumption Time: 9.21824\nPPO Batch Consumption Time: 0.98673\nTotal Iteration Time: 33.75958\n\nCumulative Model Updates: 20,187\nCumulative Timesteps: 101,082,648\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 118.03777\nPolicy Entropy: 5.34715\nValue Function Loss: 0.07121\n\nMean KL Divergence: 0.00066\nSB3 Clip Fraction: 0.02246\nPolicy Update Magnitude: 0.20303\nValue Function Update Magnitude: 0.09183\n\nCollected Steps per Second: 1,724.23303\nOverall Steps per Second: 1,241.48056\n\nTimestep Collection Time: 23.19872\nTimestep Consumption Time: 9.02087\nPPO Batch Consumption Time: 0.97029\nTotal Iteration Time: 32.21959\n\nCumulative Model Updates: 20,195\nCumulative Timesteps: 101,122,648\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 98.15693\nPolicy Entropy: 5.37031\nValue Function Loss: 0.07064\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02788\nPolicy Update Magnitude: 0.19762\nValue Function Update Magnitude: 0.08943\n\nCollected Steps per Second: 1,767.16798\nOverall Steps per Second: 1,259.53088\n\nTimestep Collection Time: 22.63509\nTimestep Consumption Time: 9.12277\nPPO Batch Consumption Time: 0.98676\nTotal Iteration Time: 31.75786\n\nCumulative Model Updates: 20,203\nCumulative Timesteps: 101,162,648\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 67.36822\nPolicy Entropy: 5.37987\nValue Function Loss: 0.07065\n\nMean KL Divergence: 0.00068\nSB3 Clip Fraction: 0.02525\nPolicy Update Magnitude: 0.19952\nValue Function Update Magnitude: 0.08492\n\nCollected Steps per Second: 1,638.93072\nOverall Steps per Second: 1,134.79566\n\nTimestep Collection Time: 24.40738\nTimestep Consumption Time: 10.84302\nPPO Batch Consumption Time: 1.19514\nTotal Iteration Time: 35.25040\n\nCumulative Model Updates: 20,211\nCumulative Timesteps: 101,202,650\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 97.48254\nPolicy Entropy: 5.36758\nValue Function Loss: 0.06938\n\nMean KL Divergence: 0.00060\nSB3 Clip Fraction: 0.02119\nPolicy Update Magnitude: 0.20027\nValue Function Update Magnitude: 0.09199\n\nCollected Steps per Second: 1,649.84467\nOverall Steps per Second: 1,195.98913\n\nTimestep Collection Time: 24.24592\nTimestep Consumption Time: 9.20087\nPPO Batch Consumption Time: 0.98888\nTotal Iteration Time: 33.44679\n\nCumulative Model Updates: 20,219\nCumulative Timesteps: 101,242,652\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 97.78937\nPolicy Entropy: 5.34082\nValue Function Loss: 0.07022\n\nMean KL Divergence: 0.00087\nSB3 Clip Fraction: 0.03449\nPolicy Update Magnitude: 0.19413\nValue Function Update Magnitude: 0.09126\n\nCollected Steps per Second: 1,650.75247\nOverall Steps per Second: 1,199.55195\n\nTimestep Collection Time: 24.23259\nTimestep Consumption Time: 9.11487\nPPO Batch Consumption Time: 0.97902\nTotal Iteration Time: 33.34745\n\nCumulative Model Updates: 20,227\nCumulative Timesteps: 101,282,654\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 117.59373\nPolicy Entropy: 5.34807\nValue Function Loss: 0.07026\n\nMean KL Divergence: 0.00084\nSB3 Clip Fraction: 0.03218\nPolicy Update Magnitude: 0.19903\nValue Function Update Magnitude: 0.08479\n\nCollected Steps per Second: 1,693.73163\nOverall Steps per Second: 1,220.65789\n\nTimestep Collection Time: 23.61649\nTimestep Consumption Time: 9.15272\nPPO Batch Consumption Time: 0.98484\nTotal Iteration Time: 32.76921\n\nCumulative Model Updates: 20,235\nCumulative Timesteps: 101,322,654\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 89.33365\nPolicy Entropy: 5.36579\nValue Function Loss: 0.07448\n\nMean KL Divergence: 0.00079\nSB3 Clip Fraction: 0.03062\nPolicy Update Magnitude: 0.21155\nValue Function Update Magnitude: 0.09047\n\nCollected Steps per Second: 1,687.14782\nOverall Steps per Second: 1,218.12434\n\nTimestep Collection Time: 23.70984\nTimestep Consumption Time: 9.12918\nPPO Batch Consumption Time: 0.97927\nTotal Iteration Time: 32.83901\n\nCumulative Model Updates: 20,243\nCumulative Timesteps: 101,362,656\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 85.97119\nPolicy Entropy: 5.36712\nValue Function Loss: 0.07611\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.02613\nPolicy Update Magnitude: 0.21846\nValue Function Update Magnitude: 0.09511\n\nCollected Steps per Second: 1,614.38026\nOverall Steps per Second: 1,176.98260\n\nTimestep Collection Time: 24.77731\nTimestep Consumption Time: 9.20790\nPPO Batch Consumption Time: 0.98324\nTotal Iteration Time: 33.98521\n\nCumulative Model Updates: 20,251\nCumulative Timesteps: 101,402,656\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 101402656...\nCheckpoint 101402656 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 127.67273\nPolicy Entropy: 5.36989\nValue Function Loss: 0.06921\n\nMean KL Divergence: 0.00086\nSB3 Clip Fraction: 0.03349\nPolicy Update Magnitude: 0.20675\nValue Function Update Magnitude: 0.09566\n\nCollected Steps per Second: 1,666.93170\nOverall Steps per Second: 1,202.06869\n\nTimestep Collection Time: 23.99618\nTimestep Consumption Time: 9.27978\nPPO Batch Consumption Time: 0.99520\nTotal Iteration Time: 33.27597\n\nCumulative Model Updates: 20,259\nCumulative Timesteps: 101,442,656\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 75.13356\nPolicy Entropy: 5.36359\nValue Function Loss: 0.06736\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.02921\nPolicy Update Magnitude: 0.20615\nValue Function Update Magnitude: 0.09503\n\nCollected Steps per Second: 1,663.46806\nOverall Steps per Second: 1,204.41656\n\nTimestep Collection Time: 24.04615\nTimestep Consumption Time: 9.16495\nPPO Batch Consumption Time: 0.99203\nTotal Iteration Time: 33.21110\n\nCumulative Model Updates: 20,267\nCumulative Timesteps: 101,482,656\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 132.84747\nPolicy Entropy: 5.36141\nValue Function Loss: 0.07122\n\nMean KL Divergence: 0.00078\nSB3 Clip Fraction: 0.03041\nPolicy Update Magnitude: 0.20577\nValue Function Update Magnitude: 0.09911\n\nCollected Steps per Second: 1,654.75408\nOverall Steps per Second: 1,199.30277\n\nTimestep Collection Time: 24.17278\nTimestep Consumption Time: 9.17994\nPPO Batch Consumption Time: 0.98703\nTotal Iteration Time: 33.35271\n\nCumulative Model Updates: 20,275\nCumulative Timesteps: 101,522,656\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 88.95147\nPolicy Entropy: 5.37321\nValue Function Loss: 0.07068\n\nMean KL Divergence: 0.00080\nSB3 Clip Fraction: 0.03163\nPolicy Update Magnitude: 0.20621\nValue Function Update Magnitude: 0.10118\n\nCollected Steps per Second: 1,674.61726\nOverall Steps per Second: 1,212.45392\n\nTimestep Collection Time: 23.88725\nTimestep Consumption Time: 9.10534\nPPO Batch Consumption Time: 0.98146\nTotal Iteration Time: 32.99259\n\nCumulative Model Updates: 20,283\nCumulative Timesteps: 101,562,658\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 112.89247\nPolicy Entropy: 5.36949\nValue Function Loss: 0.07056\n\nMean KL Divergence: 0.00096\nSB3 Clip Fraction: 0.04050\nPolicy Update Magnitude: 0.20614\nValue Function Update Magnitude: 0.09651\n\nCollected Steps per Second: 1,652.18399\nOverall Steps per Second: 1,202.11473\n\nTimestep Collection Time: 24.21038\nTimestep Consumption Time: 9.06432\nPPO Batch Consumption Time: 0.98459\nTotal Iteration Time: 33.27469\n\nCumulative Model Updates: 20,291\nCumulative Timesteps: 101,602,658\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 126.76307\nPolicy Entropy: 5.37461\nValue Function Loss: 0.07185\n\nMean KL Divergence: 0.00080\nSB3 Clip Fraction: 0.03209\nPolicy Update Magnitude: 0.20602\nValue Function Update Magnitude: 0.09876\n\nCollected Steps per Second: 1,659.01736\nOverall Steps per Second: 1,217.97070\n\nTimestep Collection Time: 24.11066\nTimestep Consumption Time: 8.73085\nPPO Batch Consumption Time: 0.97547\nTotal Iteration Time: 32.84151\n\nCumulative Model Updates: 20,299\nCumulative Timesteps: 101,642,658\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 83.36204\nPolicy Entropy: 5.35005\nValue Function Loss: 0.07239\n\nMean KL Divergence: 0.00080\nSB3 Clip Fraction: 0.03164\nPolicy Update Magnitude: 0.20593\nValue Function Update Magnitude: 0.09746\n\nCollected Steps per Second: 1,634.20957\nOverall Steps per Second: 1,199.91740\n\nTimestep Collection Time: 24.47666\nTimestep Consumption Time: 8.85896\nPPO Batch Consumption Time: 0.98996\nTotal Iteration Time: 33.33563\n\nCumulative Model Updates: 20,307\nCumulative Timesteps: 101,682,658\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 91.38871\nPolicy Entropy: 5.35655\nValue Function Loss: 0.07358\n\nMean KL Divergence: 0.00081\nSB3 Clip Fraction: 0.03080\nPolicy Update Magnitude: 0.19948\nValue Function Update Magnitude: 0.09478\n\nCollected Steps per Second: 1,605.80766\nOverall Steps per Second: 1,182.92205\n\nTimestep Collection Time: 24.90958\nTimestep Consumption Time: 8.90499\nPPO Batch Consumption Time: 0.99272\nTotal Iteration Time: 33.81457\n\nCumulative Model Updates: 20,315\nCumulative Timesteps: 101,722,658\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 104.92156\nPolicy Entropy: 5.35952\nValue Function Loss: 0.07366\n\nMean KL Divergence: 0.00071\nSB3 Clip Fraction: 0.02603\nPolicy Update Magnitude: 0.20106\nValue Function Update Magnitude: 0.09457\n\nCollected Steps per Second: 1,590.75992\nOverall Steps per Second: 1,172.33518\n\nTimestep Collection Time: 25.14521\nTimestep Consumption Time: 8.97472\nPPO Batch Consumption Time: 0.99139\nTotal Iteration Time: 34.11993\n\nCumulative Model Updates: 20,323\nCumulative Timesteps: 101,762,658\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 89.66728\nPolicy Entropy: 5.36504\nValue Function Loss: 0.07147\n\nMean KL Divergence: 0.00086\nSB3 Clip Fraction: 0.03480\nPolicy Update Magnitude: 0.19700\nValue Function Update Magnitude: 0.09222\n\nCollected Steps per Second: 1,603.90478\nOverall Steps per Second: 1,180.79155\n\nTimestep Collection Time: 24.93914\nTimestep Consumption Time: 8.93644\nPPO Batch Consumption Time: 0.99844\nTotal Iteration Time: 33.87558\n\nCumulative Model Updates: 20,331\nCumulative Timesteps: 101,802,658\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 115.31537\nPolicy Entropy: 5.37233\nValue Function Loss: 0.07210\n\nMean KL Divergence: 0.00094\nSB3 Clip Fraction: 0.03858\nPolicy Update Magnitude: 0.20261\nValue Function Update Magnitude: 0.09429\n\nCollected Steps per Second: 1,629.34227\nOverall Steps per Second: 1,195.84254\n\nTimestep Collection Time: 24.54978\nTimestep Consumption Time: 8.89944\nPPO Batch Consumption Time: 0.99487\nTotal Iteration Time: 33.44922\n\nCumulative Model Updates: 20,339\nCumulative Timesteps: 101,842,658\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 94.55168\nPolicy Entropy: 5.36938\nValue Function Loss: 0.06931\n\nMean KL Divergence: 0.00101\nSB3 Clip Fraction: 0.04185\nPolicy Update Magnitude: 0.20794\nValue Function Update Magnitude: 0.09766\n\nCollected Steps per Second: 1,647.07292\nOverall Steps per Second: 1,209.17643\n\nTimestep Collection Time: 24.28672\nTimestep Consumption Time: 8.79530\nPPO Batch Consumption Time: 0.97903\nTotal Iteration Time: 33.08202\n\nCumulative Model Updates: 20,347\nCumulative Timesteps: 101,882,660\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 70.58965\nPolicy Entropy: 5.37569\nValue Function Loss: 0.07070\n\nMean KL Divergence: 0.00068\nSB3 Clip Fraction: 0.02289\nPolicy Update Magnitude: 0.20562\nValue Function Update Magnitude: 0.09329\n\nCollected Steps per Second: 1,597.92900\nOverall Steps per Second: 1,180.74643\n\nTimestep Collection Time: 25.03240\nTimestep Consumption Time: 8.84447\nPPO Batch Consumption Time: 0.98473\nTotal Iteration Time: 33.87688\n\nCumulative Model Updates: 20,355\nCumulative Timesteps: 101,922,660\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 101922660...\nCheckpoint 101922660 saved!\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 120.52493\nPolicy Entropy: 5.37310\nValue Function Loss: 0.07262\n\nMean KL Divergence: 0.00093\nSB3 Clip Fraction: 0.03621\nPolicy Update Magnitude: 0.21112\nValue Function Update Magnitude: 0.09985\n\nCollected Steps per Second: 1,637.36205\nOverall Steps per Second: 1,197.07933\n\nTimestep Collection Time: 24.42954\nTimestep Consumption Time: 8.98512\nPPO Batch Consumption Time: 0.99968\nTotal Iteration Time: 33.41466\n\nCumulative Model Updates: 20,363\nCumulative Timesteps: 101,962,660\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 107.21467\nPolicy Entropy: 5.37035\nValue Function Loss: 0.07080\n\nMean KL Divergence: 0.00082\nSB3 Clip Fraction: 0.03265\nPolicy Update Magnitude: 0.20286\nValue Function Update Magnitude: 0.09283\n\nCollected Steps per Second: 1,618.42920\nOverall Steps per Second: 1,192.95282\n\nTimestep Collection Time: 24.71656\nTimestep Consumption Time: 8.81536\nPPO Batch Consumption Time: 0.97889\nTotal Iteration Time: 33.53192\n\nCumulative Model Updates: 20,371\nCumulative Timesteps: 102,002,662\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 94.77023\nPolicy Entropy: 5.35901\nValue Function Loss: 0.06944\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02734\nPolicy Update Magnitude: 0.19787\nValue Function Update Magnitude: 0.09171\n\nCollected Steps per Second: 1,685.82548\nOverall Steps per Second: 1,233.25091\n\nTimestep Collection Time: 23.72843\nTimestep Consumption Time: 8.70779\nPPO Batch Consumption Time: 0.97635\nTotal Iteration Time: 32.43622\n\nCumulative Model Updates: 20,379\nCumulative Timesteps: 102,042,664\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 96.01304\nPolicy Entropy: 5.36636\nValue Function Loss: 0.07189\n\nMean KL Divergence: 0.00085\nSB3 Clip Fraction: 0.03400\nPolicy Update Magnitude: 0.19871\nValue Function Update Magnitude: 0.09607\n\nCollected Steps per Second: 1,630.75472\nOverall Steps per Second: 1,193.24765\n\nTimestep Collection Time: 24.52975\nTimestep Consumption Time: 8.99389\nPPO Batch Consumption Time: 0.99543\nTotal Iteration Time: 33.52364\n\nCumulative Model Updates: 20,387\nCumulative Timesteps: 102,082,666\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 90.18463\nPolicy Entropy: 5.39009\nValue Function Loss: 0.07124\n\nMean KL Divergence: 0.00079\nSB3 Clip Fraction: 0.03011\nPolicy Update Magnitude: 0.19993\nValue Function Update Magnitude: 0.09612\n\nCollected Steps per Second: 1,565.26528\nOverall Steps per Second: 1,151.32554\n\nTimestep Collection Time: 25.55605\nTimestep Consumption Time: 9.18825\nPPO Batch Consumption Time: 1.02289\nTotal Iteration Time: 34.74430\n\nCumulative Model Updates: 20,395\nCumulative Timesteps: 102,122,668\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 85.27816\nPolicy Entropy: 5.40284\nValue Function Loss: 0.06685\n\nMean KL Divergence: 0.00059\nSB3 Clip Fraction: 0.02141\nPolicy Update Magnitude: 0.22622\nValue Function Update Magnitude: 0.10056\n\nCollected Steps per Second: 1,567.14305\nOverall Steps per Second: 1,160.04979\n\nTimestep Collection Time: 25.52415\nTimestep Consumption Time: 8.95712\nPPO Batch Consumption Time: 0.99740\nTotal Iteration Time: 34.48128\n\nCumulative Model Updates: 20,403\nCumulative Timesteps: 102,162,668\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 103.18682\nPolicy Entropy: 5.37187\nValue Function Loss: 0.06741\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.02773\nPolicy Update Magnitude: 0.21781\nValue Function Update Magnitude: 0.09035\n\nCollected Steps per Second: 1,658.54055\nOverall Steps per Second: 1,194.05186\n\nTimestep Collection Time: 24.11759\nTimestep Consumption Time: 9.38179\nPPO Batch Consumption Time: 1.00888\nTotal Iteration Time: 33.49938\n\nCumulative Model Updates: 20,411\nCumulative Timesteps: 102,202,668\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 75.38223\nPolicy Entropy: 5.35820\nValue Function Loss: 0.06911\n\nMean KL Divergence: 0.00063\nSB3 Clip Fraction: 0.02341\nPolicy Update Magnitude: 0.19907\nValue Function Update Magnitude: 0.09040\n\nCollected Steps per Second: 1,645.26135\nOverall Steps per Second: 1,194.15130\n\nTimestep Collection Time: 24.31346\nTimestep Consumption Time: 9.18481\nPPO Batch Consumption Time: 0.98288\nTotal Iteration Time: 33.49827\n\nCumulative Model Updates: 20,419\nCumulative Timesteps: 102,242,670\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 120.31138\nPolicy Entropy: 5.37997\nValue Function Loss: 0.06914\n\nMean KL Divergence: 0.00076\nSB3 Clip Fraction: 0.02700\nPolicy Update Magnitude: 0.19552\nValue Function Update Magnitude: 0.09025\n\nCollected Steps per Second: 1,614.17049\nOverall Steps per Second: 1,178.67327\n\nTimestep Collection Time: 24.78177\nTimestep Consumption Time: 9.15639\nPPO Batch Consumption Time: 0.99080\nTotal Iteration Time: 33.93816\n\nCumulative Model Updates: 20,427\nCumulative Timesteps: 102,282,672\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 110.54679\nPolicy Entropy: 5.39913\nValue Function Loss: 0.07198\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.02786\nPolicy Update Magnitude: 0.21298\nValue Function Update Magnitude: 0.09510\n\nCollected Steps per Second: 1,626.98031\nOverall Steps per Second: 1,179.29130\n\nTimestep Collection Time: 24.58665\nTimestep Consumption Time: 9.33372\nPPO Batch Consumption Time: 1.00166\nTotal Iteration Time: 33.92037\n\nCumulative Model Updates: 20,435\nCumulative Timesteps: 102,322,674\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 99.52977\nPolicy Entropy: 5.38813\nValue Function Loss: 0.06963\n\nMean KL Divergence: 0.00084\nSB3 Clip Fraction: 0.03160\nPolicy Update Magnitude: 0.20857\nValue Function Update Magnitude: 0.10051\n\nCollected Steps per Second: 1,612.71958\nOverall Steps per Second: 1,177.05845\n\nTimestep Collection Time: 24.80282\nTimestep Consumption Time: 9.18020\nPPO Batch Consumption Time: 0.98442\nTotal Iteration Time: 33.98302\n\nCumulative Model Updates: 20,443\nCumulative Timesteps: 102,362,674\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 110.71719\nPolicy Entropy: 5.38087\nValue Function Loss: 0.06730\n\nMean KL Divergence: 0.00068\nSB3 Clip Fraction: 0.02656\nPolicy Update Magnitude: 0.19565\nValue Function Update Magnitude: 0.10136\n\nCollected Steps per Second: 1,638.25252\nOverall Steps per Second: 1,201.19894\n\nTimestep Collection Time: 24.41626\nTimestep Consumption Time: 8.88380\nPPO Batch Consumption Time: 0.98798\nTotal Iteration Time: 33.30006\n\nCumulative Model Updates: 20,451\nCumulative Timesteps: 102,402,674\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 118.23822\nPolicy Entropy: 5.36907\nValue Function Loss: 0.07011\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.02795\nPolicy Update Magnitude: 0.20330\nValue Function Update Magnitude: 0.09404\n\nCollected Steps per Second: 1,640.83790\nOverall Steps per Second: 1,203.33119\n\nTimestep Collection Time: 24.37779\nTimestep Consumption Time: 8.86327\nPPO Batch Consumption Time: 0.98820\nTotal Iteration Time: 33.24106\n\nCumulative Model Updates: 20,459\nCumulative Timesteps: 102,442,674\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 102442674...\nCheckpoint 102442674 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 108.92643\nPolicy Entropy: 5.39890\nValue Function Loss: 0.07034\n\nMean KL Divergence: 0.00073\nSB3 Clip Fraction: 0.02540\nPolicy Update Magnitude: 0.21427\nValue Function Update Magnitude: 0.09845\n\nCollected Steps per Second: 1,616.99855\nOverall Steps per Second: 1,194.38714\n\nTimestep Collection Time: 24.73843\nTimestep Consumption Time: 8.75323\nPPO Batch Consumption Time: 0.97536\nTotal Iteration Time: 33.49165\n\nCumulative Model Updates: 20,467\nCumulative Timesteps: 102,482,676\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 89.60614\nPolicy Entropy: 5.39433\nValue Function Loss: 0.06661\n\nMean KL Divergence: 0.00058\nSB3 Clip Fraction: 0.02015\nPolicy Update Magnitude: 0.20158\nValue Function Update Magnitude: 0.09742\n\nCollected Steps per Second: 1,710.17313\nOverall Steps per Second: 1,244.86621\n\nTimestep Collection Time: 23.39061\nTimestep Consumption Time: 8.74296\nPPO Batch Consumption Time: 0.97392\nTotal Iteration Time: 32.13357\n\nCumulative Model Updates: 20,475\nCumulative Timesteps: 102,522,678\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 111.93585\nPolicy Entropy: 5.36799\nValue Function Loss: 0.06984\n\nMean KL Divergence: 0.00064\nSB3 Clip Fraction: 0.02358\nPolicy Update Magnitude: 0.20309\nValue Function Update Magnitude: 0.09773\n\nCollected Steps per Second: 1,640.67054\nOverall Steps per Second: 1,203.97125\n\nTimestep Collection Time: 24.38028\nTimestep Consumption Time: 8.84311\nPPO Batch Consumption Time: 0.98419\nTotal Iteration Time: 33.22338\n\nCumulative Model Updates: 20,483\nCumulative Timesteps: 102,562,678\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 124.55721\nPolicy Entropy: 5.36050\nValue Function Loss: 0.07202\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.03040\nPolicy Update Magnitude: 0.19926\nValue Function Update Magnitude: 0.09220\n\nCollected Steps per Second: 1,666.92317\nOverall Steps per Second: 1,215.60908\n\nTimestep Collection Time: 23.99631\nTimestep Consumption Time: 8.90901\nPPO Batch Consumption Time: 0.98441\nTotal Iteration Time: 32.90532\n\nCumulative Model Updates: 20,491\nCumulative Timesteps: 102,602,678\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 120.71706\nPolicy Entropy: 5.35852\nValue Function Loss: 0.06760\n\nMean KL Divergence: 0.00070\nSB3 Clip Fraction: 0.02527\nPolicy Update Magnitude: 0.20873\nValue Function Update Magnitude: 0.08888\n\nCollected Steps per Second: 1,683.88146\nOverall Steps per Second: 1,168.95114\n\nTimestep Collection Time: 23.75464\nTimestep Consumption Time: 10.46407\nPPO Batch Consumption Time: 1.18345\nTotal Iteration Time: 34.21871\n\nCumulative Model Updates: 20,499\nCumulative Timesteps: 102,642,678\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 95.93899\nPolicy Entropy: 5.35110\nValue Function Loss: 0.06764\n\nMean KL Divergence: 0.00075\nSB3 Clip Fraction: 0.02723\nPolicy Update Magnitude: 0.22557\nValue Function Update Magnitude: 0.08733\n\nCollected Steps per Second: 1,605.61958\nOverall Steps per Second: 1,184.73239\n\nTimestep Collection Time: 24.91375\nTimestep Consumption Time: 8.85084\nPPO Batch Consumption Time: 0.98906\nTotal Iteration Time: 33.76459\n\nCumulative Model Updates: 20,507\nCumulative Timesteps: 102,682,680\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 98.18651\nPolicy Entropy: 5.35171\nValue Function Loss: 0.06923\n\nMean KL Divergence: 0.00081\nSB3 Clip Fraction: 0.03205\nPolicy Update Magnitude: 0.21005\nValue Function Update Magnitude: 0.08776\n\nCollected Steps per Second: 1,611.51637\nOverall Steps per Second: 1,191.53929\n\nTimestep Collection Time: 24.82134\nTimestep Consumption Time: 8.74868\nPPO Batch Consumption Time: 0.97702\nTotal Iteration Time: 33.57002\n\nCumulative Model Updates: 20,515\nCumulative Timesteps: 102,722,680\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 91.68174\nPolicy Entropy: 5.35591\nValue Function Loss: 0.06827\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.02927\nPolicy Update Magnitude: 0.19613\nValue Function Update Magnitude: 0.08731\n\nCollected Steps per Second: 1,606.71040\nOverall Steps per Second: 1,185.00453\n\nTimestep Collection Time: 24.89683\nTimestep Consumption Time: 8.86000\nPPO Batch Consumption Time: 0.98852\nTotal Iteration Time: 33.75683\n\nCumulative Model Updates: 20,523\nCumulative Timesteps: 102,762,682\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 125.14462\nPolicy Entropy: 5.34935\nValue Function Loss: 0.06754\n\nMean KL Divergence: 0.00075\nSB3 Clip Fraction: 0.02762\nPolicy Update Magnitude: 0.19609\nValue Function Update Magnitude: 0.08466\n\nCollected Steps per Second: 1,637.01865\nOverall Steps per Second: 1,205.23895\n\nTimestep Collection Time: 24.43589\nTimestep Consumption Time: 8.75421\nPPO Batch Consumption Time: 0.97534\nTotal Iteration Time: 33.19010\n\nCumulative Model Updates: 20,531\nCumulative Timesteps: 102,802,684\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 87.12012\nPolicy Entropy: 5.38025\nValue Function Loss: 0.06975\n\nMean KL Divergence: 0.00062\nSB3 Clip Fraction: 0.02252\nPolicy Update Magnitude: 0.19664\nValue Function Update Magnitude: 0.08797\n\nCollected Steps per Second: 1,603.82609\nOverall Steps per Second: 1,187.70609\n\nTimestep Collection Time: 24.94036\nTimestep Consumption Time: 8.73801\nPPO Batch Consumption Time: 0.97267\nTotal Iteration Time: 33.67837\n\nCumulative Model Updates: 20,539\nCumulative Timesteps: 102,842,684\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 127.94202\nPolicy Entropy: 5.38146\nValue Function Loss: 0.06898\n\nMean KL Divergence: 0.00087\nSB3 Clip Fraction: 0.03566\nPolicy Update Magnitude: 0.20652\nValue Function Update Magnitude: 0.09466\n\nCollected Steps per Second: 1,641.34441\nOverall Steps per Second: 1,202.90490\n\nTimestep Collection Time: 24.37027\nTimestep Consumption Time: 8.88257\nPPO Batch Consumption Time: 0.99169\nTotal Iteration Time: 33.25284\n\nCumulative Model Updates: 20,547\nCumulative Timesteps: 102,882,684\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 93.31840\nPolicy Entropy: 5.38021\nValue Function Loss: 0.07092\n\nMean KL Divergence: 0.00078\nSB3 Clip Fraction: 0.03078\nPolicy Update Magnitude: 0.20599\nValue Function Update Magnitude: 0.09315\n\nCollected Steps per Second: 1,593.64123\nOverall Steps per Second: 1,163.45725\n\nTimestep Collection Time: 25.10101\nTimestep Consumption Time: 9.28100\nPPO Batch Consumption Time: 0.99698\nTotal Iteration Time: 34.38201\n\nCumulative Model Updates: 20,555\nCumulative Timesteps: 102,922,686\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 104.58441\nPolicy Entropy: 5.37038\nValue Function Loss: 0.07189\n\nMean KL Divergence: 0.00068\nSB3 Clip Fraction: 0.02453\nPolicy Update Magnitude: 0.20610\nValue Function Update Magnitude: 0.09337\n\nCollected Steps per Second: 1,634.78304\nOverall Steps per Second: 1,178.03610\n\nTimestep Collection Time: 24.46808\nTimestep Consumption Time: 9.48674\nPPO Batch Consumption Time: 1.02061\nTotal Iteration Time: 33.95482\n\nCumulative Model Updates: 20,563\nCumulative Timesteps: 102,962,686\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 102962686...\nCheckpoint 102962686 saved!\n\n\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 108.50191\nPolicy Entropy: 5.36837\nValue Function Loss: 0.06946\n\nMean KL Divergence: 0.00082\nSB3 Clip Fraction: 0.03370\nPolicy Update Magnitude: 0.20605\nValue Function Update Magnitude: 0.09255\n\nCollected Steps per Second: 1,694.38768\nOverall Steps per Second: 1,224.69224\n\nTimestep Collection Time: 23.60853\nTimestep Consumption Time: 9.05437\nPPO Batch Consumption Time: 0.97209\nTotal Iteration Time: 32.66290\n\nCumulative Model Updates: 20,571\nCumulative Timesteps: 103,002,688\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 97.07614\nPolicy Entropy: 5.35733\nValue Function Loss: 0.07139\n\nMean KL Divergence: 0.00078\nSB3 Clip Fraction: 0.03130\nPolicy Update Magnitude: 0.20143\nValue Function Update Magnitude: 0.08693\n\nCollected Steps per Second: 1,570.04937\nOverall Steps per Second: 1,152.02004\n\nTimestep Collection Time: 25.47818\nTimestep Consumption Time: 9.24517\nPPO Batch Consumption Time: 0.99502\nTotal Iteration Time: 34.72335\n\nCumulative Model Updates: 20,579\nCumulative Timesteps: 103,042,690\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 73.98495\nPolicy Entropy: 5.36447\nValue Function Loss: 0.07284\n\nMean KL Divergence: 0.00071\nSB3 Clip Fraction: 0.02784\nPolicy Update Magnitude: 0.19591\nValue Function Update Magnitude: 0.09199\n\nCollected Steps per Second: 1,612.63940\nOverall Steps per Second: 1,174.52235\n\nTimestep Collection Time: 24.80530\nTimestep Consumption Time: 9.25280\nPPO Batch Consumption Time: 0.98929\nTotal Iteration Time: 34.05810\n\nCumulative Model Updates: 20,587\nCumulative Timesteps: 103,082,692\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 91.64956\nPolicy Entropy: 5.37574\nValue Function Loss: 0.07086\n\nMean KL Divergence: 0.00076\nSB3 Clip Fraction: 0.02827\nPolicy Update Magnitude: 0.19892\nValue Function Update Magnitude: 0.09664\n\nCollected Steps per Second: 1,503.23726\nOverall Steps per Second: 1,121.51464\n\nTimestep Collection Time: 26.61057\nTimestep Consumption Time: 9.05727\nPPO Batch Consumption Time: 0.97340\nTotal Iteration Time: 35.66784\n\nCumulative Model Updates: 20,595\nCumulative Timesteps: 103,122,694\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 76.68878\nPolicy Entropy: 5.35982\nValue Function Loss: 0.07251\n\nMean KL Divergence: 0.00078\nSB3 Clip Fraction: 0.03002\nPolicy Update Magnitude: 0.19999\nValue Function Update Magnitude: 0.09627\n\nCollected Steps per Second: 1,673.18836\nOverall Steps per Second: 1,212.69047\n\nTimestep Collection Time: 23.90765\nTimestep Consumption Time: 9.07851\nPPO Batch Consumption Time: 0.97891\nTotal Iteration Time: 32.98616\n\nCumulative Model Updates: 20,603\nCumulative Timesteps: 103,162,696\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 94.61708\nPolicy Entropy: 5.37393\nValue Function Loss: 0.07110\n\nMean KL Divergence: 0.00066\nSB3 Clip Fraction: 0.02369\nPolicy Update Magnitude: 0.20658\nValue Function Update Magnitude: 0.09376\n\nCollected Steps per Second: 1,682.04579\nOverall Steps per Second: 1,218.22010\n\nTimestep Collection Time: 23.78057\nTimestep Consumption Time: 9.05422\nPPO Batch Consumption Time: 0.97510\nTotal Iteration Time: 32.83479\n\nCumulative Model Updates: 20,611\nCumulative Timesteps: 103,202,696\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 93.41189\nPolicy Entropy: 5.39767\nValue Function Loss: 0.07110\n\nMean KL Divergence: 0.00066\nSB3 Clip Fraction: 0.02489\nPolicy Update Magnitude: 0.20990\nValue Function Update Magnitude: 0.08182\n\nCollected Steps per Second: 1,660.48077\nOverall Steps per Second: 1,194.82227\n\nTimestep Collection Time: 24.08941\nTimestep Consumption Time: 9.38837\nPPO Batch Consumption Time: 1.02254\nTotal Iteration Time: 33.47778\n\nCumulative Model Updates: 20,619\nCumulative Timesteps: 103,242,696\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 103.71776\nPolicy Entropy: 5.38292\nValue Function Loss: 0.07110\n\nMean KL Divergence: 0.00065\nSB3 Clip Fraction: 0.02375\nPolicy Update Magnitude: 0.21295\nValue Function Update Magnitude: 0.09003\n\nCollected Steps per Second: 1,690.67360\nOverall Steps per Second: 1,219.44216\n\nTimestep Collection Time: 23.66039\nTimestep Consumption Time: 9.14313\nPPO Batch Consumption Time: 0.98057\nTotal Iteration Time: 32.80352\n\nCumulative Model Updates: 20,627\nCumulative Timesteps: 103,282,698\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 111.04200\nPolicy Entropy: 5.35913\nValue Function Loss: 0.07106\n\nMean KL Divergence: 0.00073\nSB3 Clip Fraction: 0.02865\nPolicy Update Magnitude: 0.20424\nValue Function Update Magnitude: 0.09164\n\nCollected Steps per Second: 1,680.56512\nOverall Steps per Second: 1,212.32571\n\nTimestep Collection Time: 23.80152\nTimestep Consumption Time: 9.19292\nPPO Batch Consumption Time: 0.98282\nTotal Iteration Time: 32.99443\n\nCumulative Model Updates: 20,635\nCumulative Timesteps: 103,322,698\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 99.69062\nPolicy Entropy: 5.36600\nValue Function Loss: 0.07045\n\nMean KL Divergence: 0.00081\nSB3 Clip Fraction: 0.03313\nPolicy Update Magnitude: 0.20570\nValue Function Update Magnitude: 0.09049\n\nCollected Steps per Second: 1,682.12899\nOverall Steps per Second: 1,216.27469\n\nTimestep Collection Time: 23.78058\nTimestep Consumption Time: 9.10837\nPPO Batch Consumption Time: 0.98143\nTotal Iteration Time: 32.88895\n\nCumulative Model Updates: 20,643\nCumulative Timesteps: 103,362,700\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 101.09562\nPolicy Entropy: 5.38500\nValue Function Loss: 0.06752\n\nMean KL Divergence: 0.00062\nSB3 Clip Fraction: 0.02055\nPolicy Update Magnitude: 0.20722\nValue Function Update Magnitude: 0.09409\n\nCollected Steps per Second: 1,689.62384\nOverall Steps per Second: 1,218.99276\n\nTimestep Collection Time: 23.67509\nTimestep Consumption Time: 9.14053\nPPO Batch Consumption Time: 0.98770\nTotal Iteration Time: 32.81562\n\nCumulative Model Updates: 20,651\nCumulative Timesteps: 103,402,702\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 60.64732\nPolicy Entropy: 5.36521\nValue Function Loss: 0.06614\n\nMean KL Divergence: 0.00065\nSB3 Clip Fraction: 0.02230\nPolicy Update Magnitude: 0.20205\nValue Function Update Magnitude: 0.09610\n\nCollected Steps per Second: 1,698.26124\nOverall Steps per Second: 1,228.19692\n\nTimestep Collection Time: 23.55468\nTimestep Consumption Time: 9.01502\nPPO Batch Consumption Time: 0.96544\nTotal Iteration Time: 32.56970\n\nCumulative Model Updates: 20,659\nCumulative Timesteps: 103,442,704\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 109.40682\nPolicy Entropy: 5.34894\nValue Function Loss: 0.06780\n\nMean KL Divergence: 0.00060\nSB3 Clip Fraction: 0.02206\nPolicy Update Magnitude: 0.19841\nValue Function Update Magnitude: 0.09028\n\nCollected Steps per Second: 1,717.72769\nOverall Steps per Second: 1,236.76476\n\nTimestep Collection Time: 23.28658\nTimestep Consumption Time: 9.05587\nPPO Batch Consumption Time: 0.97164\nTotal Iteration Time: 32.34245\n\nCumulative Model Updates: 20,667\nCumulative Timesteps: 103,482,704\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 103482704...\nCheckpoint 103482704 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 112.87715\nPolicy Entropy: 5.34574\nValue Function Loss: 0.06683\n\nMean KL Divergence: 0.00062\nSB3 Clip Fraction: 0.02206\nPolicy Update Magnitude: 0.19019\nValue Function Update Magnitude: 0.09027\n\nCollected Steps per Second: 1,704.78771\nOverall Steps per Second: 1,234.39033\n\nTimestep Collection Time: 23.46451\nTimestep Consumption Time: 8.94178\nPPO Batch Consumption Time: 0.96263\nTotal Iteration Time: 32.40628\n\nCumulative Model Updates: 20,675\nCumulative Timesteps: 103,522,706\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 79.49235\nPolicy Entropy: 5.33777\nValue Function Loss: 0.06805\n\nMean KL Divergence: 0.00061\nSB3 Clip Fraction: 0.02089\nPolicy Update Magnitude: 0.19368\nValue Function Update Magnitude: 0.08634\n\nCollected Steps per Second: 1,664.41963\nOverall Steps per Second: 1,204.16462\n\nTimestep Collection Time: 24.03240\nTimestep Consumption Time: 9.18565\nPPO Batch Consumption Time: 0.98349\nTotal Iteration Time: 33.21805\n\nCumulative Model Updates: 20,683\nCumulative Timesteps: 103,562,706\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 104.23984\nPolicy Entropy: 5.34763\nValue Function Loss: 0.06943\n\nMean KL Divergence: 0.00081\nSB3 Clip Fraction: 0.03178\nPolicy Update Magnitude: 0.19485\nValue Function Update Magnitude: 0.08990\n\nCollected Steps per Second: 1,711.15767\nOverall Steps per Second: 1,231.65765\n\nTimestep Collection Time: 23.37599\nTimestep Consumption Time: 9.10057\nPPO Batch Consumption Time: 0.98031\nTotal Iteration Time: 32.47656\n\nCumulative Model Updates: 20,691\nCumulative Timesteps: 103,602,706\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 116.80113\nPolicy Entropy: 5.38135\nValue Function Loss: 0.06960\n\nMean KL Divergence: 0.00073\nSB3 Clip Fraction: 0.02796\nPolicy Update Magnitude: 0.19714\nValue Function Update Magnitude: 0.09570\n\nCollected Steps per Second: 1,721.33697\nOverall Steps per Second: 1,236.28421\n\nTimestep Collection Time: 23.23775\nTimestep Consumption Time: 9.11727\nPPO Batch Consumption Time: 0.98409\nTotal Iteration Time: 32.35502\n\nCumulative Model Updates: 20,699\nCumulative Timesteps: 103,642,706\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 106.82055\nPolicy Entropy: 5.38112\nValue Function Loss: 0.07027\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.02904\nPolicy Update Magnitude: 0.20879\nValue Function Update Magnitude: 0.09636\n\nCollected Steps per Second: 1,707.06919\nOverall Steps per Second: 1,226.59168\n\nTimestep Collection Time: 23.43315\nTimestep Consumption Time: 9.17917\nPPO Batch Consumption Time: 0.98326\nTotal Iteration Time: 32.61232\n\nCumulative Model Updates: 20,707\nCumulative Timesteps: 103,682,708\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 104.12194\nPolicy Entropy: 5.36179\nValue Function Loss: 0.07132\n\nMean KL Divergence: 0.00084\nSB3 Clip Fraction: 0.03121\nPolicy Update Magnitude: 0.20950\nValue Function Update Magnitude: 0.08970\n\nCollected Steps per Second: 1,675.63779\nOverall Steps per Second: 1,213.68830\n\nTimestep Collection Time: 23.87270\nTimestep Consumption Time: 9.08634\nPPO Batch Consumption Time: 0.97880\nTotal Iteration Time: 32.95904\n\nCumulative Model Updates: 20,715\nCumulative Timesteps: 103,722,710\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 87.42051\nPolicy Entropy: 5.37160\nValue Function Loss: 0.07095\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.02905\nPolicy Update Magnitude: 0.20082\nValue Function Update Magnitude: 0.09248\n\nCollected Steps per Second: 1,736.76974\nOverall Steps per Second: 1,244.12754\n\nTimestep Collection Time: 23.03241\nTimestep Consumption Time: 9.12024\nPPO Batch Consumption Time: 0.98281\nTotal Iteration Time: 32.15265\n\nCumulative Model Updates: 20,723\nCumulative Timesteps: 103,762,712\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 103.17663\nPolicy Entropy: 5.34643\nValue Function Loss: 0.06851\n\nMean KL Divergence: 0.00084\nSB3 Clip Fraction: 0.03359\nPolicy Update Magnitude: 0.19449\nValue Function Update Magnitude: 0.09901\n\nCollected Steps per Second: 1,743.11209\nOverall Steps per Second: 1,243.53760\n\nTimestep Collection Time: 22.94746\nTimestep Consumption Time: 9.21883\nPPO Batch Consumption Time: 0.99240\nTotal Iteration Time: 32.16630\n\nCumulative Model Updates: 20,731\nCumulative Timesteps: 103,802,712\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 107.77036\nPolicy Entropy: 5.35248\nValue Function Loss: 0.06795\n\nMean KL Divergence: 0.00088\nSB3 Clip Fraction: 0.03634\nPolicy Update Magnitude: 0.19139\nValue Function Update Magnitude: 0.09512\n\nCollected Steps per Second: 1,700.61918\nOverall Steps per Second: 1,227.61842\n\nTimestep Collection Time: 23.52084\nTimestep Consumption Time: 9.06257\nPPO Batch Consumption Time: 0.97692\nTotal Iteration Time: 32.58341\n\nCumulative Model Updates: 20,739\nCumulative Timesteps: 103,842,712\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 85.80406\nPolicy Entropy: 5.35718\nValue Function Loss: 0.06783\n\nMean KL Divergence: 0.00073\nSB3 Clip Fraction: 0.02810\nPolicy Update Magnitude: 0.20411\nValue Function Update Magnitude: 0.09984\n\nCollected Steps per Second: 1,688.53385\nOverall Steps per Second: 1,217.69002\n\nTimestep Collection Time: 23.68919\nTimestep Consumption Time: 9.15989\nPPO Batch Consumption Time: 0.98322\nTotal Iteration Time: 32.84908\n\nCumulative Model Updates: 20,747\nCumulative Timesteps: 103,882,712\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 104.79804\nPolicy Entropy: 5.35365\nValue Function Loss: 0.07113\n\nMean KL Divergence: 0.00078\nSB3 Clip Fraction: 0.03059\nPolicy Update Magnitude: 0.21632\nValue Function Update Magnitude: 0.10314\n\nCollected Steps per Second: 1,717.23759\nOverall Steps per Second: 1,235.48926\n\nTimestep Collection Time: 23.29322\nTimestep Consumption Time: 9.08261\nPPO Batch Consumption Time: 0.98018\nTotal Iteration Time: 32.37584\n\nCumulative Model Updates: 20,755\nCumulative Timesteps: 103,922,712\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 70.97863\nPolicy Entropy: 5.36480\nValue Function Loss: 0.07251\n\nMean KL Divergence: 0.00078\nSB3 Clip Fraction: 0.03074\nPolicy Update Magnitude: 0.21933\nValue Function Update Magnitude: 0.11158\n\nCollected Steps per Second: 1,671.60383\nOverall Steps per Second: 1,210.66273\n\nTimestep Collection Time: 23.93031\nTimestep Consumption Time: 9.11110\nPPO Batch Consumption Time: 0.97995\nTotal Iteration Time: 33.04141\n\nCumulative Model Updates: 20,763\nCumulative Timesteps: 103,962,714\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 124.12954\nPolicy Entropy: 5.35741\nValue Function Loss: 0.07134\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.03040\nPolicy Update Magnitude: 0.21406\nValue Function Update Magnitude: 0.09332\n\nCollected Steps per Second: 1,687.14582\nOverall Steps per Second: 1,221.01049\n\nTimestep Collection Time: 23.70987\nTimestep Consumption Time: 9.05152\nPPO Batch Consumption Time: 0.97184\nTotal Iteration Time: 32.76139\n\nCumulative Model Updates: 20,771\nCumulative Timesteps: 104,002,716\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 104002716...\nCheckpoint 104002716 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 78.11609\nPolicy Entropy: 5.35523\nValue Function Loss: 0.06813\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02639\nPolicy Update Magnitude: 0.21019\nValue Function Update Magnitude: 0.09025\n\nCollected Steps per Second: 1,688.09298\nOverall Steps per Second: 1,217.79202\n\nTimestep Collection Time: 23.69538\nTimestep Consumption Time: 9.15095\nPPO Batch Consumption Time: 0.98720\nTotal Iteration Time: 32.84633\n\nCumulative Model Updates: 20,779\nCumulative Timesteps: 104,042,716\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 112.43420\nPolicy Entropy: 5.36260\nValue Function Loss: 0.06560\n\nMean KL Divergence: 0.00073\nSB3 Clip Fraction: 0.02836\nPolicy Update Magnitude: 0.20048\nValue Function Update Magnitude: 0.09476\n\nCollected Steps per Second: 1,676.14053\nOverall Steps per Second: 1,216.28049\n\nTimestep Collection Time: 23.86554\nTimestep Consumption Time: 9.02325\nPPO Batch Consumption Time: 0.96163\nTotal Iteration Time: 32.88880\n\nCumulative Model Updates: 20,787\nCumulative Timesteps: 104,082,718\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 88.80126\nPolicy Entropy: 5.36865\nValue Function Loss: 0.07012\n\nMean KL Divergence: 0.00065\nSB3 Clip Fraction: 0.02255\nPolicy Update Magnitude: 0.20738\nValue Function Update Magnitude: 0.09710\n\nCollected Steps per Second: 1,673.00372\nOverall Steps per Second: 1,210.24099\n\nTimestep Collection Time: 23.91029\nTimestep Consumption Time: 9.14263\nPPO Batch Consumption Time: 0.98597\nTotal Iteration Time: 33.05292\n\nCumulative Model Updates: 20,795\nCumulative Timesteps: 104,122,720\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 92.78447\nPolicy Entropy: 5.40153\nValue Function Loss: 0.07156\n\nMean KL Divergence: 0.00079\nSB3 Clip Fraction: 0.03102\nPolicy Update Magnitude: 0.22111\nValue Function Update Magnitude: 0.09902\n\nCollected Steps per Second: 1,748.77455\nOverall Steps per Second: 1,250.84427\n\nTimestep Collection Time: 22.87316\nTimestep Consumption Time: 9.10524\nPPO Batch Consumption Time: 0.97768\nTotal Iteration Time: 31.97840\n\nCumulative Model Updates: 20,803\nCumulative Timesteps: 104,162,720\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 120.36028\nPolicy Entropy: 5.38052\nValue Function Loss: 0.06898\n\nMean KL Divergence: 0.00079\nSB3 Clip Fraction: 0.03040\nPolicy Update Magnitude: 0.22667\nValue Function Update Magnitude: 0.09779\n\nCollected Steps per Second: 1,772.73275\nOverall Steps per Second: 1,263.94340\n\nTimestep Collection Time: 22.56403\nTimestep Consumption Time: 9.08295\nPPO Batch Consumption Time: 0.97655\nTotal Iteration Time: 31.64699\n\nCumulative Model Updates: 20,811\nCumulative Timesteps: 104,202,720\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 110.37785\nPolicy Entropy: 5.38395\nValue Function Loss: 0.06894\n\nMean KL Divergence: 0.00086\nSB3 Clip Fraction: 0.03456\nPolicy Update Magnitude: 0.21646\nValue Function Update Magnitude: 0.09799\n\nCollected Steps per Second: 1,734.43966\nOverall Steps per Second: 1,248.96612\n\nTimestep Collection Time: 23.06451\nTimestep Consumption Time: 8.96518\nPPO Batch Consumption Time: 0.96662\nTotal Iteration Time: 32.02969\n\nCumulative Model Updates: 20,819\nCumulative Timesteps: 104,242,724\n\nTimesteps Collected: 40,004\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 104.74124\nPolicy Entropy: 5.35491\nValue Function Loss: 0.06825\n\nMean KL Divergence: 0.00097\nSB3 Clip Fraction: 0.03962\nPolicy Update Magnitude: 0.20367\nValue Function Update Magnitude: 0.09871\n\nCollected Steps per Second: 1,724.44171\nOverall Steps per Second: 1,235.77053\n\nTimestep Collection Time: 23.19707\nTimestep Consumption Time: 9.17301\nPPO Batch Consumption Time: 0.98947\nTotal Iteration Time: 32.37009\n\nCumulative Model Updates: 20,827\nCumulative Timesteps: 104,282,726\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 101.82316\nPolicy Entropy: 5.35399\nValue Function Loss: 0.06965\n\nMean KL Divergence: 0.00082\nSB3 Clip Fraction: 0.03214\nPolicy Update Magnitude: 0.19766\nValue Function Update Magnitude: 0.09637\n\nCollected Steps per Second: 1,780.80316\nOverall Steps per Second: 1,271.34941\n\nTimestep Collection Time: 22.46290\nTimestep Consumption Time: 9.00131\nPPO Batch Consumption Time: 0.96836\nTotal Iteration Time: 31.46421\n\nCumulative Model Updates: 20,835\nCumulative Timesteps: 104,322,728\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 107.91256\nPolicy Entropy: 5.36176\nValue Function Loss: 0.07005\n\nMean KL Divergence: 0.00088\nSB3 Clip Fraction: 0.03535\nPolicy Update Magnitude: 0.20062\nValue Function Update Magnitude: 0.09234\n\nCollected Steps per Second: 1,743.26465\nOverall Steps per Second: 1,257.32623\n\nTimestep Collection Time: 22.94545\nTimestep Consumption Time: 8.86809\nPPO Batch Consumption Time: 0.95777\nTotal Iteration Time: 31.81354\n\nCumulative Model Updates: 20,843\nCumulative Timesteps: 104,362,728\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 122.25538\nPolicy Entropy: 5.38156\nValue Function Loss: 0.07090\n\nMean KL Divergence: 0.00084\nSB3 Clip Fraction: 0.03096\nPolicy Update Magnitude: 0.20680\nValue Function Update Magnitude: 0.09106\n\nCollected Steps per Second: 1,681.66666\nOverall Steps per Second: 1,218.73062\n\nTimestep Collection Time: 23.78712\nTimestep Consumption Time: 9.03556\nPPO Batch Consumption Time: 1.00731\nTotal Iteration Time: 32.82268\n\nCumulative Model Updates: 20,851\nCumulative Timesteps: 104,402,730\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 90.70259\nPolicy Entropy: 5.37490\nValue Function Loss: 0.07333\n\nMean KL Divergence: 0.00102\nSB3 Clip Fraction: 0.04303\nPolicy Update Magnitude: 0.20733\nValue Function Update Magnitude: 0.09716\n\nCollected Steps per Second: 1,715.86900\nOverall Steps per Second: 1,244.62309\n\nTimestep Collection Time: 23.31180\nTimestep Consumption Time: 8.82644\nPPO Batch Consumption Time: 0.98406\nTotal Iteration Time: 32.13824\n\nCumulative Model Updates: 20,859\nCumulative Timesteps: 104,442,730\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 101.67474\nPolicy Entropy: 5.38367\nValue Function Loss: 0.07137\n\nMean KL Divergence: 0.00095\nSB3 Clip Fraction: 0.03901\nPolicy Update Magnitude: 0.20419\nValue Function Update Magnitude: 0.10799\n\nCollected Steps per Second: 1,694.84841\nOverall Steps per Second: 1,236.95358\n\nTimestep Collection Time: 23.60093\nTimestep Consumption Time: 8.73658\nPPO Batch Consumption Time: 0.97904\nTotal Iteration Time: 32.33751\n\nCumulative Model Updates: 20,867\nCumulative Timesteps: 104,482,730\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 106.68258\nPolicy Entropy: 5.35732\nValue Function Loss: 0.06820\n\nMean KL Divergence: 0.00084\nSB3 Clip Fraction: 0.03455\nPolicy Update Magnitude: 0.20837\nValue Function Update Magnitude: 0.10017\n\nCollected Steps per Second: 1,721.26940\nOverall Steps per Second: 1,251.86697\n\nTimestep Collection Time: 23.23983\nTimestep Consumption Time: 8.71405\nPPO Batch Consumption Time: 0.96995\nTotal Iteration Time: 31.95387\n\nCumulative Model Updates: 20,875\nCumulative Timesteps: 104,522,732\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 104522732...\nCheckpoint 104522732 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 94.80994\nPolicy Entropy: 5.37514\nValue Function Loss: 0.06944\n\nMean KL Divergence: 0.00090\nSB3 Clip Fraction: 0.03640\nPolicy Update Magnitude: 0.20644\nValue Function Update Magnitude: 0.09568\n\nCollected Steps per Second: 1,693.93784\nOverall Steps per Second: 1,232.45318\n\nTimestep Collection Time: 23.61480\nTimestep Consumption Time: 8.84242\nPPO Batch Consumption Time: 0.98210\nTotal Iteration Time: 32.45722\n\nCumulative Model Updates: 20,883\nCumulative Timesteps: 104,562,734\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 118.71023\nPolicy Entropy: 5.38257\nValue Function Loss: 0.07127\n\nMean KL Divergence: 0.00081\nSB3 Clip Fraction: 0.02958\nPolicy Update Magnitude: 0.21274\nValue Function Update Magnitude: 0.09908\n\nCollected Steps per Second: 1,687.15789\nOverall Steps per Second: 1,227.15809\n\nTimestep Collection Time: 23.70970\nTimestep Consumption Time: 8.88757\nPPO Batch Consumption Time: 0.98855\nTotal Iteration Time: 32.59727\n\nCumulative Model Updates: 20,891\nCumulative Timesteps: 104,602,736\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 108.24676\nPolicy Entropy: 5.39216\nValue Function Loss: 0.06922\n\nMean KL Divergence: 0.00073\nSB3 Clip Fraction: 0.02713\nPolicy Update Magnitude: 0.21034\nValue Function Update Magnitude: 0.09719\n\nCollected Steps per Second: 1,727.89069\nOverall Steps per Second: 1,253.14211\n\nTimestep Collection Time: 23.14961\nTimestep Consumption Time: 8.77015\nPPO Batch Consumption Time: 0.97871\nTotal Iteration Time: 31.91976\n\nCumulative Model Updates: 20,899\nCumulative Timesteps: 104,642,736\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 74.59494\nPolicy Entropy: 5.38913\nValue Function Loss: 0.06852\n\nMean KL Divergence: 0.00079\nSB3 Clip Fraction: 0.03188\nPolicy Update Magnitude: 0.21817\nValue Function Update Magnitude: 0.09715\n\nCollected Steps per Second: 1,688.07657\nOverall Steps per Second: 1,235.75268\n\nTimestep Collection Time: 23.69679\nTimestep Consumption Time: 8.67376\nPPO Batch Consumption Time: 0.96431\nTotal Iteration Time: 32.37055\n\nCumulative Model Updates: 20,907\nCumulative Timesteps: 104,682,738\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 48.51005\nPolicy Entropy: 5.37149\nValue Function Loss: 0.06913\n\nMean KL Divergence: 0.00083\nSB3 Clip Fraction: 0.03121\nPolicy Update Magnitude: 0.21753\nValue Function Update Magnitude: 0.09585\n\nCollected Steps per Second: 1,695.25866\nOverall Steps per Second: 1,239.51152\n\nTimestep Collection Time: 23.59522\nTimestep Consumption Time: 8.67556\nPPO Batch Consumption Time: 0.97375\nTotal Iteration Time: 32.27078\n\nCumulative Model Updates: 20,915\nCumulative Timesteps: 104,722,738\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 124.31892\nPolicy Entropy: 5.37923\nValue Function Loss: 0.06714\n\nMean KL Divergence: 0.00083\nSB3 Clip Fraction: 0.03266\nPolicy Update Magnitude: 0.20856\nValue Function Update Magnitude: 0.09169\n\nCollected Steps per Second: 1,777.05901\nOverall Steps per Second: 1,277.55201\n\nTimestep Collection Time: 22.51023\nTimestep Consumption Time: 8.80122\nPPO Batch Consumption Time: 0.97586\nTotal Iteration Time: 31.31145\n\nCumulative Model Updates: 20,923\nCumulative Timesteps: 104,762,740\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 84.23158\nPolicy Entropy: 5.37253\nValue Function Loss: 0.06840\n\nMean KL Divergence: 0.00085\nSB3 Clip Fraction: 0.03289\nPolicy Update Magnitude: 0.20399\nValue Function Update Magnitude: 0.09736\n\nCollected Steps per Second: 1,709.69900\nOverall Steps per Second: 1,239.85695\n\nTimestep Collection Time: 23.39710\nTimestep Consumption Time: 8.86630\nPPO Batch Consumption Time: 0.98487\nTotal Iteration Time: 32.26340\n\nCumulative Model Updates: 20,931\nCumulative Timesteps: 104,802,742\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 119.74588\nPolicy Entropy: 5.36165\nValue Function Loss: 0.06892\n\nMean KL Divergence: 0.00071\nSB3 Clip Fraction: 0.02599\nPolicy Update Magnitude: 0.20958\nValue Function Update Magnitude: 0.09362\n\nCollected Steps per Second: 1,713.16505\nOverall Steps per Second: 1,255.06133\n\nTimestep Collection Time: 23.34976\nTimestep Consumption Time: 8.52278\nPPO Batch Consumption Time: 0.94309\nTotal Iteration Time: 31.87255\n\nCumulative Model Updates: 20,939\nCumulative Timesteps: 104,842,744\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 106.12979\nPolicy Entropy: 5.35365\nValue Function Loss: 0.07175\n\nMean KL Divergence: 0.00073\nSB3 Clip Fraction: 0.02575\nPolicy Update Magnitude: 0.21548\nValue Function Update Magnitude: 0.09249\n\nCollected Steps per Second: 1,702.21241\nOverall Steps per Second: 1,232.74826\n\nTimestep Collection Time: 23.49883\nTimestep Consumption Time: 8.94900\nPPO Batch Consumption Time: 1.00134\nTotal Iteration Time: 32.44783\n\nCumulative Model Updates: 20,947\nCumulative Timesteps: 104,882,744\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 100.39900\nPolicy Entropy: 5.36061\nValue Function Loss: 0.07508\n\nMean KL Divergence: 0.00083\nSB3 Clip Fraction: 0.03196\nPolicy Update Magnitude: 0.21657\nValue Function Update Magnitude: 0.09290\n\nCollected Steps per Second: 1,719.92627\nOverall Steps per Second: 1,252.98996\n\nTimestep Collection Time: 23.25797\nTimestep Consumption Time: 8.66726\nPPO Batch Consumption Time: 0.96899\nTotal Iteration Time: 31.92524\n\nCumulative Model Updates: 20,955\nCumulative Timesteps: 104,922,746\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 93.98626\nPolicy Entropy: 5.37633\nValue Function Loss: 0.07361\n\nMean KL Divergence: 0.00091\nSB3 Clip Fraction: 0.03610\nPolicy Update Magnitude: 0.22447\nValue Function Update Magnitude: 0.09637\n\nCollected Steps per Second: 1,715.69547\nOverall Steps per Second: 1,243.80874\n\nTimestep Collection Time: 23.31416\nTimestep Consumption Time: 8.84512\nPPO Batch Consumption Time: 0.98790\nTotal Iteration Time: 32.15929\n\nCumulative Model Updates: 20,963\nCumulative Timesteps: 104,962,746\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 117.01229\nPolicy Entropy: 5.37432\nValue Function Loss: 0.07121\n\nMean KL Divergence: 0.00082\nSB3 Clip Fraction: 0.03219\nPolicy Update Magnitude: 0.22532\nValue Function Update Magnitude: 0.09563\n\nCollected Steps per Second: 1,702.20707\nOverall Steps per Second: 1,231.51766\n\nTimestep Collection Time: 23.50008\nTimestep Consumption Time: 8.98179\nPPO Batch Consumption Time: 0.95511\nTotal Iteration Time: 32.48187\n\nCumulative Model Updates: 20,971\nCumulative Timesteps: 105,002,748\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 117.87791\nPolicy Entropy: 5.34024\nValue Function Loss: 0.07343\n\nMean KL Divergence: 0.00075\nSB3 Clip Fraction: 0.02608\nPolicy Update Magnitude: 0.21840\nValue Function Update Magnitude: 0.09440\n\nCollected Steps per Second: 1,746.74658\nOverall Steps per Second: 1,248.15646\n\nTimestep Collection Time: 22.89972\nTimestep Consumption Time: 9.14755\nPPO Batch Consumption Time: 0.98411\nTotal Iteration Time: 32.04726\n\nCumulative Model Updates: 20,979\nCumulative Timesteps: 105,042,748\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 105042748...\nCheckpoint 105042748 saved!\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 123.69825\nPolicy Entropy: 5.36028\nValue Function Loss: 0.07144\n\nMean KL Divergence: 0.00066\nSB3 Clip Fraction: 0.02339\nPolicy Update Magnitude: 0.21681\nValue Function Update Magnitude: 0.09849\n\nCollected Steps per Second: 1,774.39813\nOverall Steps per Second: 1,266.58425\n\nTimestep Collection Time: 22.54398\nTimestep Consumption Time: 9.03860\nPPO Batch Consumption Time: 0.96678\nTotal Iteration Time: 31.58258\n\nCumulative Model Updates: 20,987\nCumulative Timesteps: 105,082,750\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 85.43990\nPolicy Entropy: 5.35529\nValue Function Loss: 0.07085\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.02929\nPolicy Update Magnitude: 0.21445\nValue Function Update Magnitude: 0.09063\n\nCollected Steps per Second: 1,722.28739\nOverall Steps per Second: 1,242.15511\n\nTimestep Collection Time: 23.22609\nTimestep Consumption Time: 8.97762\nPPO Batch Consumption Time: 0.96741\nTotal Iteration Time: 32.20371\n\nCumulative Model Updates: 20,995\nCumulative Timesteps: 105,122,752\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 71.91534\nPolicy Entropy: 5.36141\nValue Function Loss: 0.07276\n\nMean KL Divergence: 0.00076\nSB3 Clip Fraction: 0.02955\nPolicy Update Magnitude: 0.21704\nValue Function Update Magnitude: 0.09206\n\nCollected Steps per Second: 1,712.21518\nOverall Steps per Second: 1,234.27393\n\nTimestep Collection Time: 23.36155\nTimestep Consumption Time: 9.04617\nPPO Batch Consumption Time: 0.97866\nTotal Iteration Time: 32.40772\n\nCumulative Model Updates: 21,003\nCumulative Timesteps: 105,162,752\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 105.44772\nPolicy Entropy: 5.35716\nValue Function Loss: 0.07067\n\nMean KL Divergence: 0.00081\nSB3 Clip Fraction: 0.03090\nPolicy Update Magnitude: 0.21853\nValue Function Update Magnitude: 0.09135\n\nCollected Steps per Second: 1,746.76992\nOverall Steps per Second: 1,252.79763\n\nTimestep Collection Time: 22.89941\nTimestep Consumption Time: 9.02913\nPPO Batch Consumption Time: 0.96908\nTotal Iteration Time: 31.92854\n\nCumulative Model Updates: 21,011\nCumulative Timesteps: 105,202,752\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 132.91122\nPolicy Entropy: 5.36281\nValue Function Loss: 0.06871\n\nMean KL Divergence: 0.00089\nSB3 Clip Fraction: 0.03506\nPolicy Update Magnitude: 0.21324\nValue Function Update Magnitude: 0.09391\n\nCollected Steps per Second: 1,750.80015\nOverall Steps per Second: 1,248.37048\n\nTimestep Collection Time: 22.84670\nTimestep Consumption Time: 9.19507\nPPO Batch Consumption Time: 0.99150\nTotal Iteration Time: 32.04177\n\nCumulative Model Updates: 21,019\nCumulative Timesteps: 105,242,752\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 120.20555\nPolicy Entropy: 5.35902\nValue Function Loss: 0.06896\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.02765\nPolicy Update Magnitude: 0.21417\nValue Function Update Magnitude: 0.08871\n\nCollected Steps per Second: 1,755.49139\nOverall Steps per Second: 1,258.16293\n\nTimestep Collection Time: 22.78564\nTimestep Consumption Time: 9.00674\nPPO Batch Consumption Time: 0.97062\nTotal Iteration Time: 31.79238\n\nCumulative Model Updates: 21,027\nCumulative Timesteps: 105,282,752\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 100.11765\nPolicy Entropy: 5.37036\nValue Function Loss: 0.06892\n\nMean KL Divergence: 0.00071\nSB3 Clip Fraction: 0.02479\nPolicy Update Magnitude: 0.21882\nValue Function Update Magnitude: 0.08774\n\nCollected Steps per Second: 1,710.70001\nOverall Steps per Second: 1,236.09114\n\nTimestep Collection Time: 23.38224\nTimestep Consumption Time: 8.97783\nPPO Batch Consumption Time: 0.96827\nTotal Iteration Time: 32.36007\n\nCumulative Model Updates: 21,035\nCumulative Timesteps: 105,322,752\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 78.76078\nPolicy Entropy: 5.37130\nValue Function Loss: 0.07023\n\nMean KL Divergence: 0.00081\nSB3 Clip Fraction: 0.03052\nPolicy Update Magnitude: 0.22395\nValue Function Update Magnitude: 0.08789\n\nCollected Steps per Second: 1,728.05007\nOverall Steps per Second: 1,244.48413\n\nTimestep Collection Time: 23.14863\nTimestep Consumption Time: 8.99480\nPPO Batch Consumption Time: 0.96411\nTotal Iteration Time: 32.14344\n\nCumulative Model Updates: 21,043\nCumulative Timesteps: 105,362,754\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 95.97042\nPolicy Entropy: 5.37274\nValue Function Loss: 0.07034\n\nMean KL Divergence: 0.00093\nSB3 Clip Fraction: 0.03735\nPolicy Update Magnitude: 0.22295\nValue Function Update Magnitude: 0.08924\n\nCollected Steps per Second: 1,708.63515\nOverall Steps per Second: 1,231.33650\n\nTimestep Collection Time: 23.41050\nTimestep Consumption Time: 9.07453\nPPO Batch Consumption Time: 0.97768\nTotal Iteration Time: 32.48503\n\nCumulative Model Updates: 21,051\nCumulative Timesteps: 105,402,754\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 105.66635\nPolicy Entropy: 5.40198\nValue Function Loss: 0.06888\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.02884\nPolicy Update Magnitude: 0.21451\nValue Function Update Magnitude: 0.09468\n\nCollected Steps per Second: 1,731.81133\nOverall Steps per Second: 1,239.67665\n\nTimestep Collection Time: 23.09836\nTimestep Consumption Time: 9.16973\nPPO Batch Consumption Time: 0.99236\nTotal Iteration Time: 32.26809\n\nCumulative Model Updates: 21,059\nCumulative Timesteps: 105,442,756\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 110.22511\nPolicy Entropy: 5.39776\nValue Function Loss: 0.07024\n\nMean KL Divergence: 0.00069\nSB3 Clip Fraction: 0.02525\nPolicy Update Magnitude: 0.21201\nValue Function Update Magnitude: 0.10172\n\nCollected Steps per Second: 1,716.57640\nOverall Steps per Second: 1,233.61226\n\nTimestep Collection Time: 23.30336\nTimestep Consumption Time: 9.12336\nPPO Batch Consumption Time: 0.98400\nTotal Iteration Time: 32.42672\n\nCumulative Model Updates: 21,067\nCumulative Timesteps: 105,482,758\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 123.27799\nPolicy Entropy: 5.36255\nValue Function Loss: 0.07002\n\nMean KL Divergence: 0.00057\nSB3 Clip Fraction: 0.01893\nPolicy Update Magnitude: 0.20857\nValue Function Update Magnitude: 0.09603\n\nCollected Steps per Second: 1,714.40026\nOverall Steps per Second: 1,239.73643\n\nTimestep Collection Time: 23.33294\nTimestep Consumption Time: 8.93360\nPPO Batch Consumption Time: 0.96185\nTotal Iteration Time: 32.26654\n\nCumulative Model Updates: 21,075\nCumulative Timesteps: 105,522,760\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 108.09264\nPolicy Entropy: 5.37254\nValue Function Loss: 0.07125\n\nMean KL Divergence: 0.00068\nSB3 Clip Fraction: 0.02504\nPolicy Update Magnitude: 0.21327\nValue Function Update Magnitude: 0.09402\n\nCollected Steps per Second: 1,687.11500\nOverall Steps per Second: 1,213.20197\n\nTimestep Collection Time: 23.70911\nTimestep Consumption Time: 9.26149\nPPO Batch Consumption Time: 0.99780\nTotal Iteration Time: 32.97060\n\nCumulative Model Updates: 21,083\nCumulative Timesteps: 105,562,760\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 105562760...\nCheckpoint 105562760 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 110.57560\nPolicy Entropy: 5.36886\nValue Function Loss: 0.06995\n\nMean KL Divergence: 0.00070\nSB3 Clip Fraction: 0.02646\nPolicy Update Magnitude: 0.21222\nValue Function Update Magnitude: 0.09407\n\nCollected Steps per Second: 1,691.14322\nOverall Steps per Second: 1,225.07488\n\nTimestep Collection Time: 23.65382\nTimestep Consumption Time: 8.99888\nPPO Batch Consumption Time: 1.00197\nTotal Iteration Time: 32.65270\n\nCumulative Model Updates: 21,091\nCumulative Timesteps: 105,602,762\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 89.01152\nPolicy Entropy: 5.35930\nValue Function Loss: 0.06484\n\nMean KL Divergence: 0.00065\nSB3 Clip Fraction: 0.02394\nPolicy Update Magnitude: 0.21998\nValue Function Update Magnitude: 0.09372\n\nCollected Steps per Second: 1,701.49319\nOverall Steps per Second: 1,239.62567\n\nTimestep Collection Time: 23.50876\nTimestep Consumption Time: 8.75904\nPPO Batch Consumption Time: 0.97452\nTotal Iteration Time: 32.26781\n\nCumulative Model Updates: 21,099\nCumulative Timesteps: 105,642,762\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 115.89306\nPolicy Entropy: 5.34749\nValue Function Loss: 0.06624\n\nMean KL Divergence: 0.00080\nSB3 Clip Fraction: 0.03184\nPolicy Update Magnitude: 0.21187\nValue Function Update Magnitude: 0.08764\n\nCollected Steps per Second: 1,720.19207\nOverall Steps per Second: 1,245.15442\n\nTimestep Collection Time: 23.25438\nTimestep Consumption Time: 8.87176\nPPO Batch Consumption Time: 0.98870\nTotal Iteration Time: 32.12614\n\nCumulative Model Updates: 21,107\nCumulative Timesteps: 105,682,764\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 68.93934\nPolicy Entropy: 5.33721\nValue Function Loss: 0.07235\n\nMean KL Divergence: 0.00082\nSB3 Clip Fraction: 0.03268\nPolicy Update Magnitude: 0.20894\nValue Function Update Magnitude: 0.08748\n\nCollected Steps per Second: 1,724.01254\nOverall Steps per Second: 1,253.95509\n\nTimestep Collection Time: 23.20285\nTimestep Consumption Time: 8.69782\nPPO Batch Consumption Time: 0.96314\nTotal Iteration Time: 31.90066\n\nCumulative Model Updates: 21,115\nCumulative Timesteps: 105,722,766\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 107.95833\nPolicy Entropy: 5.35695\nValue Function Loss: 0.07269\n\nMean KL Divergence: 0.00067\nSB3 Clip Fraction: 0.02309\nPolicy Update Magnitude: 0.24556\nValue Function Update Magnitude: 0.09179\n\nCollected Steps per Second: 1,730.87618\nOverall Steps per Second: 1,250.82542\n\nTimestep Collection Time: 23.10968\nTimestep Consumption Time: 8.86920\nPPO Batch Consumption Time: 0.99243\nTotal Iteration Time: 31.97888\n\nCumulative Model Updates: 21,123\nCumulative Timesteps: 105,762,766\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 81.92725\nPolicy Entropy: 5.36317\nValue Function Loss: 0.06895\n\nMean KL Divergence: 0.00083\nSB3 Clip Fraction: 0.02724\nPolicy Update Magnitude: 0.24225\nValue Function Update Magnitude: 0.09602\n\nCollected Steps per Second: 1,725.92440\nOverall Steps per Second: 1,252.63007\n\nTimestep Collection Time: 23.17715\nTimestep Consumption Time: 8.75726\nPPO Batch Consumption Time: 0.97465\nTotal Iteration Time: 31.93441\n\nCumulative Model Updates: 21,131\nCumulative Timesteps: 105,802,768\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 125.49208\nPolicy Entropy: 5.37039\nValue Function Loss: 0.06863\n\nMean KL Divergence: 0.00082\nSB3 Clip Fraction: 0.03278\nPolicy Update Magnitude: 0.21879\nValue Function Update Magnitude: 0.09623\n\nCollected Steps per Second: 1,731.63404\nOverall Steps per Second: 1,253.32334\n\nTimestep Collection Time: 23.10072\nTimestep Consumption Time: 8.81602\nPPO Batch Consumption Time: 0.98120\nTotal Iteration Time: 31.91674\n\nCumulative Model Updates: 21,139\nCumulative Timesteps: 105,842,770\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 78.52634\nPolicy Entropy: 5.36011\nValue Function Loss: 0.06863\n\nMean KL Divergence: 0.00085\nSB3 Clip Fraction: 0.02744\nPolicy Update Magnitude: 0.20263\nValue Function Update Magnitude: 0.09314\n\nCollected Steps per Second: 1,755.97063\nOverall Steps per Second: 1,268.74797\n\nTimestep Collection Time: 22.77942\nTimestep Consumption Time: 8.74772\nPPO Batch Consumption Time: 0.97683\nTotal Iteration Time: 31.52714\n\nCumulative Model Updates: 21,147\nCumulative Timesteps: 105,882,770\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 111.85940\nPolicy Entropy: 5.33529\nValue Function Loss: 0.06756\n\nMean KL Divergence: 0.00082\nSB3 Clip Fraction: 0.03175\nPolicy Update Magnitude: 0.20326\nValue Function Update Magnitude: 0.08442\n\nCollected Steps per Second: 1,719.16637\nOverall Steps per Second: 1,250.29415\n\nTimestep Collection Time: 23.26825\nTimestep Consumption Time: 8.72582\nPPO Batch Consumption Time: 0.97664\nTotal Iteration Time: 31.99407\n\nCumulative Model Updates: 21,155\nCumulative Timesteps: 105,922,772\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 103.55051\nPolicy Entropy: 5.33735\nValue Function Loss: 0.06575\n\nMean KL Divergence: 0.00081\nSB3 Clip Fraction: 0.03199\nPolicy Update Magnitude: 0.20447\nValue Function Update Magnitude: 0.08519\n\nCollected Steps per Second: 1,737.58273\nOverall Steps per Second: 1,266.23951\n\nTimestep Collection Time: 23.02049\nTimestep Consumption Time: 8.56911\nPPO Batch Consumption Time: 0.95259\nTotal Iteration Time: 31.58960\n\nCumulative Model Updates: 21,163\nCumulative Timesteps: 105,962,772\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 116.98828\nPolicy Entropy: 5.35846\nValue Function Loss: 0.06705\n\nMean KL Divergence: 0.00067\nSB3 Clip Fraction: 0.02361\nPolicy Update Magnitude: 0.20912\nValue Function Update Magnitude: 0.08649\n\nCollected Steps per Second: 1,773.81281\nOverall Steps per Second: 1,276.36707\n\nTimestep Collection Time: 22.55142\nTimestep Consumption Time: 8.78909\nPPO Batch Consumption Time: 0.97725\nTotal Iteration Time: 31.34051\n\nCumulative Model Updates: 21,171\nCumulative Timesteps: 106,002,774\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 93.47417\nPolicy Entropy: 5.35755\nValue Function Loss: 0.06516\n\nMean KL Divergence: 0.00066\nSB3 Clip Fraction: 0.02464\nPolicy Update Magnitude: 0.21713\nValue Function Update Magnitude: 0.09415\n\nCollected Steps per Second: 1,789.63476\nOverall Steps per Second: 1,288.95269\n\nTimestep Collection Time: 22.35205\nTimestep Consumption Time: 8.68245\nPPO Batch Consumption Time: 0.96829\nTotal Iteration Time: 31.03450\n\nCumulative Model Updates: 21,179\nCumulative Timesteps: 106,042,776\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 111.28528\nPolicy Entropy: 5.37357\nValue Function Loss: 0.06630\n\nMean KL Divergence: 0.00091\nSB3 Clip Fraction: 0.03710\nPolicy Update Magnitude: 0.20951\nValue Function Update Magnitude: 0.09757\n\nCollected Steps per Second: 1,787.33619\nOverall Steps per Second: 1,279.08418\n\nTimestep Collection Time: 22.38079\nTimestep Consumption Time: 8.89315\nPPO Batch Consumption Time: 0.98940\nTotal Iteration Time: 31.27394\n\nCumulative Model Updates: 21,187\nCumulative Timesteps: 106,082,778\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 106082778...\nCheckpoint 106082778 saved!\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 123.93005\nPolicy Entropy: 5.36331\nValue Function Loss: 0.06970\n\nMean KL Divergence: 0.00087\nSB3 Clip Fraction: 0.03391\nPolicy Update Magnitude: 0.20617\nValue Function Update Magnitude: 0.10184\n\nCollected Steps per Second: 1,776.21620\nOverall Steps per Second: 1,285.25614\n\nTimestep Collection Time: 22.52091\nTimestep Consumption Time: 8.60285\nPPO Batch Consumption Time: 0.95820\nTotal Iteration Time: 31.12376\n\nCumulative Model Updates: 21,195\nCumulative Timesteps: 106,122,780\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 78.88242\nPolicy Entropy: 5.35909\nValue Function Loss: 0.07261\n\nMean KL Divergence: 0.00091\nSB3 Clip Fraction: 0.03809\nPolicy Update Magnitude: 0.20795\nValue Function Update Magnitude: 0.09792\n\nCollected Steps per Second: 1,737.66045\nOverall Steps per Second: 1,246.03745\n\nTimestep Collection Time: 23.01946\nTimestep Consumption Time: 9.08231\nPPO Batch Consumption Time: 0.97919\nTotal Iteration Time: 32.10176\n\nCumulative Model Updates: 21,203\nCumulative Timesteps: 106,162,780\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 102.10206\nPolicy Entropy: 5.35923\nValue Function Loss: 0.07141\n\nMean KL Divergence: 0.00099\nSB3 Clip Fraction: 0.03900\nPolicy Update Magnitude: 0.25790\nValue Function Update Magnitude: 0.10041\n\nCollected Steps per Second: 1,776.12281\nOverall Steps per Second: 1,260.99721\n\nTimestep Collection Time: 22.52097\nTimestep Consumption Time: 9.19996\nPPO Batch Consumption Time: 0.99934\nTotal Iteration Time: 31.72093\n\nCumulative Model Updates: 21,211\nCumulative Timesteps: 106,202,780\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 54.37054\nPolicy Entropy: 5.37591\nValue Function Loss: 0.07005\n\nMean KL Divergence: 0.00279\nSB3 Clip Fraction: 0.03929\nPolicy Update Magnitude: 0.27442\nValue Function Update Magnitude: 0.09520\n\nCollected Steps per Second: 1,781.82069\nOverall Steps per Second: 1,269.77860\n\nTimestep Collection Time: 22.44895\nTimestep Consumption Time: 9.05261\nPPO Batch Consumption Time: 0.98188\nTotal Iteration Time: 31.50155\n\nCumulative Model Updates: 21,219\nCumulative Timesteps: 106,242,780\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 134.43944\nPolicy Entropy: 5.37675\nValue Function Loss: 0.06986\n\nMean KL Divergence: 0.00083\nSB3 Clip Fraction: 0.03260\nPolicy Update Magnitude: 0.22220\nValue Function Update Magnitude: 0.09397\n\nCollected Steps per Second: 1,796.89574\nOverall Steps per Second: 1,277.97511\n\nTimestep Collection Time: 22.26061\nTimestep Consumption Time: 9.03890\nPPO Batch Consumption Time: 0.97605\nTotal Iteration Time: 31.29951\n\nCumulative Model Updates: 21,227\nCumulative Timesteps: 106,282,780\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 86.55440\nPolicy Entropy: 5.36455\nValue Function Loss: 0.06720\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.02829\nPolicy Update Magnitude: 0.21534\nValue Function Update Magnitude: 0.09186\n\nCollected Steps per Second: 1,768.00257\nOverall Steps per Second: 1,260.10666\n\nTimestep Collection Time: 22.62553\nTimestep Consumption Time: 9.11940\nPPO Batch Consumption Time: 0.97953\nTotal Iteration Time: 31.74493\n\nCumulative Model Updates: 21,235\nCumulative Timesteps: 106,322,782\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 96.72636\nPolicy Entropy: 5.35147\nValue Function Loss: 0.06729\n\nMean KL Divergence: 0.00081\nSB3 Clip Fraction: 0.03241\nPolicy Update Magnitude: 0.21308\nValue Function Update Magnitude: 0.09462\n\nCollected Steps per Second: 1,771.39316\nOverall Steps per Second: 1,280.48409\n\nTimestep Collection Time: 22.58110\nTimestep Consumption Time: 8.65709\nPPO Batch Consumption Time: 0.96310\nTotal Iteration Time: 31.23819\n\nCumulative Model Updates: 21,243\nCumulative Timesteps: 106,362,782\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 104.32257\nPolicy Entropy: 5.36608\nValue Function Loss: 0.06621\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02699\nPolicy Update Magnitude: 0.20260\nValue Function Update Magnitude: 0.09608\n\nCollected Steps per Second: 1,800.70916\nOverall Steps per Second: 1,289.85194\n\nTimestep Collection Time: 22.21347\nTimestep Consumption Time: 8.79784\nPPO Batch Consumption Time: 0.98101\nTotal Iteration Time: 31.01131\n\nCumulative Model Updates: 21,251\nCumulative Timesteps: 106,402,782\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 104.33151\nPolicy Entropy: 5.37587\nValue Function Loss: 0.06859\n\nMean KL Divergence: 0.00063\nSB3 Clip Fraction: 0.02361\nPolicy Update Magnitude: 0.20291\nValue Function Update Magnitude: 0.09276\n\nCollected Steps per Second: 1,823.19050\nOverall Steps per Second: 1,305.54165\n\nTimestep Collection Time: 21.94066\nTimestep Consumption Time: 8.69950\nPPO Batch Consumption Time: 0.96763\nTotal Iteration Time: 30.64016\n\nCumulative Model Updates: 21,259\nCumulative Timesteps: 106,442,784\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 91.40075\nPolicy Entropy: 5.35624\nValue Function Loss: 0.06906\n\nMean KL Divergence: 0.00067\nSB3 Clip Fraction: 0.02367\nPolicy Update Magnitude: 0.20922\nValue Function Update Magnitude: 0.09641\n\nCollected Steps per Second: 1,813.76549\nOverall Steps per Second: 1,299.52163\n\nTimestep Collection Time: 22.05688\nTimestep Consumption Time: 8.72830\nPPO Batch Consumption Time: 0.97261\nTotal Iteration Time: 30.78517\n\nCumulative Model Updates: 21,267\nCumulative Timesteps: 106,482,790\n\nTimesteps Collected: 40,006\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 113.43916\nPolicy Entropy: 5.34409\nValue Function Loss: 0.06851\n\nMean KL Divergence: 0.00068\nSB3 Clip Fraction: 0.02579\nPolicy Update Magnitude: 0.20500\nValue Function Update Magnitude: 0.08970\n\nCollected Steps per Second: 1,657.35687\nOverall Steps per Second: 1,213.29786\n\nTimestep Collection Time: 24.13723\nTimestep Consumption Time: 8.83407\nPPO Batch Consumption Time: 0.98624\nTotal Iteration Time: 32.97129\n\nCumulative Model Updates: 21,275\nCumulative Timesteps: 106,522,794\n\nTimesteps Collected: 40,004\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 72.29063\nPolicy Entropy: 5.36529\nValue Function Loss: 0.06949\n\nMean KL Divergence: 0.00073\nSB3 Clip Fraction: 0.02800\nPolicy Update Magnitude: 0.20818\nValue Function Update Magnitude: 0.08700\n\nCollected Steps per Second: 1,762.07550\nOverall Steps per Second: 1,270.19200\n\nTimestep Collection Time: 22.70164\nTimestep Consumption Time: 8.79124\nPPO Batch Consumption Time: 0.97915\nTotal Iteration Time: 31.49288\n\nCumulative Model Updates: 21,283\nCumulative Timesteps: 106,562,796\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 96.93950\nPolicy Entropy: 5.36696\nValue Function Loss: 0.06885\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.03057\nPolicy Update Magnitude: 0.21057\nValue Function Update Magnitude: 0.09076\n\nCollected Steps per Second: 1,713.67944\nOverall Steps per Second: 1,244.76849\n\nTimestep Collection Time: 23.34159\nTimestep Consumption Time: 8.79290\nPPO Batch Consumption Time: 0.98591\nTotal Iteration Time: 32.13449\n\nCumulative Model Updates: 21,291\nCumulative Timesteps: 106,602,796\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 106602796...\nCheckpoint 106602796 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 79.78441\nPolicy Entropy: 5.35417\nValue Function Loss: 0.06858\n\nMean KL Divergence: 0.00073\nSB3 Clip Fraction: 0.02751\nPolicy Update Magnitude: 0.20383\nValue Function Update Magnitude: 0.08857\n\nCollected Steps per Second: 1,674.75821\nOverall Steps per Second: 1,221.30038\n\nTimestep Collection Time: 23.88404\nTimestep Consumption Time: 8.86793\nPPO Batch Consumption Time: 0.98383\nTotal Iteration Time: 32.75198\n\nCumulative Model Updates: 21,299\nCumulative Timesteps: 106,642,796\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 121.61820\nPolicy Entropy: 5.34138\nValue Function Loss: 0.06673\n\nMean KL Divergence: 0.00054\nSB3 Clip Fraction: 0.01746\nPolicy Update Magnitude: 0.20813\nValue Function Update Magnitude: 0.08701\n\nCollected Steps per Second: 1,715.87212\nOverall Steps per Second: 1,256.83329\n\nTimestep Collection Time: 23.31293\nTimestep Consumption Time: 8.51468\nPPO Batch Consumption Time: 0.95160\nTotal Iteration Time: 31.82761\n\nCumulative Model Updates: 21,307\nCumulative Timesteps: 106,682,798\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 101.31812\nPolicy Entropy: 5.34120\nValue Function Loss: 0.06763\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02686\nPolicy Update Magnitude: 0.20662\nValue Function Update Magnitude: 0.08663\n\nCollected Steps per Second: 1,723.77816\nOverall Steps per Second: 1,249.80963\n\nTimestep Collection Time: 23.20484\nTimestep Consumption Time: 8.80003\nPPO Batch Consumption Time: 0.98043\nTotal Iteration Time: 32.00487\n\nCumulative Model Updates: 21,315\nCumulative Timesteps: 106,722,798\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 102.95452\nPolicy Entropy: 5.37374\nValue Function Loss: 0.06802\n\nMean KL Divergence: 0.00075\nSB3 Clip Fraction: 0.03010\nPolicy Update Magnitude: 0.20410\nValue Function Update Magnitude: 0.08948\n\nCollected Steps per Second: 1,717.46309\nOverall Steps per Second: 1,243.93976\n\nTimestep Collection Time: 23.29133\nTimestep Consumption Time: 8.86618\nPPO Batch Consumption Time: 0.98415\nTotal Iteration Time: 32.15751\n\nCumulative Model Updates: 21,323\nCumulative Timesteps: 106,762,800\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 100.84781\nPolicy Entropy: 5.38139\nValue Function Loss: 0.06754\n\nMean KL Divergence: 0.00065\nSB3 Clip Fraction: 0.02340\nPolicy Update Magnitude: 0.20800\nValue Function Update Magnitude: 0.09064\n\nCollected Steps per Second: 1,734.56094\nOverall Steps per Second: 1,256.41705\n\nTimestep Collection Time: 23.06174\nTimestep Consumption Time: 8.77641\nPPO Batch Consumption Time: 0.97666\nTotal Iteration Time: 31.83815\n\nCumulative Model Updates: 21,331\nCumulative Timesteps: 106,802,802\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 87.22558\nPolicy Entropy: 5.37586\nValue Function Loss: 0.06879\n\nMean KL Divergence: 0.00069\nSB3 Clip Fraction: 0.02186\nPolicy Update Magnitude: 0.21646\nValue Function Update Magnitude: 0.09688\n\nCollected Steps per Second: 1,765.28443\nOverall Steps per Second: 1,273.06370\n\nTimestep Collection Time: 22.65924\nTimestep Consumption Time: 8.76103\nPPO Batch Consumption Time: 0.98330\nTotal Iteration Time: 31.42027\n\nCumulative Model Updates: 21,339\nCumulative Timesteps: 106,842,802\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 115.08683\nPolicy Entropy: 5.36099\nValue Function Loss: 0.06865\n\nMean KL Divergence: 0.00068\nSB3 Clip Fraction: 0.02540\nPolicy Update Magnitude: 0.21070\nValue Function Update Magnitude: 0.09720\n\nCollected Steps per Second: 1,793.95462\nOverall Steps per Second: 1,286.02140\n\nTimestep Collection Time: 22.29822\nTimestep Consumption Time: 8.80701\nPPO Batch Consumption Time: 0.97940\nTotal Iteration Time: 31.10524\n\nCumulative Model Updates: 21,347\nCumulative Timesteps: 106,882,804\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 105.23726\nPolicy Entropy: 5.36165\nValue Function Loss: 0.06859\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.02906\nPolicy Update Magnitude: 0.20871\nValue Function Update Magnitude: 0.09241\n\nCollected Steps per Second: 1,734.49899\nOverall Steps per Second: 1,260.34617\n\nTimestep Collection Time: 23.06141\nTimestep Consumption Time: 8.67590\nPPO Batch Consumption Time: 0.96931\nTotal Iteration Time: 31.73731\n\nCumulative Model Updates: 21,355\nCumulative Timesteps: 106,922,804\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 86.63715\nPolicy Entropy: 5.35750\nValue Function Loss: 0.06851\n\nMean KL Divergence: 0.00068\nSB3 Clip Fraction: 0.02487\nPolicy Update Magnitude: 0.20174\nValue Function Update Magnitude: 0.09497\n\nCollected Steps per Second: 1,745.44735\nOverall Steps per Second: 1,265.15592\n\nTimestep Collection Time: 22.91791\nTimestep Consumption Time: 8.70033\nPPO Batch Consumption Time: 0.97253\nTotal Iteration Time: 31.61824\n\nCumulative Model Updates: 21,363\nCumulative Timesteps: 106,962,806\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 91.69977\nPolicy Entropy: 5.35564\nValue Function Loss: 0.06946\n\nMean KL Divergence: 0.00071\nSB3 Clip Fraction: 0.02765\nPolicy Update Magnitude: 0.20306\nValue Function Update Magnitude: 0.08716\n\nCollected Steps per Second: 1,773.08602\nOverall Steps per Second: 1,267.87469\n\nTimestep Collection Time: 22.55954\nTimestep Consumption Time: 8.98932\nPPO Batch Consumption Time: 0.97165\nTotal Iteration Time: 31.54886\n\nCumulative Model Updates: 21,371\nCumulative Timesteps: 107,002,806\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 135.40680\nPolicy Entropy: 5.36551\nValue Function Loss: 0.07016\n\nMean KL Divergence: 0.00081\nSB3 Clip Fraction: 0.03203\nPolicy Update Magnitude: 0.20435\nValue Function Update Magnitude: 0.09002\n\nCollected Steps per Second: 1,784.36567\nOverall Steps per Second: 1,275.38374\n\nTimestep Collection Time: 22.41693\nTimestep Consumption Time: 8.94618\nPPO Batch Consumption Time: 0.96395\nTotal Iteration Time: 31.36311\n\nCumulative Model Updates: 21,379\nCumulative Timesteps: 107,042,806\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 105.99381\nPolicy Entropy: 5.38601\nValue Function Loss: 0.07110\n\nMean KL Divergence: 0.00067\nSB3 Clip Fraction: 0.02451\nPolicy Update Magnitude: 0.20980\nValue Function Update Magnitude: 0.09094\n\nCollected Steps per Second: 1,809.68680\nOverall Steps per Second: 1,282.81588\n\nTimestep Collection Time: 22.10327\nTimestep Consumption Time: 9.07813\nPPO Batch Consumption Time: 0.98402\nTotal Iteration Time: 31.18140\n\nCumulative Model Updates: 21,387\nCumulative Timesteps: 107,082,806\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 90.97945\nPolicy Entropy: 5.39765\nValue Function Loss: 0.07230\n\nMean KL Divergence: 0.00152\nSB3 Clip Fraction: 0.03239\nPolicy Update Magnitude: 0.28031\nValue Function Update Magnitude: 0.10712\n\nCollected Steps per Second: 1,812.61022\nOverall Steps per Second: 1,288.06882\n\nTimestep Collection Time: 22.06762\nTimestep Consumption Time: 8.98662\nPPO Batch Consumption Time: 0.97267\nTotal Iteration Time: 31.05424\n\nCumulative Model Updates: 21,395\nCumulative Timesteps: 107,122,806\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 107122806...\nCheckpoint 107122806 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 106.37732\nPolicy Entropy: 5.37374\nValue Function Loss: 0.07209\n\nMean KL Divergence: 0.00218\nSB3 Clip Fraction: 0.02915\nPolicy Update Magnitude: 0.28990\nValue Function Update Magnitude: 0.10275\n\nCollected Steps per Second: 1,799.93857\nOverall Steps per Second: 1,281.62490\n\nTimestep Collection Time: 22.22298\nTimestep Consumption Time: 8.98740\nPPO Batch Consumption Time: 0.96871\nTotal Iteration Time: 31.21038\n\nCumulative Model Updates: 21,403\nCumulative Timesteps: 107,162,806\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 120.04363\nPolicy Entropy: 5.37865\nValue Function Loss: 0.06845\n\nMean KL Divergence: 0.00058\nSB3 Clip Fraction: 0.02144\nPolicy Update Magnitude: 0.24623\nValue Function Update Magnitude: 0.09558\n\nCollected Steps per Second: 1,812.75051\nOverall Steps per Second: 1,302.14020\n\nTimestep Collection Time: 22.06592\nTimestep Consumption Time: 8.65274\nPPO Batch Consumption Time: 0.96603\nTotal Iteration Time: 30.71866\n\nCumulative Model Updates: 21,411\nCumulative Timesteps: 107,202,806\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 121.41342\nPolicy Entropy: 5.33292\nValue Function Loss: 0.06819\n\nMean KL Divergence: 0.00073\nSB3 Clip Fraction: 0.02698\nPolicy Update Magnitude: 0.20613\nValue Function Update Magnitude: 0.08506\n\nCollected Steps per Second: 1,717.80781\nOverall Steps per Second: 1,245.68494\n\nTimestep Collection Time: 23.28666\nTimestep Consumption Time: 8.82580\nPPO Batch Consumption Time: 0.97168\nTotal Iteration Time: 32.11245\n\nCumulative Model Updates: 21,419\nCumulative Timesteps: 107,242,808\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 111.25877\nPolicy Entropy: 5.32835\nValue Function Loss: 0.06850\n\nMean KL Divergence: 0.00073\nSB3 Clip Fraction: 0.02785\nPolicy Update Magnitude: 0.20108\nValue Function Update Magnitude: 0.08791\n\nCollected Steps per Second: 1,734.23110\nOverall Steps per Second: 1,258.73419\n\nTimestep Collection Time: 23.06498\nTimestep Consumption Time: 8.71298\nPPO Batch Consumption Time: 0.97289\nTotal Iteration Time: 31.77796\n\nCumulative Model Updates: 21,427\nCumulative Timesteps: 107,282,808\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 121.80652\nPolicy Entropy: 5.33740\nValue Function Loss: 0.06397\n\nMean KL Divergence: 0.00067\nSB3 Clip Fraction: 0.02489\nPolicy Update Magnitude: 0.19488\nValue Function Update Magnitude: 0.08999\n\nCollected Steps per Second: 1,710.80198\nOverall Steps per Second: 1,246.71187\n\nTimestep Collection Time: 23.38085\nTimestep Consumption Time: 8.70355\nPPO Batch Consumption Time: 0.97429\nTotal Iteration Time: 32.08440\n\nCumulative Model Updates: 21,435\nCumulative Timesteps: 107,322,808\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 86.98989\nPolicy Entropy: 5.34590\nValue Function Loss: 0.06271\n\nMean KL Divergence: 0.00088\nSB3 Clip Fraction: 0.03685\nPolicy Update Magnitude: 0.19192\nValue Function Update Magnitude: 0.08424\n\nCollected Steps per Second: 1,749.63184\nOverall Steps per Second: 1,260.31064\n\nTimestep Collection Time: 22.86195\nTimestep Consumption Time: 8.87625\nPPO Batch Consumption Time: 0.99677\nTotal Iteration Time: 31.73821\n\nCumulative Model Updates: 21,443\nCumulative Timesteps: 107,362,808\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 97.89531\nPolicy Entropy: 5.35745\nValue Function Loss: 0.06545\n\nMean KL Divergence: 0.00081\nSB3 Clip Fraction: 0.03018\nPolicy Update Magnitude: 0.19416\nValue Function Update Magnitude: 0.08508\n\nCollected Steps per Second: 1,708.84549\nOverall Steps per Second: 1,243.01728\n\nTimestep Collection Time: 23.40762\nTimestep Consumption Time: 8.77215\nPPO Batch Consumption Time: 0.97150\nTotal Iteration Time: 32.17976\n\nCumulative Model Updates: 21,451\nCumulative Timesteps: 107,402,808\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 89.44248\nPolicy Entropy: 5.36960\nValue Function Loss: 0.06761\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.02660\nPolicy Update Magnitude: 0.20006\nValue Function Update Magnitude: 0.09055\n\nCollected Steps per Second: 1,660.75582\nOverall Steps per Second: 1,217.42735\n\nTimestep Collection Time: 24.08662\nTimestep Consumption Time: 8.77119\nPPO Batch Consumption Time: 0.97525\nTotal Iteration Time: 32.85781\n\nCumulative Model Updates: 21,459\nCumulative Timesteps: 107,442,810\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 110.62677\nPolicy Entropy: 5.36045\nValue Function Loss: 0.06868\n\nMean KL Divergence: 0.00069\nSB3 Clip Fraction: 0.02534\nPolicy Update Magnitude: 0.21124\nValue Function Update Magnitude: 0.09608\n\nCollected Steps per Second: 1,701.33334\nOverall Steps per Second: 1,240.85767\n\nTimestep Collection Time: 23.51097\nTimestep Consumption Time: 8.72480\nPPO Batch Consumption Time: 0.96830\nTotal Iteration Time: 32.23577\n\nCumulative Model Updates: 21,467\nCumulative Timesteps: 107,482,810\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 127.19728\nPolicy Entropy: 5.35443\nValue Function Loss: 0.06796\n\nMean KL Divergence: 0.00088\nSB3 Clip Fraction: 0.03505\nPolicy Update Magnitude: 0.20715\nValue Function Update Magnitude: 0.09028\n\nCollected Steps per Second: 1,719.61575\nOverall Steps per Second: 1,237.54600\n\nTimestep Collection Time: 23.26217\nTimestep Consumption Time: 9.06147\nPPO Batch Consumption Time: 0.97394\nTotal Iteration Time: 32.32365\n\nCumulative Model Updates: 21,475\nCumulative Timesteps: 107,522,812\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 80.77698\nPolicy Entropy: 5.36075\nValue Function Loss: 0.06744\n\nMean KL Divergence: 0.00093\nSB3 Clip Fraction: 0.03829\nPolicy Update Magnitude: 0.19578\nValue Function Update Magnitude: 0.08960\n\nCollected Steps per Second: 1,728.83911\nOverall Steps per Second: 1,237.58530\n\nTimestep Collection Time: 23.13691\nTimestep Consumption Time: 9.18409\nPPO Batch Consumption Time: 0.99182\nTotal Iteration Time: 32.32100\n\nCumulative Model Updates: 21,483\nCumulative Timesteps: 107,562,812\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 110.96572\nPolicy Entropy: 5.37233\nValue Function Loss: 0.07090\n\nMean KL Divergence: 0.00084\nSB3 Clip Fraction: 0.03372\nPolicy Update Magnitude: 0.20288\nValue Function Update Magnitude: 0.09283\n\nCollected Steps per Second: 1,641.29119\nOverall Steps per Second: 1,190.88954\n\nTimestep Collection Time: 24.37106\nTimestep Consumption Time: 9.21728\nPPO Batch Consumption Time: 0.98846\nTotal Iteration Time: 33.58834\n\nCumulative Model Updates: 21,491\nCumulative Timesteps: 107,602,812\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 98.89442\nPolicy Entropy: 5.36344\nValue Function Loss: 0.07198\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02771\nPolicy Update Magnitude: 0.21470\nValue Function Update Magnitude: 0.09669\n\nCollected Steps per Second: 1,680.24868\nOverall Steps per Second: 1,210.06810\n\nTimestep Collection Time: 23.80719\nTimestep Consumption Time: 9.25045\nPPO Batch Consumption Time: 0.98875\nTotal Iteration Time: 33.05764\n\nCumulative Model Updates: 21,499\nCumulative Timesteps: 107,642,814\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 107642814...\nCheckpoint 107642814 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 77.51539\nPolicy Entropy: 5.36137\nValue Function Loss: 0.06976\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.02974\nPolicy Update Magnitude: 0.20475\nValue Function Update Magnitude: 0.09020\n\nCollected Steps per Second: 1,701.91141\nOverall Steps per Second: 1,224.98156\n\nTimestep Collection Time: 23.50299\nTimestep Consumption Time: 9.15057\nPPO Batch Consumption Time: 0.98928\nTotal Iteration Time: 32.65355\n\nCumulative Model Updates: 21,507\nCumulative Timesteps: 107,682,814\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 76.73913\nPolicy Entropy: 5.35233\nValue Function Loss: 0.06898\n\nMean KL Divergence: 0.00062\nSB3 Clip Fraction: 0.02286\nPolicy Update Magnitude: 0.20315\nValue Function Update Magnitude: 0.09386\n\nCollected Steps per Second: 1,684.80470\nOverall Steps per Second: 1,161.04798\n\nTimestep Collection Time: 23.74281\nTimestep Consumption Time: 10.71055\nPPO Batch Consumption Time: 1.17355\nTotal Iteration Time: 34.45336\n\nCumulative Model Updates: 21,515\nCumulative Timesteps: 107,722,816\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 93.33798\nPolicy Entropy: 5.36134\nValue Function Loss: 0.06793\n\nMean KL Divergence: 0.00061\nSB3 Clip Fraction: 0.02180\nPolicy Update Magnitude: 0.20687\nValue Function Update Magnitude: 0.09709\n\nCollected Steps per Second: 1,636.04512\nOverall Steps per Second: 1,189.95360\n\nTimestep Collection Time: 24.44920\nTimestep Consumption Time: 9.16555\nPPO Batch Consumption Time: 0.98681\nTotal Iteration Time: 33.61476\n\nCumulative Model Updates: 21,523\nCumulative Timesteps: 107,762,816\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 55.55941\nPolicy Entropy: 5.37056\nValue Function Loss: 0.06761\n\nMean KL Divergence: 0.00061\nSB3 Clip Fraction: 0.02245\nPolicy Update Magnitude: 0.20398\nValue Function Update Magnitude: 0.09516\n\nCollected Steps per Second: 1,697.36321\nOverall Steps per Second: 1,219.74503\n\nTimestep Collection Time: 23.56714\nTimestep Consumption Time: 9.22824\nPPO Batch Consumption Time: 0.99502\nTotal Iteration Time: 32.79538\n\nCumulative Model Updates: 21,531\nCumulative Timesteps: 107,802,818\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 117.75508\nPolicy Entropy: 5.39084\nValue Function Loss: 0.06977\n\nMean KL Divergence: 0.00063\nSB3 Clip Fraction: 0.02271\nPolicy Update Magnitude: 0.22900\nValue Function Update Magnitude: 0.10159\n\nCollected Steps per Second: 1,651.01758\nOverall Steps per Second: 1,198.66412\n\nTimestep Collection Time: 24.22748\nTimestep Consumption Time: 9.14300\nPPO Batch Consumption Time: 0.98651\nTotal Iteration Time: 33.37048\n\nCumulative Model Updates: 21,539\nCumulative Timesteps: 107,842,818\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 131.78620\nPolicy Entropy: 5.38997\nValue Function Loss: 0.07139\n\nMean KL Divergence: 0.00084\nSB3 Clip Fraction: 0.03000\nPolicy Update Magnitude: 0.22278\nValue Function Update Magnitude: 0.09648\n\nCollected Steps per Second: 1,678.14910\nOverall Steps per Second: 1,208.94922\n\nTimestep Collection Time: 23.83698\nTimestep Consumption Time: 9.25126\nPPO Batch Consumption Time: 0.99599\nTotal Iteration Time: 33.08824\n\nCumulative Model Updates: 21,547\nCumulative Timesteps: 107,882,820\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 94.52510\nPolicy Entropy: 5.37684\nValue Function Loss: 0.07011\n\nMean KL Divergence: 0.00080\nSB3 Clip Fraction: 0.03171\nPolicy Update Magnitude: 0.20639\nValue Function Update Magnitude: 0.09310\n\nCollected Steps per Second: 1,665.49493\nOverall Steps per Second: 1,209.66231\n\nTimestep Collection Time: 24.01809\nTimestep Consumption Time: 9.05065\nPPO Batch Consumption Time: 0.97052\nTotal Iteration Time: 33.06873\n\nCumulative Model Updates: 21,555\nCumulative Timesteps: 107,922,822\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 105.15006\nPolicy Entropy: 5.36595\nValue Function Loss: 0.06840\n\nMean KL Divergence: 0.00079\nSB3 Clip Fraction: 0.03088\nPolicy Update Magnitude: 0.20104\nValue Function Update Magnitude: 0.08841\n\nCollected Steps per Second: 1,628.66295\nOverall Steps per Second: 1,186.61610\n\nTimestep Collection Time: 24.56002\nTimestep Consumption Time: 9.14928\nPPO Batch Consumption Time: 0.98635\nTotal Iteration Time: 33.70930\n\nCumulative Model Updates: 21,563\nCumulative Timesteps: 107,962,822\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 97.26859\nPolicy Entropy: 5.36972\nValue Function Loss: 0.07160\n\nMean KL Divergence: 0.00082\nSB3 Clip Fraction: 0.03244\nPolicy Update Magnitude: 0.20344\nValue Function Update Magnitude: 0.09141\n\nCollected Steps per Second: 1,629.03965\nOverall Steps per Second: 1,193.12685\n\nTimestep Collection Time: 24.55557\nTimestep Consumption Time: 8.97146\nPPO Batch Consumption Time: 0.99703\nTotal Iteration Time: 33.52703\n\nCumulative Model Updates: 21,571\nCumulative Timesteps: 108,002,824\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 80.23542\nPolicy Entropy: 5.36978\nValue Function Loss: 0.07362\n\nMean KL Divergence: 0.00098\nSB3 Clip Fraction: 0.04075\nPolicy Update Magnitude: 0.20143\nValue Function Update Magnitude: 0.09547\n\nCollected Steps per Second: 1,652.54120\nOverall Steps per Second: 1,211.83126\n\nTimestep Collection Time: 24.20636\nTimestep Consumption Time: 8.80319\nPPO Batch Consumption Time: 0.97930\nTotal Iteration Time: 33.00955\n\nCumulative Model Updates: 21,579\nCumulative Timesteps: 108,042,826\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 92.51960\nPolicy Entropy: 5.37759\nValue Function Loss: 0.07064\n\nMean KL Divergence: 0.00089\nSB3 Clip Fraction: 0.03649\nPolicy Update Magnitude: 0.20099\nValue Function Update Magnitude: 0.09251\n\nCollected Steps per Second: 1,706.30667\nOverall Steps per Second: 1,237.03084\n\nTimestep Collection Time: 23.44362\nTimestep Consumption Time: 8.89349\nPPO Batch Consumption Time: 0.98523\nTotal Iteration Time: 32.33711\n\nCumulative Model Updates: 21,587\nCumulative Timesteps: 108,082,828\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 113.21113\nPolicy Entropy: 5.37340\nValue Function Loss: 0.06961\n\nMean KL Divergence: 0.00081\nSB3 Clip Fraction: 0.03129\nPolicy Update Magnitude: 0.20445\nValue Function Update Magnitude: 0.09079\n\nCollected Steps per Second: 1,717.71260\nOverall Steps per Second: 1,249.21714\n\nTimestep Collection Time: 23.28795\nTimestep Consumption Time: 8.73371\nPPO Batch Consumption Time: 0.97460\nTotal Iteration Time: 32.02165\n\nCumulative Model Updates: 21,595\nCumulative Timesteps: 108,122,830\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 122.85701\nPolicy Entropy: 5.36868\nValue Function Loss: 0.07078\n\nMean KL Divergence: 0.00080\nSB3 Clip Fraction: 0.03085\nPolicy Update Magnitude: 0.20587\nValue Function Update Magnitude: 0.09299\n\nCollected Steps per Second: 1,713.47742\nOverall Steps per Second: 1,241.19878\n\nTimestep Collection Time: 23.34551\nTimestep Consumption Time: 8.88301\nPPO Batch Consumption Time: 0.98783\nTotal Iteration Time: 32.22852\n\nCumulative Model Updates: 21,603\nCumulative Timesteps: 108,162,832\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 108162832...\nCheckpoint 108162832 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 114.09445\nPolicy Entropy: 5.36899\nValue Function Loss: 0.07164\n\nMean KL Divergence: 0.00073\nSB3 Clip Fraction: 0.02750\nPolicy Update Magnitude: 0.20939\nValue Function Update Magnitude: 0.09486\n\nCollected Steps per Second: 1,720.74887\nOverall Steps per Second: 1,252.30891\n\nTimestep Collection Time: 23.24686\nTimestep Consumption Time: 8.69574\nPPO Batch Consumption Time: 0.96957\nTotal Iteration Time: 31.94260\n\nCumulative Model Updates: 21,611\nCumulative Timesteps: 108,202,834\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 85.12082\nPolicy Entropy: 5.37841\nValue Function Loss: 0.07086\n\nMean KL Divergence: 0.00068\nSB3 Clip Fraction: 0.02432\nPolicy Update Magnitude: 0.21644\nValue Function Update Magnitude: 0.10079\n\nCollected Steps per Second: 1,781.17954\nOverall Steps per Second: 1,286.09525\n\nTimestep Collection Time: 22.45703\nTimestep Consumption Time: 8.64487\nPPO Batch Consumption Time: 0.96583\nTotal Iteration Time: 31.10190\n\nCumulative Model Updates: 21,619\nCumulative Timesteps: 108,242,834\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 103.99927\nPolicy Entropy: 5.40287\nValue Function Loss: 0.06998\n\nMean KL Divergence: 0.00080\nSB3 Clip Fraction: 0.02876\nPolicy Update Magnitude: 0.22953\nValue Function Update Magnitude: 0.09872\n\nCollected Steps per Second: 1,767.59069\nOverall Steps per Second: 1,272.49588\n\nTimestep Collection Time: 22.63080\nTimestep Consumption Time: 8.80505\nPPO Batch Consumption Time: 0.97974\nTotal Iteration Time: 31.43586\n\nCumulative Model Updates: 21,627\nCumulative Timesteps: 108,282,836\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 113.50823\nPolicy Entropy: 5.39388\nValue Function Loss: 0.07372\n\nMean KL Divergence: 0.00087\nSB3 Clip Fraction: 0.03466\nPolicy Update Magnitude: 0.21854\nValue Function Update Magnitude: 0.09371\n\nCollected Steps per Second: 1,767.60783\nOverall Steps per Second: 1,277.30944\n\nTimestep Collection Time: 22.63059\nTimestep Consumption Time: 8.68681\nPPO Batch Consumption Time: 0.96306\nTotal Iteration Time: 31.31739\n\nCumulative Model Updates: 21,635\nCumulative Timesteps: 108,322,838\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 113.60042\nPolicy Entropy: 5.38756\nValue Function Loss: 0.07187\n\nMean KL Divergence: 0.00078\nSB3 Clip Fraction: 0.02964\nPolicy Update Magnitude: 0.21039\nValue Function Update Magnitude: 0.10407\n\nCollected Steps per Second: 1,777.73679\nOverall Steps per Second: 1,279.87973\n\nTimestep Collection Time: 22.50164\nTimestep Consumption Time: 8.75286\nPPO Batch Consumption Time: 0.97359\nTotal Iteration Time: 31.25450\n\nCumulative Model Updates: 21,643\nCumulative Timesteps: 108,362,840\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 120.89322\nPolicy Entropy: 5.35826\nValue Function Loss: 0.06730\n\nMean KL Divergence: 0.00083\nSB3 Clip Fraction: 0.03206\nPolicy Update Magnitude: 0.20663\nValue Function Update Magnitude: 0.09861\n\nCollected Steps per Second: 1,766.13672\nOverall Steps per Second: 1,270.47926\n\nTimestep Collection Time: 22.64830\nTimestep Consumption Time: 8.83588\nPPO Batch Consumption Time: 0.98485\nTotal Iteration Time: 31.48418\n\nCumulative Model Updates: 21,651\nCumulative Timesteps: 108,402,840\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 92.73812\nPolicy Entropy: 5.35893\nValue Function Loss: 0.06721\n\nMean KL Divergence: 0.00109\nSB3 Clip Fraction: 0.04603\nPolicy Update Magnitude: 0.19802\nValue Function Update Magnitude: 0.09840\n\nCollected Steps per Second: 1,741.86006\nOverall Steps per Second: 1,257.24797\n\nTimestep Collection Time: 22.96511\nTimestep Consumption Time: 8.85201\nPPO Batch Consumption Time: 0.98999\nTotal Iteration Time: 31.81711\n\nCumulative Model Updates: 21,659\nCumulative Timesteps: 108,442,842\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 113.93134\nPolicy Entropy: 5.36478\nValue Function Loss: 0.06903\n\nMean KL Divergence: 0.00089\nSB3 Clip Fraction: 0.03519\nPolicy Update Magnitude: 0.19830\nValue Function Update Magnitude: 0.09152\n\nCollected Steps per Second: 1,750.49447\nOverall Steps per Second: 1,253.67924\n\nTimestep Collection Time: 22.85069\nTimestep Consumption Time: 9.05540\nPPO Batch Consumption Time: 0.97457\nTotal Iteration Time: 31.90609\n\nCumulative Model Updates: 21,667\nCumulative Timesteps: 108,482,842\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 107.63774\nPolicy Entropy: 5.37408\nValue Function Loss: 0.07089\n\nMean KL Divergence: 0.00083\nSB3 Clip Fraction: 0.03338\nPolicy Update Magnitude: 0.20911\nValue Function Update Magnitude: 0.09440\n\nCollected Steps per Second: 1,782.77254\nOverall Steps per Second: 1,271.99661\n\nTimestep Collection Time: 22.43696\nTimestep Consumption Time: 9.00966\nPPO Batch Consumption Time: 0.97494\nTotal Iteration Time: 31.44662\n\nCumulative Model Updates: 21,675\nCumulative Timesteps: 108,522,842\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 91.55029\nPolicy Entropy: 5.35781\nValue Function Loss: 0.07275\n\nMean KL Divergence: 0.00084\nSB3 Clip Fraction: 0.03250\nPolicy Update Magnitude: 0.22169\nValue Function Update Magnitude: 0.09629\n\nCollected Steps per Second: 1,802.86151\nOverall Steps per Second: 1,282.22152\n\nTimestep Collection Time: 22.18695\nTimestep Consumption Time: 9.00891\nPPO Batch Consumption Time: 0.97139\nTotal Iteration Time: 31.19586\n\nCumulative Model Updates: 21,683\nCumulative Timesteps: 108,562,842\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 117.40972\nPolicy Entropy: 5.37949\nValue Function Loss: 0.07168\n\nMean KL Divergence: 0.00088\nSB3 Clip Fraction: 0.03048\nPolicy Update Magnitude: 0.22916\nValue Function Update Magnitude: 0.09865\n\nCollected Steps per Second: 1,803.75816\nOverall Steps per Second: 1,281.39983\n\nTimestep Collection Time: 22.17703\nTimestep Consumption Time: 9.04039\nPPO Batch Consumption Time: 0.96984\nTotal Iteration Time: 31.21742\n\nCumulative Model Updates: 21,691\nCumulative Timesteps: 108,602,844\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 91.35078\nPolicy Entropy: 5.38449\nValue Function Loss: 0.07206\n\nMean KL Divergence: 0.00086\nSB3 Clip Fraction: 0.03299\nPolicy Update Magnitude: 0.22302\nValue Function Update Magnitude: 0.09072\n\nCollected Steps per Second: 1,741.94065\nOverall Steps per Second: 1,254.51815\n\nTimestep Collection Time: 22.96404\nTimestep Consumption Time: 8.92230\nPPO Batch Consumption Time: 0.96243\nTotal Iteration Time: 31.88635\n\nCumulative Model Updates: 21,699\nCumulative Timesteps: 108,642,846\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 80.48836\nPolicy Entropy: 5.37876\nValue Function Loss: 0.07083\n\nMean KL Divergence: 0.00085\nSB3 Clip Fraction: 0.03259\nPolicy Update Magnitude: 0.21810\nValue Function Update Magnitude: 0.09635\n\nCollected Steps per Second: 1,797.30287\nOverall Steps per Second: 1,282.44790\n\nTimestep Collection Time: 22.25557\nTimestep Consumption Time: 8.93478\nPPO Batch Consumption Time: 0.96869\nTotal Iteration Time: 31.19035\n\nCumulative Model Updates: 21,707\nCumulative Timesteps: 108,682,846\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 108682846...\nCheckpoint 108682846 saved!\n\n\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 101.03218\nPolicy Entropy: 5.36148\nValue Function Loss: 0.07243\n\nMean KL Divergence: 0.00079\nSB3 Clip Fraction: 0.03067\nPolicy Update Magnitude: 0.20470\nValue Function Update Magnitude: 0.10141\n\nCollected Steps per Second: 1,790.93924\nOverall Steps per Second: 1,279.23218\n\nTimestep Collection Time: 22.33465\nTimestep Consumption Time: 8.93411\nPPO Batch Consumption Time: 0.96213\nTotal Iteration Time: 31.26876\n\nCumulative Model Updates: 21,715\nCumulative Timesteps: 108,722,846\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 131.97273\nPolicy Entropy: 5.36443\nValue Function Loss: 0.07211\n\nMean KL Divergence: 0.00099\nSB3 Clip Fraction: 0.03868\nPolicy Update Magnitude: 0.20694\nValue Function Update Magnitude: 0.09333\n\nCollected Steps per Second: 1,793.75541\nOverall Steps per Second: 1,267.32730\n\nTimestep Collection Time: 22.30070\nTimestep Consumption Time: 9.26336\nPPO Batch Consumption Time: 1.00618\nTotal Iteration Time: 31.56406\n\nCumulative Model Updates: 21,723\nCumulative Timesteps: 108,762,848\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 109.96419\nPolicy Entropy: 5.34791\nValue Function Loss: 0.07075\n\nMean KL Divergence: 0.00088\nSB3 Clip Fraction: 0.03541\nPolicy Update Magnitude: 0.19969\nValue Function Update Magnitude: 0.08684\n\nCollected Steps per Second: 1,748.47676\nOverall Steps per Second: 1,245.36858\n\nTimestep Collection Time: 22.87820\nTimestep Consumption Time: 9.24241\nPPO Batch Consumption Time: 0.98964\nTotal Iteration Time: 32.12061\n\nCumulative Model Updates: 21,731\nCumulative Timesteps: 108,802,850\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 93.95099\nPolicy Entropy: 5.35778\nValue Function Loss: 0.07009\n\nMean KL Divergence: 0.00061\nSB3 Clip Fraction: 0.02235\nPolicy Update Magnitude: 0.20646\nValue Function Update Magnitude: 0.09439\n\nCollected Steps per Second: 1,740.13347\nOverall Steps per Second: 1,238.95024\n\nTimestep Collection Time: 22.98789\nTimestep Consumption Time: 9.29912\nPPO Batch Consumption Time: 0.99029\nTotal Iteration Time: 32.28701\n\nCumulative Model Updates: 21,739\nCumulative Timesteps: 108,842,852\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 86.47647\nPolicy Entropy: 5.34083\nValue Function Loss: 0.07075\n\nMean KL Divergence: 0.00086\nSB3 Clip Fraction: 0.02974\nPolicy Update Magnitude: 0.21013\nValue Function Update Magnitude: 0.09122\n\nCollected Steps per Second: 1,739.06695\nOverall Steps per Second: 1,242.01032\n\nTimestep Collection Time: 23.00199\nTimestep Consumption Time: 9.20547\nPPO Batch Consumption Time: 0.99110\nTotal Iteration Time: 32.20746\n\nCumulative Model Updates: 21,747\nCumulative Timesteps: 108,882,854\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 83.85591\nPolicy Entropy: 5.37066\nValue Function Loss: 0.06975\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.02959\nPolicy Update Magnitude: 0.20617\nValue Function Update Magnitude: 0.09728\n\nCollected Steps per Second: 1,749.48075\nOverall Steps per Second: 1,241.43919\n\nTimestep Collection Time: 22.86393\nTimestep Consumption Time: 9.35674\nPPO Batch Consumption Time: 1.00429\nTotal Iteration Time: 32.22067\n\nCumulative Model Updates: 21,755\nCumulative Timesteps: 108,922,854\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 99.36727\nPolicy Entropy: 5.36521\nValue Function Loss: 0.07116\n\nMean KL Divergence: 0.00078\nSB3 Clip Fraction: 0.02934\nPolicy Update Magnitude: 0.21443\nValue Function Update Magnitude: 0.09393\n\nCollected Steps per Second: 1,786.47852\nOverall Steps per Second: 1,268.02492\n\nTimestep Collection Time: 22.39154\nTimestep Consumption Time: 9.15516\nPPO Batch Consumption Time: 0.99048\nTotal Iteration Time: 31.54670\n\nCumulative Model Updates: 21,763\nCumulative Timesteps: 108,962,856\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 126.84330\nPolicy Entropy: 5.35549\nValue Function Loss: 0.07036\n\nMean KL Divergence: 0.00083\nSB3 Clip Fraction: 0.03189\nPolicy Update Magnitude: 0.21668\nValue Function Update Magnitude: 0.09277\n\nCollected Steps per Second: 1,798.73537\nOverall Steps per Second: 1,263.66310\n\nTimestep Collection Time: 22.23785\nTimestep Consumption Time: 9.41616\nPPO Batch Consumption Time: 0.97404\nTotal Iteration Time: 31.65401\n\nCumulative Model Updates: 21,771\nCumulative Timesteps: 109,002,856\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 98.06362\nPolicy Entropy: 5.35295\nValue Function Loss: 0.06510\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.02791\nPolicy Update Magnitude: 0.21459\nValue Function Update Magnitude: 0.09664\n\nCollected Steps per Second: 1,824.41711\nOverall Steps per Second: 1,290.99210\n\nTimestep Collection Time: 21.92481\nTimestep Consumption Time: 9.05911\nPPO Batch Consumption Time: 0.97050\nTotal Iteration Time: 30.98392\n\nCumulative Model Updates: 21,779\nCumulative Timesteps: 109,042,856\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 122.45248\nPolicy Entropy: 5.37226\nValue Function Loss: 0.06707\n\nMean KL Divergence: 0.00066\nSB3 Clip Fraction: 0.02323\nPolicy Update Magnitude: 0.20897\nValue Function Update Magnitude: 0.09102\n\nCollected Steps per Second: 1,805.44021\nOverall Steps per Second: 1,279.53468\n\nTimestep Collection Time: 22.15637\nTimestep Consumption Time: 9.10656\nPPO Batch Consumption Time: 0.97671\nTotal Iteration Time: 31.26293\n\nCumulative Model Updates: 21,787\nCumulative Timesteps: 109,082,858\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 103.13100\nPolicy Entropy: 5.39970\nValue Function Loss: 0.07084\n\nMean KL Divergence: 0.00071\nSB3 Clip Fraction: 0.02693\nPolicy Update Magnitude: 0.21669\nValue Function Update Magnitude: 0.10215\n\nCollected Steps per Second: 1,786.86676\nOverall Steps per Second: 1,270.58148\n\nTimestep Collection Time: 22.38555\nTimestep Consumption Time: 9.09610\nPPO Batch Consumption Time: 0.97995\nTotal Iteration Time: 31.48165\n\nCumulative Model Updates: 21,795\nCumulative Timesteps: 109,122,858\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 95.29887\nPolicy Entropy: 5.39096\nValue Function Loss: 0.07084\n\nMean KL Divergence: 0.00069\nSB3 Clip Fraction: 0.02373\nPolicy Update Magnitude: 0.22748\nValue Function Update Magnitude: 0.10271\n\nCollected Steps per Second: 1,793.80669\nOverall Steps per Second: 1,279.04668\n\nTimestep Collection Time: 22.29895\nTimestep Consumption Time: 8.97435\nPPO Batch Consumption Time: 1.01151\nTotal Iteration Time: 31.27329\n\nCumulative Model Updates: 21,803\nCumulative Timesteps: 109,162,858\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 90.95140\nPolicy Entropy: 5.40904\nValue Function Loss: 0.07035\n\nMean KL Divergence: 0.00071\nSB3 Clip Fraction: 0.02716\nPolicy Update Magnitude: 0.22948\nValue Function Update Magnitude: 0.10439\n\nCollected Steps per Second: 1,809.90740\nOverall Steps per Second: 1,286.67839\n\nTimestep Collection Time: 22.10058\nTimestep Consumption Time: 8.98722\nPPO Batch Consumption Time: 1.00545\nTotal Iteration Time: 31.08780\n\nCumulative Model Updates: 21,811\nCumulative Timesteps: 109,202,858\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 109202858...\nCheckpoint 109202858 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 78.85872\nPolicy Entropy: 5.38527\nValue Function Loss: 0.06881\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.02771\nPolicy Update Magnitude: 0.23043\nValue Function Update Magnitude: 0.10154\n\nCollected Steps per Second: 1,766.73248\nOverall Steps per Second: 1,271.45264\n\nTimestep Collection Time: 22.64067\nTimestep Consumption Time: 8.81941\nPPO Batch Consumption Time: 0.98341\nTotal Iteration Time: 31.46008\n\nCumulative Model Updates: 21,819\nCumulative Timesteps: 109,242,858\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 124.45393\nPolicy Entropy: 5.38147\nValue Function Loss: 0.06920\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.02981\nPolicy Update Magnitude: 0.21940\nValue Function Update Magnitude: 0.09593\n\nCollected Steps per Second: 1,789.17774\nOverall Steps per Second: 1,285.95106\n\nTimestep Collection Time: 22.35664\nTimestep Consumption Time: 8.74874\nPPO Batch Consumption Time: 0.98012\nTotal Iteration Time: 31.10538\n\nCumulative Model Updates: 21,827\nCumulative Timesteps: 109,282,858\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 88.34018\nPolicy Entropy: 5.37529\nValue Function Loss: 0.07446\n\nMean KL Divergence: 0.00076\nSB3 Clip Fraction: 0.02756\nPolicy Update Magnitude: 0.21978\nValue Function Update Magnitude: 0.10401\n\nCollected Steps per Second: 1,790.05152\nOverall Steps per Second: 1,289.15938\n\nTimestep Collection Time: 22.34684\nTimestep Consumption Time: 8.68268\nPPO Batch Consumption Time: 0.96609\nTotal Iteration Time: 31.02952\n\nCumulative Model Updates: 21,835\nCumulative Timesteps: 109,322,860\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 67.65424\nPolicy Entropy: 5.35631\nValue Function Loss: 0.07861\n\nMean KL Divergence: 0.00071\nSB3 Clip Fraction: 0.02775\nPolicy Update Magnitude: 0.22168\nValue Function Update Magnitude: 0.11092\n\nCollected Steps per Second: 1,770.60330\nOverall Steps per Second: 1,281.09382\n\nTimestep Collection Time: 22.59230\nTimestep Consumption Time: 8.63258\nPPO Batch Consumption Time: 0.96027\nTotal Iteration Time: 31.22488\n\nCumulative Model Updates: 21,843\nCumulative Timesteps: 109,362,862\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 103.64658\nPolicy Entropy: 5.34551\nValue Function Loss: 0.07536\n\nMean KL Divergence: 0.00089\nSB3 Clip Fraction: 0.03548\nPolicy Update Magnitude: 0.21596\nValue Function Update Magnitude: 0.10537\n\nCollected Steps per Second: 1,784.22068\nOverall Steps per Second: 1,288.55758\n\nTimestep Collection Time: 22.41875\nTimestep Consumption Time: 8.62371\nPPO Batch Consumption Time: 0.96835\nTotal Iteration Time: 31.04246\n\nCumulative Model Updates: 21,851\nCumulative Timesteps: 109,402,862\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 95.55020\nPolicy Entropy: 5.35728\nValue Function Loss: 0.07148\n\nMean KL Divergence: 0.00067\nSB3 Clip Fraction: 0.02410\nPolicy Update Magnitude: 0.22174\nValue Function Update Magnitude: 0.10407\n\nCollected Steps per Second: 1,778.78143\nOverall Steps per Second: 1,285.10257\n\nTimestep Collection Time: 22.48730\nTimestep Consumption Time: 8.63862\nPPO Batch Consumption Time: 0.96322\nTotal Iteration Time: 31.12592\n\nCumulative Model Updates: 21,859\nCumulative Timesteps: 109,442,862\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 90.66814\nPolicy Entropy: 5.35935\nValue Function Loss: 0.07161\n\nMean KL Divergence: 0.00081\nSB3 Clip Fraction: 0.02954\nPolicy Update Magnitude: 0.23531\nValue Function Update Magnitude: 0.10647\n\nCollected Steps per Second: 1,771.54895\nOverall Steps per Second: 1,279.95497\n\nTimestep Collection Time: 22.58024\nTimestep Consumption Time: 8.67242\nPPO Batch Consumption Time: 0.96336\nTotal Iteration Time: 31.25266\n\nCumulative Model Updates: 21,867\nCumulative Timesteps: 109,482,864\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 135.09355\nPolicy Entropy: 5.35223\nValue Function Loss: 0.07315\n\nMean KL Divergence: 0.00078\nSB3 Clip Fraction: 0.02854\nPolicy Update Magnitude: 0.22704\nValue Function Update Magnitude: 0.10009\n\nCollected Steps per Second: 1,766.66970\nOverall Steps per Second: 1,279.21403\n\nTimestep Collection Time: 22.64260\nTimestep Consumption Time: 8.62816\nPPO Batch Consumption Time: 0.95752\nTotal Iteration Time: 31.27076\n\nCumulative Model Updates: 21,875\nCumulative Timesteps: 109,522,866\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 103.65051\nPolicy Entropy: 5.33460\nValue Function Loss: 0.07122\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02489\nPolicy Update Magnitude: 0.21333\nValue Function Update Magnitude: 0.09194\n\nCollected Steps per Second: 1,752.62755\nOverall Steps per Second: 1,274.00627\n\nTimestep Collection Time: 22.82402\nTimestep Consumption Time: 8.57457\nPPO Batch Consumption Time: 0.95853\nTotal Iteration Time: 31.39859\n\nCumulative Model Updates: 21,883\nCumulative Timesteps: 109,562,868\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 77.62731\nPolicy Entropy: 5.34854\nValue Function Loss: 0.06840\n\nMean KL Divergence: 0.00068\nSB3 Clip Fraction: 0.02463\nPolicy Update Magnitude: 0.20517\nValue Function Update Magnitude: 0.09390\n\nCollected Steps per Second: 1,768.96452\nOverall Steps per Second: 1,287.87443\n\nTimestep Collection Time: 22.61323\nTimestep Consumption Time: 8.44725\nPPO Batch Consumption Time: 0.93994\nTotal Iteration Time: 31.06048\n\nCumulative Model Updates: 21,891\nCumulative Timesteps: 109,602,870\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 59.65600\nPolicy Entropy: 5.36158\nValue Function Loss: 0.06868\n\nMean KL Divergence: 0.00071\nSB3 Clip Fraction: 0.02575\nPolicy Update Magnitude: 0.20487\nValue Function Update Magnitude: 0.09887\n\nCollected Steps per Second: 1,787.46486\nOverall Steps per Second: 1,280.90814\n\nTimestep Collection Time: 22.37918\nTimestep Consumption Time: 8.85022\nPPO Batch Consumption Time: 0.98697\nTotal Iteration Time: 31.22941\n\nCumulative Model Updates: 21,899\nCumulative Timesteps: 109,642,872\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 100.85569\nPolicy Entropy: 5.35731\nValue Function Loss: 0.06697\n\nMean KL Divergence: 0.00067\nSB3 Clip Fraction: 0.02455\nPolicy Update Magnitude: 0.20403\nValue Function Update Magnitude: 0.10071\n\nCollected Steps per Second: 1,735.52323\nOverall Steps per Second: 1,258.73923\n\nTimestep Collection Time: 23.04896\nTimestep Consumption Time: 8.73046\nPPO Batch Consumption Time: 0.96912\nTotal Iteration Time: 31.77942\n\nCumulative Model Updates: 21,907\nCumulative Timesteps: 109,682,874\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 95.83929\nPolicy Entropy: 5.36790\nValue Function Loss: 0.06971\n\nMean KL Divergence: 0.00094\nSB3 Clip Fraction: 0.03893\nPolicy Update Magnitude: 0.20476\nValue Function Update Magnitude: 0.09649\n\nCollected Steps per Second: 1,745.64448\nOverall Steps per Second: 1,249.15356\n\nTimestep Collection Time: 22.91417\nTimestep Consumption Time: 9.10751\nPPO Batch Consumption Time: 0.97645\nTotal Iteration Time: 32.02168\n\nCumulative Model Updates: 21,915\nCumulative Timesteps: 109,722,874\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 109722874...\nCheckpoint 109722874 saved!\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 81.82088\nPolicy Entropy: 5.37851\nValue Function Loss: 0.07352\n\nMean KL Divergence: 0.00070\nSB3 Clip Fraction: 0.02530\nPolicy Update Magnitude: 0.20627\nValue Function Update Magnitude: 0.10126\n\nCollected Steps per Second: 1,770.54822\nOverall Steps per Second: 1,258.98895\n\nTimestep Collection Time: 22.59187\nTimestep Consumption Time: 9.17965\nPPO Batch Consumption Time: 0.98384\nTotal Iteration Time: 31.77153\n\nCumulative Model Updates: 21,923\nCumulative Timesteps: 109,762,874\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 123.66314\nPolicy Entropy: 5.39111\nValue Function Loss: 0.07341\n\nMean KL Divergence: 0.00084\nSB3 Clip Fraction: 0.03280\nPolicy Update Magnitude: 0.22642\nValue Function Update Magnitude: 0.10568\n\nCollected Steps per Second: 1,807.21896\nOverall Steps per Second: 1,281.90381\n\nTimestep Collection Time: 22.13346\nTimestep Consumption Time: 9.07013\nPPO Batch Consumption Time: 0.97951\nTotal Iteration Time: 31.20359\n\nCumulative Model Updates: 21,931\nCumulative Timesteps: 109,802,874\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 117.67848\nPolicy Entropy: 5.39092\nValue Function Loss: 0.07317\n\nMean KL Divergence: 0.00084\nSB3 Clip Fraction: 0.03280\nPolicy Update Magnitude: 0.24709\nValue Function Update Magnitude: 0.10703\n\nCollected Steps per Second: 1,790.39334\nOverall Steps per Second: 1,269.02469\n\nTimestep Collection Time: 22.34258\nTimestep Consumption Time: 9.17927\nPPO Batch Consumption Time: 0.99177\nTotal Iteration Time: 31.52185\n\nCumulative Model Updates: 21,939\nCumulative Timesteps: 109,842,876\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 95.67945\nPolicy Entropy: 5.38545\nValue Function Loss: 0.07243\n\nMean KL Divergence: 0.00083\nSB3 Clip Fraction: 0.03118\nPolicy Update Magnitude: 0.24329\nValue Function Update Magnitude: 0.10363\n\nCollected Steps per Second: 1,821.51951\nOverall Steps per Second: 1,295.41124\n\nTimestep Collection Time: 21.95969\nTimestep Consumption Time: 8.91854\nPPO Batch Consumption Time: 0.96272\nTotal Iteration Time: 30.87823\n\nCumulative Model Updates: 21,947\nCumulative Timesteps: 109,882,876\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 101.10008\nPolicy Entropy: 5.37283\nValue Function Loss: 0.07048\n\nMean KL Divergence: 0.00058\nSB3 Clip Fraction: 0.02015\nPolicy Update Magnitude: 0.21940\nValue Function Update Magnitude: 0.10292\n\nCollected Steps per Second: 1,843.87877\nOverall Steps per Second: 1,301.25196\n\nTimestep Collection Time: 21.69448\nTimestep Consumption Time: 9.04668\nPPO Batch Consumption Time: 0.97576\nTotal Iteration Time: 30.74116\n\nCumulative Model Updates: 21,955\nCumulative Timesteps: 109,922,878\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 92.66347\nPolicy Entropy: 5.36901\nValue Function Loss: 0.07170\n\nMean KL Divergence: 0.00067\nSB3 Clip Fraction: 0.02487\nPolicy Update Magnitude: 0.21770\nValue Function Update Magnitude: 0.10241\n\nCollected Steps per Second: 1,814.09129\nOverall Steps per Second: 1,290.49311\n\nTimestep Collection Time: 22.05071\nTimestep Consumption Time: 8.94674\nPPO Batch Consumption Time: 0.96460\nTotal Iteration Time: 30.99745\n\nCumulative Model Updates: 21,963\nCumulative Timesteps: 109,962,880\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 88.51568\nPolicy Entropy: 5.37681\nValue Function Loss: 0.07036\n\nMean KL Divergence: 0.00087\nSB3 Clip Fraction: 0.03439\nPolicy Update Magnitude: 0.21820\nValue Function Update Magnitude: 0.10756\n\nCollected Steps per Second: 1,785.26579\nOverall Steps per Second: 1,271.10885\n\nTimestep Collection Time: 22.40563\nTimestep Consumption Time: 9.06296\nPPO Batch Consumption Time: 0.97156\nTotal Iteration Time: 31.46859\n\nCumulative Model Updates: 21,971\nCumulative Timesteps: 110,002,880\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 109.60558\nPolicy Entropy: 5.37757\nValue Function Loss: 0.06861\n\nMean KL Divergence: 0.00099\nSB3 Clip Fraction: 0.04121\nPolicy Update Magnitude: 0.20777\nValue Function Update Magnitude: 0.10363\n\nCollected Steps per Second: 1,755.95714\nOverall Steps per Second: 1,250.78166\n\nTimestep Collection Time: 22.77960\nTimestep Consumption Time: 9.20040\nPPO Batch Consumption Time: 0.99143\nTotal Iteration Time: 31.98000\n\nCumulative Model Updates: 21,979\nCumulative Timesteps: 110,042,880\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 120.10264\nPolicy Entropy: 5.37163\nValue Function Loss: 0.07097\n\nMean KL Divergence: 0.00078\nSB3 Clip Fraction: 0.03126\nPolicy Update Magnitude: 0.21122\nValue Function Update Magnitude: 0.09891\n\nCollected Steps per Second: 1,807.32267\nOverall Steps per Second: 1,283.76755\n\nTimestep Collection Time: 22.13329\nTimestep Consumption Time: 9.02655\nPPO Batch Consumption Time: 0.97726\nTotal Iteration Time: 31.15985\n\nCumulative Model Updates: 21,987\nCumulative Timesteps: 110,082,882\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 95.99811\nPolicy Entropy: 5.38307\nValue Function Loss: 0.07102\n\nMean KL Divergence: 0.00086\nSB3 Clip Fraction: 0.03426\nPolicy Update Magnitude: 0.21740\nValue Function Update Magnitude: 0.10460\n\nCollected Steps per Second: 1,808.73921\nOverall Steps per Second: 1,285.77700\n\nTimestep Collection Time: 22.11596\nTimestep Consumption Time: 8.99519\nPPO Batch Consumption Time: 0.96927\nTotal Iteration Time: 31.11115\n\nCumulative Model Updates: 21,995\nCumulative Timesteps: 110,122,884\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 109.88863\nPolicy Entropy: 5.37861\nValue Function Loss: 0.06828\n\nMean KL Divergence: 0.00090\nSB3 Clip Fraction: 0.03759\nPolicy Update Magnitude: 0.21425\nValue Function Update Magnitude: 0.10001\n\nCollected Steps per Second: 1,760.10534\nOverall Steps per Second: 1,264.10696\n\nTimestep Collection Time: 22.72591\nTimestep Consumption Time: 8.91698\nPPO Batch Consumption Time: 0.96442\nTotal Iteration Time: 31.64289\n\nCumulative Model Updates: 22,003\nCumulative Timesteps: 110,162,884\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 57.66742\nPolicy Entropy: 5.38687\nValue Function Loss: 0.06978\n\nMean KL Divergence: 0.00090\nSB3 Clip Fraction: 0.03546\nPolicy Update Magnitude: 0.20983\nValue Function Update Magnitude: 0.09128\n\nCollected Steps per Second: 1,827.17467\nOverall Steps per Second: 1,294.21289\n\nTimestep Collection Time: 21.89172\nTimestep Consumption Time: 9.01509\nPPO Batch Consumption Time: 0.96728\nTotal Iteration Time: 30.90682\n\nCumulative Model Updates: 22,011\nCumulative Timesteps: 110,202,884\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 117.15422\nPolicy Entropy: 5.36739\nValue Function Loss: 0.06911\n\nMean KL Divergence: 0.00083\nSB3 Clip Fraction: 0.03149\nPolicy Update Magnitude: 0.20743\nValue Function Update Magnitude: 0.09265\n\nCollected Steps per Second: 1,813.00489\nOverall Steps per Second: 1,288.72017\n\nTimestep Collection Time: 22.06392\nTimestep Consumption Time: 8.97617\nPPO Batch Consumption Time: 0.97113\nTotal Iteration Time: 31.04010\n\nCumulative Model Updates: 22,019\nCumulative Timesteps: 110,242,886\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 110242886...\nCheckpoint 110242886 saved!\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 123.47929\nPolicy Entropy: 5.36282\nValue Function Loss: 0.06984\n\nMean KL Divergence: 0.00081\nSB3 Clip Fraction: 0.03049\nPolicy Update Magnitude: 0.20940\nValue Function Update Magnitude: 0.09438\n\nCollected Steps per Second: 1,841.15311\nOverall Steps per Second: 1,306.19076\n\nTimestep Collection Time: 21.72552\nTimestep Consumption Time: 8.89788\nPPO Batch Consumption Time: 0.95956\nTotal Iteration Time: 30.62340\n\nCumulative Model Updates: 22,027\nCumulative Timesteps: 110,282,886\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 104.37960\nPolicy Entropy: 5.36238\nValue Function Loss: 0.07312\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.03070\nPolicy Update Magnitude: 0.21878\nValue Function Update Magnitude: 0.09365\n\nCollected Steps per Second: 1,821.15860\nOverall Steps per Second: 1,296.24942\n\nTimestep Collection Time: 21.96514\nTimestep Consumption Time: 8.89466\nPPO Batch Consumption Time: 0.95025\nTotal Iteration Time: 30.85980\n\nCumulative Model Updates: 22,035\nCumulative Timesteps: 110,322,888\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 81.97766\nPolicy Entropy: 5.38199\nValue Function Loss: 0.07201\n\nMean KL Divergence: 0.00087\nSB3 Clip Fraction: 0.03334\nPolicy Update Magnitude: 0.23094\nValue Function Update Magnitude: 0.09439\n\nCollected Steps per Second: 1,848.37479\nOverall Steps per Second: 1,304.02036\n\nTimestep Collection Time: 21.64063\nTimestep Consumption Time: 9.03373\nPPO Batch Consumption Time: 0.97074\nTotal Iteration Time: 30.67437\n\nCumulative Model Updates: 22,043\nCumulative Timesteps: 110,362,888\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 91.09738\nPolicy Entropy: 5.37288\nValue Function Loss: 0.06877\n\nMean KL Divergence: 0.00126\nSB3 Clip Fraction: 0.03855\nPolicy Update Magnitude: 0.23633\nValue Function Update Magnitude: 0.09935\n\nCollected Steps per Second: 1,805.04163\nOverall Steps per Second: 1,289.73759\n\nTimestep Collection Time: 22.16015\nTimestep Consumption Time: 8.85391\nPPO Batch Consumption Time: 0.95772\nTotal Iteration Time: 31.01406\n\nCumulative Model Updates: 22,051\nCumulative Timesteps: 110,402,888\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 122.58330\nPolicy Entropy: 5.36147\nValue Function Loss: 0.07387\n\nMean KL Divergence: 0.00098\nSB3 Clip Fraction: 0.03836\nPolicy Update Magnitude: 0.24539\nValue Function Update Magnitude: 0.10157\n\nCollected Steps per Second: 1,807.10920\nOverall Steps per Second: 1,285.10682\n\nTimestep Collection Time: 22.13591\nTimestep Consumption Time: 8.99147\nPPO Batch Consumption Time: 0.97036\nTotal Iteration Time: 31.12737\n\nCumulative Model Updates: 22,059\nCumulative Timesteps: 110,442,890\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 109.97374\nPolicy Entropy: 5.38850\nValue Function Loss: 0.07665\n\nMean KL Divergence: 0.00085\nSB3 Clip Fraction: 0.02806\nPolicy Update Magnitude: 0.25277\nValue Function Update Magnitude: 0.11218\n\nCollected Steps per Second: 1,670.84118\nOverall Steps per Second: 1,215.35853\n\nTimestep Collection Time: 23.94123\nTimestep Consumption Time: 8.97251\nPPO Batch Consumption Time: 0.95443\nTotal Iteration Time: 32.91374\n\nCumulative Model Updates: 22,067\nCumulative Timesteps: 110,482,892\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 88.60733\nPolicy Entropy: 5.38184\nValue Function Loss: 0.07163\n\nMean KL Divergence: 0.00064\nSB3 Clip Fraction: 0.02304\nPolicy Update Magnitude: 0.24129\nValue Function Update Magnitude: 0.10711\n\nCollected Steps per Second: 1,830.12096\nOverall Steps per Second: 1,301.68760\n\nTimestep Collection Time: 21.85757\nTimestep Consumption Time: 8.87330\nPPO Batch Consumption Time: 0.95506\nTotal Iteration Time: 30.73088\n\nCumulative Model Updates: 22,075\nCumulative Timesteps: 110,522,894\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 109.38425\nPolicy Entropy: 5.36158\nValue Function Loss: 0.06824\n\nMean KL Divergence: 0.00067\nSB3 Clip Fraction: 0.02411\nPolicy Update Magnitude: 0.22315\nValue Function Update Magnitude: 0.10506\n\nCollected Steps per Second: 1,797.82112\nOverall Steps per Second: 1,277.30698\n\nTimestep Collection Time: 22.24915\nTimestep Consumption Time: 9.06673\nPPO Batch Consumption Time: 0.97750\nTotal Iteration Time: 31.31589\n\nCumulative Model Updates: 22,083\nCumulative Timesteps: 110,562,894\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 61.82304\nPolicy Entropy: 5.37662\nValue Function Loss: 0.06992\n\nMean KL Divergence: 0.00078\nSB3 Clip Fraction: 0.03099\nPolicy Update Magnitude: 0.21980\nValue Function Update Magnitude: 0.10834\n\nCollected Steps per Second: 1,795.88699\nOverall Steps per Second: 1,277.43439\n\nTimestep Collection Time: 22.27312\nTimestep Consumption Time: 9.03965\nPPO Batch Consumption Time: 0.96791\nTotal Iteration Time: 31.31276\n\nCumulative Model Updates: 22,091\nCumulative Timesteps: 110,602,894\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 129.71130\nPolicy Entropy: 5.35625\nValue Function Loss: 0.07189\n\nMean KL Divergence: 0.00088\nSB3 Clip Fraction: 0.03177\nPolicy Update Magnitude: 0.22079\nValue Function Update Magnitude: 0.10803\n\nCollected Steps per Second: 1,830.21298\nOverall Steps per Second: 1,294.71146\n\nTimestep Collection Time: 21.85538\nTimestep Consumption Time: 9.03953\nPPO Batch Consumption Time: 0.96922\nTotal Iteration Time: 30.89491\n\nCumulative Model Updates: 22,099\nCumulative Timesteps: 110,642,894\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 104.64299\nPolicy Entropy: 5.37055\nValue Function Loss: 0.07223\n\nMean KL Divergence: 0.00085\nSB3 Clip Fraction: 0.03401\nPolicy Update Magnitude: 0.22005\nValue Function Update Magnitude: 0.10392\n\nCollected Steps per Second: 1,839.60044\nOverall Steps per Second: 1,304.16946\n\nTimestep Collection Time: 21.74494\nTimestep Consumption Time: 8.92746\nPPO Batch Consumption Time: 0.95528\nTotal Iteration Time: 30.67239\n\nCumulative Model Updates: 22,107\nCumulative Timesteps: 110,682,896\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 104.34763\nPolicy Entropy: 5.38443\nValue Function Loss: 0.07269\n\nMean KL Divergence: 0.00081\nSB3 Clip Fraction: 0.03269\nPolicy Update Magnitude: 0.23152\nValue Function Update Magnitude: 0.10496\n\nCollected Steps per Second: 1,811.12493\nOverall Steps per Second: 1,287.79791\n\nTimestep Collection Time: 22.08572\nTimestep Consumption Time: 8.97505\nPPO Batch Consumption Time: 0.96872\nTotal Iteration Time: 31.06077\n\nCumulative Model Updates: 22,115\nCumulative Timesteps: 110,722,896\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 115.15719\nPolicy Entropy: 5.38233\nValue Function Loss: 0.06932\n\nMean KL Divergence: 0.00083\nSB3 Clip Fraction: 0.03274\nPolicy Update Magnitude: 0.22670\nValue Function Update Magnitude: 0.10289\n\nCollected Steps per Second: 1,821.62785\nOverall Steps per Second: 1,292.26485\n\nTimestep Collection Time: 21.95948\nTimestep Consumption Time: 8.99548\nPPO Batch Consumption Time: 0.97434\nTotal Iteration Time: 30.95495\n\nCumulative Model Updates: 22,123\nCumulative Timesteps: 110,762,898\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 110762898...\nCheckpoint 110762898 saved!\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 121.80476\nPolicy Entropy: 5.35967\nValue Function Loss: 0.06656\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02657\nPolicy Update Magnitude: 0.21688\nValue Function Update Magnitude: 0.10048\n\nCollected Steps per Second: 1,810.28437\nOverall Steps per Second: 1,284.33506\n\nTimestep Collection Time: 22.09819\nTimestep Consumption Time: 9.04945\nPPO Batch Consumption Time: 0.97676\nTotal Iteration Time: 31.14764\n\nCumulative Model Updates: 22,131\nCumulative Timesteps: 110,802,902\n\nTimesteps Collected: 40,004\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 104.75229\nPolicy Entropy: 5.35370\nValue Function Loss: 0.06681\n\nMean KL Divergence: 0.00096\nSB3 Clip Fraction: 0.03819\nPolicy Update Magnitude: 0.21714\nValue Function Update Magnitude: 0.09438\n\nCollected Steps per Second: 1,812.75219\nOverall Steps per Second: 1,286.84929\n\nTimestep Collection Time: 22.06590\nTimestep Consumption Time: 9.01778\nPPO Batch Consumption Time: 0.97463\nTotal Iteration Time: 31.08367\n\nCumulative Model Updates: 22,139\nCumulative Timesteps: 110,842,902\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 69.14060\nPolicy Entropy: 5.34632\nValue Function Loss: 0.07067\n\nMean KL Divergence: 0.00075\nSB3 Clip Fraction: 0.02601\nPolicy Update Magnitude: 0.21510\nValue Function Update Magnitude: 0.09684\n\nCollected Steps per Second: 1,804.40821\nOverall Steps per Second: 1,284.29176\n\nTimestep Collection Time: 22.16904\nTimestep Consumption Time: 8.97809\nPPO Batch Consumption Time: 0.97011\nTotal Iteration Time: 31.14713\n\nCumulative Model Updates: 22,147\nCumulative Timesteps: 110,882,904\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 106.79366\nPolicy Entropy: 5.35562\nValue Function Loss: 0.06788\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02733\nPolicy Update Magnitude: 0.21402\nValue Function Update Magnitude: 0.09414\n\nCollected Steps per Second: 1,815.19728\nOverall Steps per Second: 1,297.43304\n\nTimestep Collection Time: 22.03727\nTimestep Consumption Time: 8.79437\nPPO Batch Consumption Time: 0.98152\nTotal Iteration Time: 30.83165\n\nCumulative Model Updates: 22,155\nCumulative Timesteps: 110,922,906\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 110.06526\nPolicy Entropy: 5.35735\nValue Function Loss: 0.06778\n\nMean KL Divergence: 0.00075\nSB3 Clip Fraction: 0.02918\nPolicy Update Magnitude: 0.20545\nValue Function Update Magnitude: 0.09121\n\nCollected Steps per Second: 1,796.62971\nOverall Steps per Second: 1,288.19672\n\nTimestep Collection Time: 22.26391\nTimestep Consumption Time: 8.78725\nPPO Batch Consumption Time: 0.97626\nTotal Iteration Time: 31.05116\n\nCumulative Model Updates: 22,163\nCumulative Timesteps: 110,962,906\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 107.74088\nPolicy Entropy: 5.35443\nValue Function Loss: 0.07022\n\nMean KL Divergence: 0.00067\nSB3 Clip Fraction: 0.02423\nPolicy Update Magnitude: 0.21051\nValue Function Update Magnitude: 0.09315\n\nCollected Steps per Second: 1,770.67993\nOverall Steps per Second: 1,274.64897\n\nTimestep Collection Time: 22.59132\nTimestep Consumption Time: 8.79144\nPPO Batch Consumption Time: 0.97522\nTotal Iteration Time: 31.38276\n\nCumulative Model Updates: 22,171\nCumulative Timesteps: 111,002,908\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 103.82013\nPolicy Entropy: 5.36578\nValue Function Loss: 0.06834\n\nMean KL Divergence: 0.00075\nSB3 Clip Fraction: 0.02714\nPolicy Update Magnitude: 0.21410\nValue Function Update Magnitude: 0.09623\n\nCollected Steps per Second: 1,709.57691\nOverall Steps per Second: 1,241.32385\n\nTimestep Collection Time: 23.39760\nTimestep Consumption Time: 8.82606\nPPO Batch Consumption Time: 0.98705\nTotal Iteration Time: 32.22366\n\nCumulative Model Updates: 22,179\nCumulative Timesteps: 111,042,908\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 132.05995\nPolicy Entropy: 5.35607\nValue Function Loss: 0.06741\n\nMean KL Divergence: 0.00067\nSB3 Clip Fraction: 0.02386\nPolicy Update Magnitude: 0.21206\nValue Function Update Magnitude: 0.09703\n\nCollected Steps per Second: 1,645.83601\nOverall Steps per Second: 1,209.58050\n\nTimestep Collection Time: 24.30497\nTimestep Consumption Time: 8.76600\nPPO Batch Consumption Time: 0.97315\nTotal Iteration Time: 33.07097\n\nCumulative Model Updates: 22,187\nCumulative Timesteps: 111,082,910\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 82.72376\nPolicy Entropy: 5.35990\nValue Function Loss: 0.06814\n\nMean KL Divergence: 0.00066\nSB3 Clip Fraction: 0.02348\nPolicy Update Magnitude: 0.20809\nValue Function Update Magnitude: 0.09790\n\nCollected Steps per Second: 1,697.10593\nOverall Steps per Second: 1,240.90373\n\nTimestep Collection Time: 23.57071\nTimestep Consumption Time: 8.66547\nPPO Batch Consumption Time: 0.97014\nTotal Iteration Time: 32.23618\n\nCumulative Model Updates: 22,195\nCumulative Timesteps: 111,122,912\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 121.40862\nPolicy Entropy: 5.36673\nValue Function Loss: 0.06951\n\nMean KL Divergence: 0.00066\nSB3 Clip Fraction: 0.02350\nPolicy Update Magnitude: 0.20106\nValue Function Update Magnitude: 0.08978\n\nCollected Steps per Second: 1,702.79839\nOverall Steps per Second: 1,236.54640\n\nTimestep Collection Time: 23.49074\nTimestep Consumption Time: 8.85742\nPPO Batch Consumption Time: 0.98666\nTotal Iteration Time: 32.34816\n\nCumulative Model Updates: 22,203\nCumulative Timesteps: 111,162,912\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 80.66410\nPolicy Entropy: 5.36160\nValue Function Loss: 0.06896\n\nMean KL Divergence: 0.00064\nSB3 Clip Fraction: 0.02275\nPolicy Update Magnitude: 0.20224\nValue Function Update Magnitude: 0.08782\n\nCollected Steps per Second: 1,734.97182\nOverall Steps per Second: 1,266.25254\n\nTimestep Collection Time: 23.05628\nTimestep Consumption Time: 8.53457\nPPO Batch Consumption Time: 0.94914\nTotal Iteration Time: 31.59085\n\nCumulative Model Updates: 22,211\nCumulative Timesteps: 111,202,914\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 82.63562\nPolicy Entropy: 5.36817\nValue Function Loss: 0.07067\n\nMean KL Divergence: 0.00085\nSB3 Clip Fraction: 0.03236\nPolicy Update Magnitude: 0.21096\nValue Function Update Magnitude: 0.09701\n\nCollected Steps per Second: 1,729.80053\nOverall Steps per Second: 1,256.73449\n\nTimestep Collection Time: 23.12521\nTimestep Consumption Time: 8.70490\nPPO Batch Consumption Time: 0.97790\nTotal Iteration Time: 31.83011\n\nCumulative Model Updates: 22,219\nCumulative Timesteps: 111,242,916\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 78.32465\nPolicy Entropy: 5.37021\nValue Function Loss: 0.07179\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.02650\nPolicy Update Magnitude: 0.21463\nValue Function Update Magnitude: 0.09698\n\nCollected Steps per Second: 1,749.79825\nOverall Steps per Second: 1,268.96922\n\nTimestep Collection Time: 22.85978\nTimestep Consumption Time: 8.66187\nPPO Batch Consumption Time: 0.96575\nTotal Iteration Time: 31.52165\n\nCumulative Model Updates: 22,227\nCumulative Timesteps: 111,282,916\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 111282916...\nCheckpoint 111282916 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 123.24160\nPolicy Entropy: 5.36980\nValue Function Loss: 0.07090\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.02784\nPolicy Update Magnitude: 0.22307\nValue Function Update Magnitude: 0.09926\n\nCollected Steps per Second: 1,790.33351\nOverall Steps per Second: 1,279.74006\n\nTimestep Collection Time: 22.34332\nTimestep Consumption Time: 8.91459\nPPO Batch Consumption Time: 0.96356\nTotal Iteration Time: 31.25791\n\nCumulative Model Updates: 22,235\nCumulative Timesteps: 111,322,918\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 116.29372\nPolicy Entropy: 5.35125\nValue Function Loss: 0.07233\n\nMean KL Divergence: 0.00080\nSB3 Clip Fraction: 0.02894\nPolicy Update Magnitude: 0.22418\nValue Function Update Magnitude: 0.09182\n\nCollected Steps per Second: 1,799.25117\nOverall Steps per Second: 1,283.34274\n\nTimestep Collection Time: 22.23147\nTimestep Consumption Time: 8.93713\nPPO Batch Consumption Time: 0.96374\nTotal Iteration Time: 31.16860\n\nCumulative Model Updates: 22,243\nCumulative Timesteps: 111,362,918\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 81.38350\nPolicy Entropy: 5.35843\nValue Function Loss: 0.07251\n\nMean KL Divergence: 0.00089\nSB3 Clip Fraction: 0.03630\nPolicy Update Magnitude: 0.21814\nValue Function Update Magnitude: 0.10138\n\nCollected Steps per Second: 1,808.71950\nOverall Steps per Second: 1,284.21069\n\nTimestep Collection Time: 22.11620\nTimestep Consumption Time: 9.03290\nPPO Batch Consumption Time: 0.96654\nTotal Iteration Time: 31.14909\n\nCumulative Model Updates: 22,251\nCumulative Timesteps: 111,402,920\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 94.56191\nPolicy Entropy: 5.35628\nValue Function Loss: 0.07022\n\nMean KL Divergence: 0.00081\nSB3 Clip Fraction: 0.02989\nPolicy Update Magnitude: 0.21768\nValue Function Update Magnitude: 0.10008\n\nCollected Steps per Second: 1,802.61573\nOverall Steps per Second: 1,283.38444\n\nTimestep Collection Time: 22.18998\nTimestep Consumption Time: 8.97761\nPPO Batch Consumption Time: 0.96558\nTotal Iteration Time: 31.16759\n\nCumulative Model Updates: 22,259\nCumulative Timesteps: 111,442,920\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 106.43865\nPolicy Entropy: 5.35804\nValue Function Loss: 0.06725\n\nMean KL Divergence: 0.00081\nSB3 Clip Fraction: 0.02954\nPolicy Update Magnitude: 0.21394\nValue Function Update Magnitude: 0.10264\n\nCollected Steps per Second: 1,796.74744\nOverall Steps per Second: 1,277.17024\n\nTimestep Collection Time: 22.26356\nTimestep Consumption Time: 9.05724\nPPO Batch Consumption Time: 0.97233\nTotal Iteration Time: 31.32081\n\nCumulative Model Updates: 22,267\nCumulative Timesteps: 111,482,922\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 108.93205\nPolicy Entropy: 5.38429\nValue Function Loss: 0.06521\n\nMean KL Divergence: 0.00067\nSB3 Clip Fraction: 0.02450\nPolicy Update Magnitude: 0.20748\nValue Function Update Magnitude: 0.10163\n\nCollected Steps per Second: 1,760.93586\nOverall Steps per Second: 1,261.60685\n\nTimestep Collection Time: 22.71519\nTimestep Consumption Time: 8.99040\nPPO Batch Consumption Time: 0.96252\nTotal Iteration Time: 31.70560\n\nCumulative Model Updates: 22,275\nCumulative Timesteps: 111,522,922\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 84.30668\nPolicy Entropy: 5.39768\nValue Function Loss: 0.07137\n\nMean KL Divergence: 0.00064\nSB3 Clip Fraction: 0.02271\nPolicy Update Magnitude: 0.20623\nValue Function Update Magnitude: 0.10042\n\nCollected Steps per Second: 1,750.08240\nOverall Steps per Second: 1,252.21813\n\nTimestep Collection Time: 22.85607\nTimestep Consumption Time: 9.08725\nPPO Batch Consumption Time: 0.97779\nTotal Iteration Time: 31.94332\n\nCumulative Model Updates: 22,283\nCumulative Timesteps: 111,562,922\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 97.18457\nPolicy Entropy: 5.39686\nValue Function Loss: 0.07058\n\nMean KL Divergence: 0.00081\nSB3 Clip Fraction: 0.03221\nPolicy Update Magnitude: 0.21065\nValue Function Update Magnitude: 0.10227\n\nCollected Steps per Second: 1,833.21999\nOverall Steps per Second: 1,301.26491\n\nTimestep Collection Time: 21.82062\nTimestep Consumption Time: 8.92024\nPPO Batch Consumption Time: 0.96241\nTotal Iteration Time: 30.74086\n\nCumulative Model Updates: 22,291\nCumulative Timesteps: 111,602,924\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 127.95895\nPolicy Entropy: 5.37974\nValue Function Loss: 0.06893\n\nMean KL Divergence: 0.00065\nSB3 Clip Fraction: 0.02239\nPolicy Update Magnitude: 0.21131\nValue Function Update Magnitude: 0.09833\n\nCollected Steps per Second: 1,782.23046\nOverall Steps per Second: 1,267.41399\n\nTimestep Collection Time: 22.44491\nTimestep Consumption Time: 9.11700\nPPO Batch Consumption Time: 0.98605\nTotal Iteration Time: 31.56191\n\nCumulative Model Updates: 22,299\nCumulative Timesteps: 111,642,926\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 120.52367\nPolicy Entropy: 5.37816\nValue Function Loss: 0.07212\n\nMean KL Divergence: 0.00079\nSB3 Clip Fraction: 0.03085\nPolicy Update Magnitude: 0.21026\nValue Function Update Magnitude: 0.09176\n\nCollected Steps per Second: 1,802.21142\nOverall Steps per Second: 1,280.76788\n\nTimestep Collection Time: 22.19606\nTimestep Consumption Time: 9.03676\nPPO Batch Consumption Time: 0.96974\nTotal Iteration Time: 31.23283\n\nCumulative Model Updates: 22,307\nCumulative Timesteps: 111,682,928\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 100.84432\nPolicy Entropy: 5.37084\nValue Function Loss: 0.07307\n\nMean KL Divergence: 0.00086\nSB3 Clip Fraction: 0.03414\nPolicy Update Magnitude: 0.21257\nValue Function Update Magnitude: 0.09852\n\nCollected Steps per Second: 1,682.14346\nOverall Steps per Second: 1,219.08949\n\nTimestep Collection Time: 23.77918\nTimestep Consumption Time: 9.03219\nPPO Batch Consumption Time: 0.96794\nTotal Iteration Time: 32.81137\n\nCumulative Model Updates: 22,315\nCumulative Timesteps: 111,722,928\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 101.58071\nPolicy Entropy: 5.38635\nValue Function Loss: 0.07214\n\nMean KL Divergence: 0.00075\nSB3 Clip Fraction: 0.02816\nPolicy Update Magnitude: 0.21514\nValue Function Update Magnitude: 0.10423\n\nCollected Steps per Second: 1,779.42956\nOverall Steps per Second: 1,271.28390\n\nTimestep Collection Time: 22.48024\nTimestep Consumption Time: 8.98559\nPPO Batch Consumption Time: 0.96749\nTotal Iteration Time: 31.46583\n\nCumulative Model Updates: 22,323\nCumulative Timesteps: 111,762,930\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 114.25292\nPolicy Entropy: 5.38830\nValue Function Loss: 0.07302\n\nMean KL Divergence: 0.00089\nSB3 Clip Fraction: 0.03573\nPolicy Update Magnitude: 0.21270\nValue Function Update Magnitude: 0.09433\n\nCollected Steps per Second: 1,789.38262\nOverall Steps per Second: 1,277.47226\n\nTimestep Collection Time: 22.35520\nTimestep Consumption Time: 8.95820\nPPO Batch Consumption Time: 0.96867\nTotal Iteration Time: 31.31340\n\nCumulative Model Updates: 22,331\nCumulative Timesteps: 111,802,932\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 111802932...\nCheckpoint 111802932 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 118.66382\nPolicy Entropy: 5.36563\nValue Function Loss: 0.07310\n\nMean KL Divergence: 0.00088\nSB3 Clip Fraction: 0.03576\nPolicy Update Magnitude: 0.20702\nValue Function Update Magnitude: 0.09425\n\nCollected Steps per Second: 1,800.61005\nOverall Steps per Second: 1,281.41552\n\nTimestep Collection Time: 22.21469\nTimestep Consumption Time: 9.00079\nPPO Batch Consumption Time: 0.97290\nTotal Iteration Time: 31.21548\n\nCumulative Model Updates: 22,339\nCumulative Timesteps: 111,842,932\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 134.98159\nPolicy Entropy: 5.39476\nValue Function Loss: 0.07021\n\nMean KL Divergence: 0.00095\nSB3 Clip Fraction: 0.03904\nPolicy Update Magnitude: 0.20378\nValue Function Update Magnitude: 0.09650\n\nCollected Steps per Second: 1,808.72457\nOverall Steps per Second: 1,284.81941\n\nTimestep Collection Time: 22.11503\nTimestep Consumption Time: 9.01775\nPPO Batch Consumption Time: 0.96995\nTotal Iteration Time: 31.13278\n\nCumulative Model Updates: 22,347\nCumulative Timesteps: 111,882,932\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 92.19503\nPolicy Entropy: 5.41444\nValue Function Loss: 0.07167\n\nMean KL Divergence: 0.00084\nSB3 Clip Fraction: 0.03255\nPolicy Update Magnitude: 0.20283\nValue Function Update Magnitude: 0.09937\n\nCollected Steps per Second: 1,768.46976\nOverall Steps per Second: 1,262.25763\n\nTimestep Collection Time: 22.61956\nTimestep Consumption Time: 9.07128\nPPO Batch Consumption Time: 0.97405\nTotal Iteration Time: 31.69084\n\nCumulative Model Updates: 22,355\nCumulative Timesteps: 111,922,934\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 112.99757\nPolicy Entropy: 5.41943\nValue Function Loss: 0.07486\n\nMean KL Divergence: 0.00078\nSB3 Clip Fraction: 0.03006\nPolicy Update Magnitude: 0.21195\nValue Function Update Magnitude: 0.10085\n\nCollected Steps per Second: 1,817.47323\nOverall Steps per Second: 1,287.22938\n\nTimestep Collection Time: 22.00968\nTimestep Consumption Time: 9.06637\nPPO Batch Consumption Time: 0.98066\nTotal Iteration Time: 31.07605\n\nCumulative Model Updates: 22,363\nCumulative Timesteps: 111,962,936\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 103.36847\nPolicy Entropy: 5.40131\nValue Function Loss: 0.07177\n\nMean KL Divergence: 0.00104\nSB3 Clip Fraction: 0.04244\nPolicy Update Magnitude: 0.21945\nValue Function Update Magnitude: 0.09657\n\nCollected Steps per Second: 1,735.19463\nOverall Steps per Second: 1,246.95028\n\nTimestep Collection Time: 23.05217\nTimestep Consumption Time: 9.02609\nPPO Batch Consumption Time: 0.97096\nTotal Iteration Time: 32.07826\n\nCumulative Model Updates: 22,371\nCumulative Timesteps: 112,002,936\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 79.77176\nPolicy Entropy: 5.43329\nValue Function Loss: 0.07036\n\nMean KL Divergence: 0.00087\nSB3 Clip Fraction: 0.03250\nPolicy Update Magnitude: 0.23002\nValue Function Update Magnitude: 0.10293\n\nCollected Steps per Second: 1,757.67863\nOverall Steps per Second: 1,272.54240\n\nTimestep Collection Time: 22.75843\nTimestep Consumption Time: 8.67628\nPPO Batch Consumption Time: 0.96425\nTotal Iteration Time: 31.43471\n\nCumulative Model Updates: 22,379\nCumulative Timesteps: 112,042,938\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 121.06734\nPolicy Entropy: 5.41119\nValue Function Loss: 0.06860\n\nMean KL Divergence: 0.00082\nSB3 Clip Fraction: 0.03089\nPolicy Update Magnitude: 0.21951\nValue Function Update Magnitude: 0.10476\n\nCollected Steps per Second: 1,764.55670\nOverall Steps per Second: 1,270.70543\n\nTimestep Collection Time: 22.66858\nTimestep Consumption Time: 8.81000\nPPO Batch Consumption Time: 0.98422\nTotal Iteration Time: 31.47858\n\nCumulative Model Updates: 22,387\nCumulative Timesteps: 112,082,938\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 109.71588\nPolicy Entropy: 5.37370\nValue Function Loss: 0.06792\n\nMean KL Divergence: 0.00086\nSB3 Clip Fraction: 0.03355\nPolicy Update Magnitude: 0.20732\nValue Function Update Magnitude: 0.09423\n\nCollected Steps per Second: 1,768.70788\nOverall Steps per Second: 1,268.32117\n\nTimestep Collection Time: 22.61651\nTimestep Consumption Time: 8.92282\nPPO Batch Consumption Time: 0.99567\nTotal Iteration Time: 31.53933\n\nCumulative Model Updates: 22,395\nCumulative Timesteps: 112,122,940\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 80.65404\nPolicy Entropy: 5.38501\nValue Function Loss: 0.06722\n\nMean KL Divergence: 0.00088\nSB3 Clip Fraction: 0.03571\nPolicy Update Magnitude: 0.20567\nValue Function Update Magnitude: 0.09469\n\nCollected Steps per Second: 1,717.98670\nOverall Steps per Second: 1,248.15459\n\nTimestep Collection Time: 23.28307\nTimestep Consumption Time: 8.76425\nPPO Batch Consumption Time: 0.98145\nTotal Iteration Time: 32.04731\n\nCumulative Model Updates: 22,403\nCumulative Timesteps: 112,162,940\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 104.82851\nPolicy Entropy: 5.41278\nValue Function Loss: 0.06870\n\nMean KL Divergence: 0.00085\nSB3 Clip Fraction: 0.03207\nPolicy Update Magnitude: 0.21019\nValue Function Update Magnitude: 0.10318\n\nCollected Steps per Second: 1,687.91895\nOverall Steps per Second: 1,235.27634\n\nTimestep Collection Time: 23.69901\nTimestep Consumption Time: 8.68403\nPPO Batch Consumption Time: 0.97265\nTotal Iteration Time: 32.38304\n\nCumulative Model Updates: 22,411\nCumulative Timesteps: 112,202,942\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 127.53505\nPolicy Entropy: 5.39520\nValue Function Loss: 0.06911\n\nMean KL Divergence: 0.00095\nSB3 Clip Fraction: 0.03889\nPolicy Update Magnitude: 0.20527\nValue Function Update Magnitude: 0.10084\n\nCollected Steps per Second: 1,715.11844\nOverall Steps per Second: 1,248.52696\n\nTimestep Collection Time: 23.32200\nTimestep Consumption Time: 8.71575\nPPO Batch Consumption Time: 0.97120\nTotal Iteration Time: 32.03775\n\nCumulative Model Updates: 22,419\nCumulative Timesteps: 112,242,942\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 90.99960\nPolicy Entropy: 5.39570\nValue Function Loss: 0.07027\n\nMean KL Divergence: 0.00091\nSB3 Clip Fraction: 0.03748\nPolicy Update Magnitude: 0.20325\nValue Function Update Magnitude: 0.08916\n\nCollected Steps per Second: 1,720.35680\nOverall Steps per Second: 1,250.75154\n\nTimestep Collection Time: 23.25099\nTimestep Consumption Time: 8.72978\nPPO Batch Consumption Time: 0.96914\nTotal Iteration Time: 31.98077\n\nCumulative Model Updates: 22,427\nCumulative Timesteps: 112,282,942\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 80.13375\nPolicy Entropy: 5.40024\nValue Function Loss: 0.06959\n\nMean KL Divergence: 0.00085\nSB3 Clip Fraction: 0.03349\nPolicy Update Magnitude: 0.20991\nValue Function Update Magnitude: 0.09608\n\nCollected Steps per Second: 1,770.18366\nOverall Steps per Second: 1,273.07415\n\nTimestep Collection Time: 22.59766\nTimestep Consumption Time: 8.82392\nPPO Batch Consumption Time: 0.98181\nTotal Iteration Time: 31.42158\n\nCumulative Model Updates: 22,435\nCumulative Timesteps: 112,322,944\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 112322944...\nCheckpoint 112322944 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 91.92751\nPolicy Entropy: 5.40436\nValue Function Loss: 0.06757\n\nMean KL Divergence: 0.00076\nSB3 Clip Fraction: 0.02980\nPolicy Update Magnitude: 0.21580\nValue Function Update Magnitude: 0.10167\n\nCollected Steps per Second: 1,800.76033\nOverall Steps per Second: 1,297.32940\n\nTimestep Collection Time: 22.21395\nTimestep Consumption Time: 8.62016\nPPO Batch Consumption Time: 0.96250\nTotal Iteration Time: 30.83411\n\nCumulative Model Updates: 22,443\nCumulative Timesteps: 112,362,946\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 82.86082\nPolicy Entropy: 5.39860\nValue Function Loss: 0.06584\n\nMean KL Divergence: 0.00085\nSB3 Clip Fraction: 0.03309\nPolicy Update Magnitude: 0.21542\nValue Function Update Magnitude: 0.10099\n\nCollected Steps per Second: 1,739.28512\nOverall Steps per Second: 1,260.94622\n\nTimestep Collection Time: 22.99795\nTimestep Consumption Time: 8.72425\nPPO Batch Consumption Time: 0.97311\nTotal Iteration Time: 31.72221\n\nCumulative Model Updates: 22,451\nCumulative Timesteps: 112,402,946\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 112.14782\nPolicy Entropy: 5.40504\nValue Function Loss: 0.06757\n\nMean KL Divergence: 0.00086\nSB3 Clip Fraction: 0.03285\nPolicy Update Magnitude: 0.21569\nValue Function Update Magnitude: 0.09413\n\nCollected Steps per Second: 1,754.26829\nOverall Steps per Second: 1,271.52307\n\nTimestep Collection Time: 22.80267\nTimestep Consumption Time: 8.65724\nPPO Batch Consumption Time: 0.96902\nTotal Iteration Time: 31.45991\n\nCumulative Model Updates: 22,459\nCumulative Timesteps: 112,442,948\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 86.91777\nPolicy Entropy: 5.37173\nValue Function Loss: 0.07488\n\nMean KL Divergence: 0.00082\nSB3 Clip Fraction: 0.03100\nPolicy Update Magnitude: 0.21502\nValue Function Update Magnitude: 0.09674\n\nCollected Steps per Second: 1,729.07213\nOverall Steps per Second: 1,256.27317\n\nTimestep Collection Time: 23.13495\nTimestep Consumption Time: 8.70685\nPPO Batch Consumption Time: 0.96067\nTotal Iteration Time: 31.84180\n\nCumulative Model Updates: 22,467\nCumulative Timesteps: 112,482,950\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 110.95734\nPolicy Entropy: 5.37334\nValue Function Loss: 0.07690\n\nMean KL Divergence: 0.00082\nSB3 Clip Fraction: 0.03161\nPolicy Update Magnitude: 0.21780\nValue Function Update Magnitude: 0.10072\n\nCollected Steps per Second: 1,803.20004\nOverall Steps per Second: 1,280.17716\n\nTimestep Collection Time: 22.18279\nTimestep Consumption Time: 9.06289\nPPO Batch Consumption Time: 0.97355\nTotal Iteration Time: 31.24568\n\nCumulative Model Updates: 22,475\nCumulative Timesteps: 112,522,950\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 105.59987\nPolicy Entropy: 5.37318\nValue Function Loss: 0.07050\n\nMean KL Divergence: 0.00113\nSB3 Clip Fraction: 0.04746\nPolicy Update Magnitude: 0.21608\nValue Function Update Magnitude: 0.09556\n\nCollected Steps per Second: 1,755.93457\nOverall Steps per Second: 1,258.99928\n\nTimestep Collection Time: 22.78103\nTimestep Consumption Time: 8.99182\nPPO Batch Consumption Time: 0.96309\nTotal Iteration Time: 31.77285\n\nCumulative Model Updates: 22,483\nCumulative Timesteps: 112,562,952\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 115.57264\nPolicy Entropy: 5.38775\nValue Function Loss: 0.06662\n\nMean KL Divergence: 0.00088\nSB3 Clip Fraction: 0.03071\nPolicy Update Magnitude: 0.20421\nValue Function Update Magnitude: 0.09413\n\nCollected Steps per Second: 1,744.58203\nOverall Steps per Second: 1,237.96042\n\nTimestep Collection Time: 22.92813\nTimestep Consumption Time: 9.38308\nPPO Batch Consumption Time: 1.00941\nTotal Iteration Time: 32.31121\n\nCumulative Model Updates: 22,491\nCumulative Timesteps: 112,602,952\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 125.97909\nPolicy Entropy: 5.35659\nValue Function Loss: 0.06677\n\nMean KL Divergence: 0.00087\nSB3 Clip Fraction: 0.03518\nPolicy Update Magnitude: 0.19698\nValue Function Update Magnitude: 0.09394\n\nCollected Steps per Second: 1,770.61916\nOverall Steps per Second: 1,267.21444\n\nTimestep Collection Time: 22.59210\nTimestep Consumption Time: 8.97478\nPPO Batch Consumption Time: 0.96822\nTotal Iteration Time: 31.56688\n\nCumulative Model Updates: 22,499\nCumulative Timesteps: 112,642,954\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 105.00039\nPolicy Entropy: 5.38337\nValue Function Loss: 0.06979\n\nMean KL Divergence: 0.00082\nSB3 Clip Fraction: 0.03233\nPolicy Update Magnitude: 0.19864\nValue Function Update Magnitude: 0.09278\n\nCollected Steps per Second: 1,728.84120\nOverall Steps per Second: 1,260.45721\n\nTimestep Collection Time: 23.13804\nTimestep Consumption Time: 8.59806\nPPO Batch Consumption Time: 0.95717\nTotal Iteration Time: 31.73610\n\nCumulative Model Updates: 22,507\nCumulative Timesteps: 112,682,956\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 115.30975\nPolicy Entropy: 5.39621\nValue Function Loss: 0.06985\n\nMean KL Divergence: 0.00068\nSB3 Clip Fraction: 0.02490\nPolicy Update Magnitude: 0.20588\nValue Function Update Magnitude: 0.09556\n\nCollected Steps per Second: 1,785.87760\nOverall Steps per Second: 1,292.63738\n\nTimestep Collection Time: 22.39907\nTimestep Consumption Time: 8.54696\nPPO Batch Consumption Time: 0.95035\nTotal Iteration Time: 30.94603\n\nCumulative Model Updates: 22,515\nCumulative Timesteps: 112,722,958\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 96.83549\nPolicy Entropy: 5.39903\nValue Function Loss: 0.06902\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.02849\nPolicy Update Magnitude: 0.20222\nValue Function Update Magnitude: 0.09311\n\nCollected Steps per Second: 1,750.63078\nOverall Steps per Second: 1,264.15104\n\nTimestep Collection Time: 22.84891\nTimestep Consumption Time: 8.79288\nPPO Batch Consumption Time: 0.98555\nTotal Iteration Time: 31.64179\n\nCumulative Model Updates: 22,523\nCumulative Timesteps: 112,762,958\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 111.34141\nPolicy Entropy: 5.38235\nValue Function Loss: 0.06932\n\nMean KL Divergence: 0.00073\nSB3 Clip Fraction: 0.02732\nPolicy Update Magnitude: 0.20316\nValue Function Update Magnitude: 0.09440\n\nCollected Steps per Second: 1,753.35501\nOverall Steps per Second: 1,266.50200\n\nTimestep Collection Time: 22.81341\nTimestep Consumption Time: 8.76965\nPPO Batch Consumption Time: 0.98370\nTotal Iteration Time: 31.58305\n\nCumulative Model Updates: 22,531\nCumulative Timesteps: 112,802,958\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 99.98638\nPolicy Entropy: 5.37548\nValue Function Loss: 0.06920\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.02649\nPolicy Update Magnitude: 0.21110\nValue Function Update Magnitude: 0.09507\n\nCollected Steps per Second: 1,768.72905\nOverall Steps per Second: 1,277.60296\n\nTimestep Collection Time: 22.61511\nTimestep Consumption Time: 8.69352\nPPO Batch Consumption Time: 0.96943\nTotal Iteration Time: 31.30863\n\nCumulative Model Updates: 22,539\nCumulative Timesteps: 112,842,958\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 112842958...\nCheckpoint 112842958 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 98.97016\nPolicy Entropy: 5.35976\nValue Function Loss: 0.07050\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02563\nPolicy Update Magnitude: 0.20456\nValue Function Update Magnitude: 0.09527\n\nCollected Steps per Second: 1,768.52629\nOverall Steps per Second: 1,273.45337\n\nTimestep Collection Time: 22.61883\nTimestep Consumption Time: 8.79339\nPPO Batch Consumption Time: 0.97741\nTotal Iteration Time: 31.41222\n\nCumulative Model Updates: 22,547\nCumulative Timesteps: 112,882,960\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 130.91759\nPolicy Entropy: 5.35698\nValue Function Loss: 0.06911\n\nMean KL Divergence: 0.00086\nSB3 Clip Fraction: 0.03311\nPolicy Update Magnitude: 0.20439\nValue Function Update Magnitude: 0.09342\n\nCollected Steps per Second: 1,748.93993\nOverall Steps per Second: 1,257.99523\n\nTimestep Collection Time: 22.87100\nTimestep Consumption Time: 8.92563\nPPO Batch Consumption Time: 0.99778\nTotal Iteration Time: 31.79662\n\nCumulative Model Updates: 22,555\nCumulative Timesteps: 112,922,960\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 123.22776\nPolicy Entropy: 5.38304\nValue Function Loss: 0.06675\n\nMean KL Divergence: 0.00080\nSB3 Clip Fraction: 0.03165\nPolicy Update Magnitude: 0.20416\nValue Function Update Magnitude: 0.09394\n\nCollected Steps per Second: 1,764.92442\nOverall Steps per Second: 1,267.91559\n\nTimestep Collection Time: 22.66499\nTimestep Consumption Time: 8.88443\nPPO Batch Consumption Time: 0.99147\nTotal Iteration Time: 31.54942\n\nCumulative Model Updates: 22,563\nCumulative Timesteps: 112,962,962\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 76.27183\nPolicy Entropy: 5.38840\nValue Function Loss: 0.06874\n\nMean KL Divergence: 0.00076\nSB3 Clip Fraction: 0.02922\nPolicy Update Magnitude: 0.19934\nValue Function Update Magnitude: 0.09960\n\nCollected Steps per Second: 1,696.63416\nOverall Steps per Second: 1,237.31747\n\nTimestep Collection Time: 23.57727\nTimestep Consumption Time: 8.75235\nPPO Batch Consumption Time: 0.97645\nTotal Iteration Time: 32.32962\n\nCumulative Model Updates: 22,571\nCumulative Timesteps: 113,002,964\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 81.68241\nPolicy Entropy: 5.36389\nValue Function Loss: 0.07173\n\nMean KL Divergence: 0.00066\nSB3 Clip Fraction: 0.02417\nPolicy Update Magnitude: 0.20287\nValue Function Update Magnitude: 0.09597\n\nCollected Steps per Second: 1,751.37562\nOverall Steps per Second: 1,265.03182\n\nTimestep Collection Time: 22.84033\nTimestep Consumption Time: 8.78101\nPPO Batch Consumption Time: 0.97813\nTotal Iteration Time: 31.62134\n\nCumulative Model Updates: 22,579\nCumulative Timesteps: 113,042,966\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 124.37219\nPolicy Entropy: 5.36819\nValue Function Loss: 0.07005\n\nMean KL Divergence: 0.00084\nSB3 Clip Fraction: 0.03322\nPolicy Update Magnitude: 0.21022\nValue Function Update Magnitude: 0.09116\n\nCollected Steps per Second: 1,755.82128\nOverall Steps per Second: 1,268.25143\n\nTimestep Collection Time: 22.78136\nTimestep Consumption Time: 8.75813\nPPO Batch Consumption Time: 0.97335\nTotal Iteration Time: 31.53949\n\nCumulative Model Updates: 22,587\nCumulative Timesteps: 113,082,966\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 117.25007\nPolicy Entropy: 5.38089\nValue Function Loss: 0.06936\n\nMean KL Divergence: 0.00076\nSB3 Clip Fraction: 0.02706\nPolicy Update Magnitude: 0.20508\nValue Function Update Magnitude: 0.08895\n\nCollected Steps per Second: 1,698.28287\nOverall Steps per Second: 1,236.90502\n\nTimestep Collection Time: 23.55438\nTimestep Consumption Time: 8.78602\nPPO Batch Consumption Time: 0.97608\nTotal Iteration Time: 32.34040\n\nCumulative Model Updates: 22,595\nCumulative Timesteps: 113,122,968\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 112.90486\nPolicy Entropy: 5.40165\nValue Function Loss: 0.07038\n\nMean KL Divergence: 0.00066\nSB3 Clip Fraction: 0.02349\nPolicy Update Magnitude: 0.21501\nValue Function Update Magnitude: 0.09788\n\nCollected Steps per Second: 1,759.70301\nOverall Steps per Second: 1,280.74351\n\nTimestep Collection Time: 22.73224\nTimestep Consumption Time: 8.50118\nPPO Batch Consumption Time: 0.94870\nTotal Iteration Time: 31.23342\n\nCumulative Model Updates: 22,603\nCumulative Timesteps: 113,162,970\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 112.26350\nPolicy Entropy: 5.40674\nValue Function Loss: 0.06642\n\nMean KL Divergence: 0.00084\nSB3 Clip Fraction: 0.02701\nPolicy Update Magnitude: 0.21692\nValue Function Update Magnitude: 0.09956\n\nCollected Steps per Second: 1,761.74621\nOverall Steps per Second: 1,267.80636\n\nTimestep Collection Time: 22.70475\nTimestep Consumption Time: 8.84581\nPPO Batch Consumption Time: 0.98210\nTotal Iteration Time: 31.55056\n\nCumulative Model Updates: 22,611\nCumulative Timesteps: 113,202,970\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 86.19601\nPolicy Entropy: 5.38108\nValue Function Loss: 0.06757\n\nMean KL Divergence: 0.00069\nSB3 Clip Fraction: 0.02444\nPolicy Update Magnitude: 0.21343\nValue Function Update Magnitude: 0.09668\n\nCollected Steps per Second: 1,713.71830\nOverall Steps per Second: 1,232.20609\n\nTimestep Collection Time: 23.34223\nTimestep Consumption Time: 9.12150\nPPO Batch Consumption Time: 0.97800\nTotal Iteration Time: 32.46373\n\nCumulative Model Updates: 22,619\nCumulative Timesteps: 113,242,972\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 94.96035\nPolicy Entropy: 5.36370\nValue Function Loss: 0.06920\n\nMean KL Divergence: 0.00085\nSB3 Clip Fraction: 0.03416\nPolicy Update Magnitude: 0.21120\nValue Function Update Magnitude: 0.09711\n\nCollected Steps per Second: 1,793.00255\nOverall Steps per Second: 1,276.05530\n\nTimestep Collection Time: 22.31006\nTimestep Consumption Time: 9.03811\nPPO Batch Consumption Time: 0.97483\nTotal Iteration Time: 31.34817\n\nCumulative Model Updates: 22,627\nCumulative Timesteps: 113,282,974\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 108.10411\nPolicy Entropy: 5.37878\nValue Function Loss: 0.06532\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.02889\nPolicy Update Magnitude: 0.19900\nValue Function Update Magnitude: 0.09576\n\nCollected Steps per Second: 1,808.97535\nOverall Steps per Second: 1,285.55448\n\nTimestep Collection Time: 22.11307\nTimestep Consumption Time: 9.00346\nPPO Batch Consumption Time: 0.97350\nTotal Iteration Time: 31.11653\n\nCumulative Model Updates: 22,635\nCumulative Timesteps: 113,322,976\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 103.23939\nPolicy Entropy: 5.39945\nValue Function Loss: 0.06518\n\nMean KL Divergence: 0.00070\nSB3 Clip Fraction: 0.02556\nPolicy Update Magnitude: 0.19975\nValue Function Update Magnitude: 0.08948\n\nCollected Steps per Second: 1,772.01876\nOverall Steps per Second: 1,268.73839\n\nTimestep Collection Time: 22.57425\nTimestep Consumption Time: 8.95471\nPPO Batch Consumption Time: 0.96414\nTotal Iteration Time: 31.52896\n\nCumulative Model Updates: 22,643\nCumulative Timesteps: 113,362,978\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 113362978...\nCheckpoint 113362978 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 74.18224\nPolicy Entropy: 5.40034\nValue Function Loss: 0.06949\n\nMean KL Divergence: 0.00070\nSB3 Clip Fraction: 0.02556\nPolicy Update Magnitude: 0.21644\nValue Function Update Magnitude: 0.09695\n\nCollected Steps per Second: 1,767.56275\nOverall Steps per Second: 1,270.48741\n\nTimestep Collection Time: 22.63116\nTimestep Consumption Time: 8.85439\nPPO Batch Consumption Time: 0.95471\nTotal Iteration Time: 31.48555\n\nCumulative Model Updates: 22,651\nCumulative Timesteps: 113,402,980\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 103.05105\nPolicy Entropy: 5.38771\nValue Function Loss: 0.07192\n\nMean KL Divergence: 0.00076\nSB3 Clip Fraction: 0.02960\nPolicy Update Magnitude: 0.20974\nValue Function Update Magnitude: 0.09415\n\nCollected Steps per Second: 1,781.08328\nOverall Steps per Second: 1,274.11537\n\nTimestep Collection Time: 22.45937\nTimestep Consumption Time: 8.93654\nPPO Batch Consumption Time: 0.96948\nTotal Iteration Time: 31.39590\n\nCumulative Model Updates: 22,659\nCumulative Timesteps: 113,442,982\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 115.58439\nPolicy Entropy: 5.39040\nValue Function Loss: 0.07128\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.03020\nPolicy Update Magnitude: 0.21769\nValue Function Update Magnitude: 0.09834\n\nCollected Steps per Second: 1,795.16442\nOverall Steps per Second: 1,272.86872\n\nTimestep Collection Time: 22.28208\nTimestep Consumption Time: 9.14300\nPPO Batch Consumption Time: 0.98539\nTotal Iteration Time: 31.42508\n\nCumulative Model Updates: 22,667\nCumulative Timesteps: 113,482,982\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 105.46594\nPolicy Entropy: 5.40505\nValue Function Loss: 0.07076\n\nMean KL Divergence: 0.00085\nSB3 Clip Fraction: 0.03135\nPolicy Update Magnitude: 0.22058\nValue Function Update Magnitude: 0.09972\n\nCollected Steps per Second: 1,772.32319\nOverall Steps per Second: 1,257.12241\n\nTimestep Collection Time: 22.57038\nTimestep Consumption Time: 9.24991\nPPO Batch Consumption Time: 0.99710\nTotal Iteration Time: 31.82029\n\nCumulative Model Updates: 22,675\nCumulative Timesteps: 113,522,984\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 100.17906\nPolicy Entropy: 5.40337\nValue Function Loss: 0.07157\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.02776\nPolicy Update Magnitude: 0.20862\nValue Function Update Magnitude: 0.09876\n\nCollected Steps per Second: 1,766.26630\nOverall Steps per Second: 1,261.16633\n\nTimestep Collection Time: 22.64777\nTimestep Consumption Time: 9.07048\nPPO Batch Consumption Time: 0.97768\nTotal Iteration Time: 31.71826\n\nCumulative Model Updates: 22,683\nCumulative Timesteps: 113,562,986\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 111.02145\nPolicy Entropy: 5.40281\nValue Function Loss: 0.06999\n\nMean KL Divergence: 0.00083\nSB3 Clip Fraction: 0.03191\nPolicy Update Magnitude: 0.20456\nValue Function Update Magnitude: 0.09714\n\nCollected Steps per Second: 1,754.64246\nOverall Steps per Second: 1,254.16144\n\nTimestep Collection Time: 22.79667\nTimestep Consumption Time: 9.09715\nPPO Batch Consumption Time: 0.98300\nTotal Iteration Time: 31.89382\n\nCumulative Model Updates: 22,691\nCumulative Timesteps: 113,602,986\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 84.67296\nPolicy Entropy: 5.41500\nValue Function Loss: 0.06917\n\nMean KL Divergence: 0.00089\nSB3 Clip Fraction: 0.03457\nPolicy Update Magnitude: 0.21390\nValue Function Update Magnitude: 0.10020\n\nCollected Steps per Second: 1,713.82063\nOverall Steps per Second: 1,232.44218\n\nTimestep Collection Time: 23.33967\nTimestep Consumption Time: 9.11622\nPPO Batch Consumption Time: 0.98578\nTotal Iteration Time: 32.45588\n\nCumulative Model Updates: 22,699\nCumulative Timesteps: 113,642,986\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 100.06274\nPolicy Entropy: 5.40113\nValue Function Loss: 0.07230\n\nMean KL Divergence: 0.00071\nSB3 Clip Fraction: 0.02494\nPolicy Update Magnitude: 0.21225\nValue Function Update Magnitude: 0.10319\n\nCollected Steps per Second: 1,730.67072\nOverall Steps per Second: 1,243.09998\n\nTimestep Collection Time: 23.11243\nTimestep Consumption Time: 9.06519\nPPO Batch Consumption Time: 0.97231\nTotal Iteration Time: 32.17762\n\nCumulative Model Updates: 22,707\nCumulative Timesteps: 113,682,986\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 100.39568\nPolicy Entropy: 5.38950\nValue Function Loss: 0.07352\n\nMean KL Divergence: 0.00059\nSB3 Clip Fraction: 0.02066\nPolicy Update Magnitude: 0.21398\nValue Function Update Magnitude: 0.10154\n\nCollected Steps per Second: 1,753.01303\nOverall Steps per Second: 1,256.59335\n\nTimestep Collection Time: 22.81786\nTimestep Consumption Time: 9.01424\nPPO Batch Consumption Time: 0.97503\nTotal Iteration Time: 31.83210\n\nCumulative Model Updates: 22,715\nCumulative Timesteps: 113,722,986\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 114.29998\nPolicy Entropy: 5.38184\nValue Function Loss: 0.07011\n\nMean KL Divergence: 0.00065\nSB3 Clip Fraction: 0.02415\nPolicy Update Magnitude: 0.22331\nValue Function Update Magnitude: 0.10364\n\nCollected Steps per Second: 1,751.47434\nOverall Steps per Second: 1,249.67993\n\nTimestep Collection Time: 22.83904\nTimestep Consumption Time: 9.17075\nPPO Batch Consumption Time: 0.98837\nTotal Iteration Time: 32.00980\n\nCumulative Model Updates: 22,723\nCumulative Timesteps: 113,762,988\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 102.41285\nPolicy Entropy: 5.37254\nValue Function Loss: 0.06861\n\nMean KL Divergence: 0.00070\nSB3 Clip Fraction: 0.02571\nPolicy Update Magnitude: 0.21762\nValue Function Update Magnitude: 0.10333\n\nCollected Steps per Second: 1,738.90935\nOverall Steps per Second: 1,237.45807\n\nTimestep Collection Time: 23.00292\nTimestep Consumption Time: 9.32140\nPPO Batch Consumption Time: 1.00273\nTotal Iteration Time: 32.32433\n\nCumulative Model Updates: 22,731\nCumulative Timesteps: 113,802,988\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 75.86613\nPolicy Entropy: 5.36087\nValue Function Loss: 0.07411\n\nMean KL Divergence: 0.04095\nSB3 Clip Fraction: 0.03171\nPolicy Update Magnitude: 0.28663\nValue Function Update Magnitude: 0.10309\n\nCollected Steps per Second: 1,666.08738\nOverall Steps per Second: 1,215.30760\n\nTimestep Collection Time: 24.00955\nTimestep Consumption Time: 8.90558\nPPO Batch Consumption Time: 0.98342\nTotal Iteration Time: 32.91512\n\nCumulative Model Updates: 22,739\nCumulative Timesteps: 113,842,990\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 110.95687\nPolicy Entropy: 5.33862\nValue Function Loss: 0.07222\n\nMean KL Divergence: 0.10194\nSB3 Clip Fraction: 0.03118\nPolicy Update Magnitude: 0.25276\nValue Function Update Magnitude: 0.10261\n\nCollected Steps per Second: 1,707.22553\nOverall Steps per Second: 1,241.36059\n\nTimestep Collection Time: 23.43100\nTimestep Consumption Time: 8.79332\nPPO Batch Consumption Time: 0.97792\nTotal Iteration Time: 32.22432\n\nCumulative Model Updates: 22,747\nCumulative Timesteps: 113,882,992\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 113882992...\nCheckpoint 113882992 saved!\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 98.88642\nPolicy Entropy: 5.38981\nValue Function Loss: 0.06667\n\nMean KL Divergence: 0.00076\nSB3 Clip Fraction: 0.02925\nPolicy Update Magnitude: 0.23166\nValue Function Update Magnitude: 0.09825\n\nCollected Steps per Second: 1,734.96311\nOverall Steps per Second: 1,256.41512\n\nTimestep Collection Time: 23.05640\nTimestep Consumption Time: 8.78181\nPPO Batch Consumption Time: 0.97668\nTotal Iteration Time: 31.83820\n\nCumulative Model Updates: 22,755\nCumulative Timesteps: 113,922,994\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 110.94562\nPolicy Entropy: 5.38369\nValue Function Loss: 0.06654\n\nMean KL Divergence: 0.00071\nSB3 Clip Fraction: 0.02155\nPolicy Update Magnitude: 0.22122\nValue Function Update Magnitude: 0.09862\n\nCollected Steps per Second: 1,710.54710\nOverall Steps per Second: 1,242.72476\n\nTimestep Collection Time: 23.38433\nTimestep Consumption Time: 8.80301\nPPO Batch Consumption Time: 0.98492\nTotal Iteration Time: 32.18734\n\nCumulative Model Updates: 22,763\nCumulative Timesteps: 113,962,994\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 97.10931\nPolicy Entropy: 5.37843\nValue Function Loss: 0.06561\n\nMean KL Divergence: 0.00067\nSB3 Clip Fraction: 0.02432\nPolicy Update Magnitude: 0.20555\nValue Function Update Magnitude: 0.09435\n\nCollected Steps per Second: 1,696.77298\nOverall Steps per Second: 1,238.14048\n\nTimestep Collection Time: 23.57534\nTimestep Consumption Time: 8.73279\nPPO Batch Consumption Time: 0.97046\nTotal Iteration Time: 32.30813\n\nCumulative Model Updates: 22,771\nCumulative Timesteps: 114,002,996\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 103.73431\nPolicy Entropy: 5.39149\nValue Function Loss: 0.06604\n\nMean KL Divergence: 0.00069\nSB3 Clip Fraction: 0.02481\nPolicy Update Magnitude: 0.19382\nValue Function Update Magnitude: 0.09373\n\nCollected Steps per Second: 1,704.68997\nOverall Steps per Second: 1,241.53810\n\nTimestep Collection Time: 23.46468\nTimestep Consumption Time: 8.75342\nPPO Batch Consumption Time: 0.98418\nTotal Iteration Time: 32.21810\n\nCumulative Model Updates: 22,779\nCumulative Timesteps: 114,042,996\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 85.74811\nPolicy Entropy: 5.39228\nValue Function Loss: 0.07148\n\nMean KL Divergence: 0.00081\nSB3 Clip Fraction: 0.03244\nPolicy Update Magnitude: 0.20406\nValue Function Update Magnitude: 0.10283\n\nCollected Steps per Second: 1,711.54622\nOverall Steps per Second: 1,249.36517\n\nTimestep Collection Time: 23.37068\nTimestep Consumption Time: 8.64558\nPPO Batch Consumption Time: 0.96776\nTotal Iteration Time: 32.01626\n\nCumulative Model Updates: 22,787\nCumulative Timesteps: 114,082,996\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 87.86303\nPolicy Entropy: 5.38524\nValue Function Loss: 0.07261\n\nMean KL Divergence: 0.00097\nSB3 Clip Fraction: 0.03849\nPolicy Update Magnitude: 0.21798\nValue Function Update Magnitude: 0.10982\n\nCollected Steps per Second: 1,705.81354\nOverall Steps per Second: 1,208.35123\n\nTimestep Collection Time: 23.44922\nTimestep Consumption Time: 9.65374\nPPO Batch Consumption Time: 1.09195\nTotal Iteration Time: 33.10296\n\nCumulative Model Updates: 22,795\nCumulative Timesteps: 114,122,996\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 82.29099\nPolicy Entropy: 5.38274\nValue Function Loss: 0.06845\n\nMean KL Divergence: 0.00086\nSB3 Clip Fraction: 0.03359\nPolicy Update Magnitude: 0.22290\nValue Function Update Magnitude: 0.10824\n\nCollected Steps per Second: 1,689.03112\nOverall Steps per Second: 1,227.90886\n\nTimestep Collection Time: 23.68222\nTimestep Consumption Time: 8.89349\nPPO Batch Consumption Time: 0.98895\nTotal Iteration Time: 32.57571\n\nCumulative Model Updates: 22,803\nCumulative Timesteps: 114,162,996\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 115.05678\nPolicy Entropy: 5.39380\nValue Function Loss: 0.07240\n\nMean KL Divergence: 0.00069\nSB3 Clip Fraction: 0.02376\nPolicy Update Magnitude: 0.21434\nValue Function Update Magnitude: 0.10266\n\nCollected Steps per Second: 1,702.86290\nOverall Steps per Second: 1,238.94959\n\nTimestep Collection Time: 23.49103\nTimestep Consumption Time: 8.79600\nPPO Batch Consumption Time: 0.98212\nTotal Iteration Time: 32.28703\n\nCumulative Model Updates: 22,811\nCumulative Timesteps: 114,202,998\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 119.65247\nPolicy Entropy: 5.37258\nValue Function Loss: 0.07317\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.02724\nPolicy Update Magnitude: 0.20637\nValue Function Update Magnitude: 0.10092\n\nCollected Steps per Second: 1,683.48844\nOverall Steps per Second: 1,229.06313\n\nTimestep Collection Time: 23.76019\nTimestep Consumption Time: 8.78493\nPPO Batch Consumption Time: 0.98179\nTotal Iteration Time: 32.54511\n\nCumulative Model Updates: 22,819\nCumulative Timesteps: 114,242,998\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 94.66751\nPolicy Entropy: 5.35525\nValue Function Loss: 0.06944\n\nMean KL Divergence: 0.00073\nSB3 Clip Fraction: 0.02824\nPolicy Update Magnitude: 0.19812\nValue Function Update Magnitude: 0.10179\n\nCollected Steps per Second: 1,705.42647\nOverall Steps per Second: 1,230.06467\n\nTimestep Collection Time: 23.45572\nTimestep Consumption Time: 9.06452\nPPO Batch Consumption Time: 0.98216\nTotal Iteration Time: 32.52024\n\nCumulative Model Updates: 22,827\nCumulative Timesteps: 114,283,000\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 118.53032\nPolicy Entropy: 5.34274\nValue Function Loss: 0.06707\n\nMean KL Divergence: 0.00093\nSB3 Clip Fraction: 0.03771\nPolicy Update Magnitude: 0.19805\nValue Function Update Magnitude: 0.09671\n\nCollected Steps per Second: 1,714.98226\nOverall Steps per Second: 1,237.51964\n\nTimestep Collection Time: 23.32386\nTimestep Consumption Time: 8.99886\nPPO Batch Consumption Time: 0.96875\nTotal Iteration Time: 32.32272\n\nCumulative Model Updates: 22,835\nCumulative Timesteps: 114,323,000\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 109.65915\nPolicy Entropy: 5.37472\nValue Function Loss: 0.06864\n\nMean KL Divergence: 0.00105\nSB3 Clip Fraction: 0.04421\nPolicy Update Magnitude: 0.20099\nValue Function Update Magnitude: 0.09092\n\nCollected Steps per Second: 1,701.88683\nOverall Steps per Second: 1,229.17027\n\nTimestep Collection Time: 23.50333\nTimestep Consumption Time: 9.03895\nPPO Batch Consumption Time: 0.97321\nTotal Iteration Time: 32.54228\n\nCumulative Model Updates: 22,843\nCumulative Timesteps: 114,363,000\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 123.45668\nPolicy Entropy: 5.38076\nValue Function Loss: 0.07009\n\nMean KL Divergence: 0.00095\nSB3 Clip Fraction: 0.03785\nPolicy Update Magnitude: 0.20619\nValue Function Update Magnitude: 0.09514\n\nCollected Steps per Second: 1,724.87358\nOverall Steps per Second: 1,239.31683\n\nTimestep Collection Time: 23.19126\nTimestep Consumption Time: 9.08620\nPPO Batch Consumption Time: 0.97305\nTotal Iteration Time: 32.27746\n\nCumulative Model Updates: 22,851\nCumulative Timesteps: 114,403,002\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 114403002...\nCheckpoint 114403002 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 67.37621\nPolicy Entropy: 5.38262\nValue Function Loss: 0.06907\n\nMean KL Divergence: 0.00079\nSB3 Clip Fraction: 0.03083\nPolicy Update Magnitude: 0.20234\nValue Function Update Magnitude: 0.10014\n\nCollected Steps per Second: 1,702.46257\nOverall Steps per Second: 1,233.89813\n\nTimestep Collection Time: 23.49655\nTimestep Consumption Time: 8.92266\nPPO Batch Consumption Time: 0.96159\nTotal Iteration Time: 32.41921\n\nCumulative Model Updates: 22,859\nCumulative Timesteps: 114,443,004\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 99.54897\nPolicy Entropy: 5.36763\nValue Function Loss: 0.06864\n\nMean KL Divergence: 0.00080\nSB3 Clip Fraction: 0.03059\nPolicy Update Magnitude: 0.21012\nValue Function Update Magnitude: 0.10135\n\nCollected Steps per Second: 1,711.75579\nOverall Steps per Second: 1,247.41818\n\nTimestep Collection Time: 23.36782\nTimestep Consumption Time: 8.69841\nPPO Batch Consumption Time: 0.97550\nTotal Iteration Time: 32.06623\n\nCumulative Model Updates: 22,867\nCumulative Timesteps: 114,483,004\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 108.74933\nPolicy Entropy: 5.37616\nValue Function Loss: 0.06849\n\nMean KL Divergence: 0.00079\nSB3 Clip Fraction: 0.02915\nPolicy Update Magnitude: 0.20886\nValue Function Update Magnitude: 0.09756\n\nCollected Steps per Second: 1,696.68794\nOverall Steps per Second: 1,234.66702\n\nTimestep Collection Time: 23.57652\nTimestep Consumption Time: 8.82250\nPPO Batch Consumption Time: 0.97599\nTotal Iteration Time: 32.39902\n\nCumulative Model Updates: 22,875\nCumulative Timesteps: 114,523,006\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 86.28073\nPolicy Entropy: 5.37791\nValue Function Loss: 0.07119\n\nMean KL Divergence: 0.00090\nSB3 Clip Fraction: 0.03448\nPolicy Update Magnitude: 0.20604\nValue Function Update Magnitude: 0.09122\n\nCollected Steps per Second: 1,678.33921\nOverall Steps per Second: 1,229.65400\n\nTimestep Collection Time: 23.83428\nTimestep Consumption Time: 8.69683\nPPO Batch Consumption Time: 0.97151\nTotal Iteration Time: 32.53110\n\nCumulative Model Updates: 22,883\nCumulative Timesteps: 114,563,008\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 112.95925\nPolicy Entropy: 5.38386\nValue Function Loss: 0.07138\n\nMean KL Divergence: 0.00066\nSB3 Clip Fraction: 0.02290\nPolicy Update Magnitude: 0.20264\nValue Function Update Magnitude: 0.09571\n\nCollected Steps per Second: 1,744.64928\nOverall Steps per Second: 1,261.12094\n\nTimestep Collection Time: 22.92724\nTimestep Consumption Time: 8.79057\nPPO Batch Consumption Time: 0.97607\nTotal Iteration Time: 31.71781\n\nCumulative Model Updates: 22,891\nCumulative Timesteps: 114,603,008\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 121.70218\nPolicy Entropy: 5.38081\nValue Function Loss: 0.06996\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.02854\nPolicy Update Magnitude: 0.19523\nValue Function Update Magnitude: 0.09551\n\nCollected Steps per Second: 1,711.96276\nOverall Steps per Second: 1,242.84371\n\nTimestep Collection Time: 23.36616\nTimestep Consumption Time: 8.81970\nPPO Batch Consumption Time: 0.97837\nTotal Iteration Time: 32.18587\n\nCumulative Model Updates: 22,899\nCumulative Timesteps: 114,643,010\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 118.18371\nPolicy Entropy: 5.39847\nValue Function Loss: 0.07027\n\nMean KL Divergence: 0.00073\nSB3 Clip Fraction: 0.02726\nPolicy Update Magnitude: 0.19862\nValue Function Update Magnitude: 0.09881\n\nCollected Steps per Second: 1,738.98057\nOverall Steps per Second: 1,259.44997\n\nTimestep Collection Time: 23.00313\nTimestep Consumption Time: 8.75835\nPPO Batch Consumption Time: 0.97854\nTotal Iteration Time: 31.76148\n\nCumulative Model Updates: 22,907\nCumulative Timesteps: 114,683,012\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 97.93297\nPolicy Entropy: 5.40690\nValue Function Loss: 0.07352\n\nMean KL Divergence: 0.00066\nSB3 Clip Fraction: 0.02331\nPolicy Update Magnitude: 0.20239\nValue Function Update Magnitude: 0.09992\n\nCollected Steps per Second: 1,723.50310\nOverall Steps per Second: 1,248.11839\n\nTimestep Collection Time: 23.20855\nTimestep Consumption Time: 8.83970\nPPO Batch Consumption Time: 0.98045\nTotal Iteration Time: 32.04824\n\nCumulative Model Updates: 22,915\nCumulative Timesteps: 114,723,012\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 117.27682\nPolicy Entropy: 5.38566\nValue Function Loss: 0.07345\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02780\nPolicy Update Magnitude: 0.20549\nValue Function Update Magnitude: 0.09888\n\nCollected Steps per Second: 1,776.83712\nOverall Steps per Second: 1,290.36774\n\nTimestep Collection Time: 22.51304\nTimestep Consumption Time: 8.48743\nPPO Batch Consumption Time: 0.94795\nTotal Iteration Time: 31.00046\n\nCumulative Model Updates: 22,923\nCumulative Timesteps: 114,763,014\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 118.74754\nPolicy Entropy: 5.38675\nValue Function Loss: 0.06841\n\nMean KL Divergence: 0.00071\nSB3 Clip Fraction: 0.02580\nPolicy Update Magnitude: 0.20780\nValue Function Update Magnitude: 0.09996\n\nCollected Steps per Second: 1,759.52918\nOverall Steps per Second: 1,271.44543\n\nTimestep Collection Time: 22.73335\nTimestep Consumption Time: 8.72690\nPPO Batch Consumption Time: 0.96890\nTotal Iteration Time: 31.46026\n\nCumulative Model Updates: 22,931\nCumulative Timesteps: 114,803,014\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 105.07992\nPolicy Entropy: 5.39547\nValue Function Loss: 0.06822\n\nMean KL Divergence: 0.00076\nSB3 Clip Fraction: 0.02991\nPolicy Update Magnitude: 0.21272\nValue Function Update Magnitude: 0.10120\n\nCollected Steps per Second: 1,777.65632\nOverall Steps per Second: 1,280.78210\n\nTimestep Collection Time: 22.50154\nTimestep Consumption Time: 8.72938\nPPO Batch Consumption Time: 0.96756\nTotal Iteration Time: 31.23092\n\nCumulative Model Updates: 22,939\nCumulative Timesteps: 114,843,014\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 92.08376\nPolicy Entropy: 5.39925\nValue Function Loss: 0.06970\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.02925\nPolicy Update Magnitude: 0.20773\nValue Function Update Magnitude: 0.09659\n\nCollected Steps per Second: 1,730.90187\nOverall Steps per Second: 1,256.00599\n\nTimestep Collection Time: 23.10934\nTimestep Consumption Time: 8.73764\nPPO Batch Consumption Time: 0.97492\nTotal Iteration Time: 31.84698\n\nCumulative Model Updates: 22,947\nCumulative Timesteps: 114,883,014\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 99.37938\nPolicy Entropy: 5.38275\nValue Function Loss: 0.07030\n\nMean KL Divergence: 0.00071\nSB3 Clip Fraction: 0.02674\nPolicy Update Magnitude: 0.19709\nValue Function Update Magnitude: 0.09782\n\nCollected Steps per Second: 1,784.31447\nOverall Steps per Second: 1,279.97526\n\nTimestep Collection Time: 22.41869\nTimestep Consumption Time: 8.83347\nPPO Batch Consumption Time: 0.98049\nTotal Iteration Time: 31.25217\n\nCumulative Model Updates: 22,955\nCumulative Timesteps: 114,923,016\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 114923016...\nCheckpoint 114923016 saved!\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 107.82120\nPolicy Entropy: 5.38917\nValue Function Loss: 0.07110\n\nMean KL Divergence: 0.00081\nSB3 Clip Fraction: 0.02691\nPolicy Update Magnitude: 0.22544\nValue Function Update Magnitude: 0.10040\n\nCollected Steps per Second: 1,749.44652\nOverall Steps per Second: 1,267.24425\n\nTimestep Collection Time: 22.86437\nTimestep Consumption Time: 8.70018\nPPO Batch Consumption Time: 0.96651\nTotal Iteration Time: 31.56455\n\nCumulative Model Updates: 22,963\nCumulative Timesteps: 114,963,016\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 119.69215\nPolicy Entropy: 5.39408\nValue Function Loss: 0.07245\n\nMean KL Divergence: 0.00108\nSB3 Clip Fraction: 0.02914\nPolicy Update Magnitude: 0.23938\nValue Function Update Magnitude: 0.10518\n\nCollected Steps per Second: 1,784.83483\nOverall Steps per Second: 1,281.94408\n\nTimestep Collection Time: 22.41104\nTimestep Consumption Time: 8.79157\nPPO Batch Consumption Time: 0.96886\nTotal Iteration Time: 31.20261\n\nCumulative Model Updates: 22,971\nCumulative Timesteps: 115,003,016\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 97.96512\nPolicy Entropy: 5.41351\nValue Function Loss: 0.07440\n\nMean KL Divergence: 0.00076\nSB3 Clip Fraction: 0.02855\nPolicy Update Magnitude: 0.22826\nValue Function Update Magnitude: 0.10315\n\nCollected Steps per Second: 1,583.26365\nOverall Steps per Second: 1,171.81344\n\nTimestep Collection Time: 25.26553\nTimestep Consumption Time: 8.87130\nPPO Batch Consumption Time: 0.99066\nTotal Iteration Time: 34.13683\n\nCumulative Model Updates: 22,979\nCumulative Timesteps: 115,043,018\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 120.63699\nPolicy Entropy: 5.38900\nValue Function Loss: 0.07282\n\nMean KL Divergence: 0.00073\nSB3 Clip Fraction: 0.02706\nPolicy Update Magnitude: 0.21992\nValue Function Update Magnitude: 0.10222\n\nCollected Steps per Second: 1,764.34014\nOverall Steps per Second: 1,261.50791\n\nTimestep Collection Time: 22.67137\nTimestep Consumption Time: 9.03672\nPPO Batch Consumption Time: 0.97418\nTotal Iteration Time: 31.70808\n\nCumulative Model Updates: 22,987\nCumulative Timesteps: 115,083,018\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 111.22094\nPolicy Entropy: 5.37097\nValue Function Loss: 0.07103\n\nMean KL Divergence: 0.00081\nSB3 Clip Fraction: 0.03090\nPolicy Update Magnitude: 0.22503\nValue Function Update Magnitude: 0.10303\n\nCollected Steps per Second: 1,787.21398\nOverall Steps per Second: 1,277.28143\n\nTimestep Collection Time: 22.38232\nTimestep Consumption Time: 8.93576\nPPO Batch Consumption Time: 0.96248\nTotal Iteration Time: 31.31808\n\nCumulative Model Updates: 22,995\nCumulative Timesteps: 115,123,020\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 109.39278\nPolicy Entropy: 5.36525\nValue Function Loss: 0.06944\n\nMean KL Divergence: 0.00075\nSB3 Clip Fraction: 0.02624\nPolicy Update Magnitude: 0.21970\nValue Function Update Magnitude: 0.10379\n\nCollected Steps per Second: 1,781.88335\nOverall Steps per Second: 1,266.22008\n\nTimestep Collection Time: 22.44816\nTimestep Consumption Time: 9.14193\nPPO Batch Consumption Time: 0.98660\nTotal Iteration Time: 31.59009\n\nCumulative Model Updates: 23,003\nCumulative Timesteps: 115,163,020\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 116.00424\nPolicy Entropy: 5.38114\nValue Function Loss: 0.07009\n\nMean KL Divergence: 0.00079\nSB3 Clip Fraction: 0.03013\nPolicy Update Magnitude: 0.21081\nValue Function Update Magnitude: 0.10355\n\nCollected Steps per Second: 1,748.83526\nOverall Steps per Second: 1,250.78468\n\nTimestep Collection Time: 22.87351\nTimestep Consumption Time: 9.10801\nPPO Batch Consumption Time: 0.97828\nTotal Iteration Time: 31.98152\n\nCumulative Model Updates: 23,011\nCumulative Timesteps: 115,203,022\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 117.12707\nPolicy Entropy: 5.38943\nValue Function Loss: 0.07203\n\nMean KL Divergence: 0.00091\nSB3 Clip Fraction: 0.03643\nPolicy Update Magnitude: 0.22105\nValue Function Update Magnitude: 0.10438\n\nCollected Steps per Second: 1,727.16648\nOverall Steps per Second: 1,244.23277\n\nTimestep Collection Time: 23.16048\nTimestep Consumption Time: 8.98946\nPPO Batch Consumption Time: 0.96890\nTotal Iteration Time: 32.14993\n\nCumulative Model Updates: 23,019\nCumulative Timesteps: 115,243,024\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 105.47856\nPolicy Entropy: 5.39896\nValue Function Loss: 0.07167\n\nMean KL Divergence: 0.00095\nSB3 Clip Fraction: 0.03840\nPolicy Update Magnitude: 0.22528\nValue Function Update Magnitude: 0.10496\n\nCollected Steps per Second: 1,778.81763\nOverall Steps per Second: 1,267.22136\n\nTimestep Collection Time: 22.48797\nTimestep Consumption Time: 9.07873\nPPO Batch Consumption Time: 0.97230\nTotal Iteration Time: 31.56670\n\nCumulative Model Updates: 23,027\nCumulative Timesteps: 115,283,026\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 82.84165\nPolicy Entropy: 5.38179\nValue Function Loss: 0.07116\n\nMean KL Divergence: 0.00068\nSB3 Clip Fraction: 0.02420\nPolicy Update Magnitude: 0.22824\nValue Function Update Magnitude: 0.10219\n\nCollected Steps per Second: 1,744.13249\nOverall Steps per Second: 1,269.59227\n\nTimestep Collection Time: 22.93518\nTimestep Consumption Time: 8.57257\nPPO Batch Consumption Time: 0.96161\nTotal Iteration Time: 31.50775\n\nCumulative Model Updates: 23,035\nCumulative Timesteps: 115,323,028\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 85.83259\nPolicy Entropy: 5.35550\nValue Function Loss: 0.07102\n\nMean KL Divergence: 0.00079\nSB3 Clip Fraction: 0.03002\nPolicy Update Magnitude: 0.22542\nValue Function Update Magnitude: 0.10125\n\nCollected Steps per Second: 1,729.08475\nOverall Steps per Second: 1,255.90897\n\nTimestep Collection Time: 23.13478\nTimestep Consumption Time: 8.71625\nPPO Batch Consumption Time: 0.97206\nTotal Iteration Time: 31.85103\n\nCumulative Model Updates: 23,043\nCumulative Timesteps: 115,363,030\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 107.52174\nPolicy Entropy: 5.36215\nValue Function Loss: 0.07189\n\nMean KL Divergence: 0.00073\nSB3 Clip Fraction: 0.02903\nPolicy Update Magnitude: 0.21217\nValue Function Update Magnitude: 0.10734\n\nCollected Steps per Second: 1,761.52595\nOverall Steps per Second: 1,277.75725\n\nTimestep Collection Time: 22.70872\nTimestep Consumption Time: 8.59770\nPPO Batch Consumption Time: 0.96439\nTotal Iteration Time: 31.30642\n\nCumulative Model Updates: 23,051\nCumulative Timesteps: 115,403,032\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 82.58553\nPolicy Entropy: 5.38555\nValue Function Loss: 0.07116\n\nMean KL Divergence: 0.00080\nSB3 Clip Fraction: 0.02909\nPolicy Update Magnitude: 0.20867\nValue Function Update Magnitude: 0.10218\n\nCollected Steps per Second: 1,727.27052\nOverall Steps per Second: 1,262.80724\n\nTimestep Collection Time: 23.15792\nTimestep Consumption Time: 8.51754\nPPO Batch Consumption Time: 0.95269\nTotal Iteration Time: 31.67546\n\nCumulative Model Updates: 23,059\nCumulative Timesteps: 115,443,032\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 115443032...\nCheckpoint 115443032 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 124.45999\nPolicy Entropy: 5.37292\nValue Function Loss: 0.06947\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.02754\nPolicy Update Magnitude: 0.21322\nValue Function Update Magnitude: 0.09585\n\nCollected Steps per Second: 1,752.45352\nOverall Steps per Second: 1,269.82630\n\nTimestep Collection Time: 22.82514\nTimestep Consumption Time: 8.67523\nPPO Batch Consumption Time: 0.96560\nTotal Iteration Time: 31.50037\n\nCumulative Model Updates: 23,067\nCumulative Timesteps: 115,483,032\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 75.52177\nPolicy Entropy: 5.36663\nValue Function Loss: 0.07211\n\nMean KL Divergence: 0.00091\nSB3 Clip Fraction: 0.03468\nPolicy Update Magnitude: 0.24720\nValue Function Update Magnitude: 0.09716\n\nCollected Steps per Second: 1,753.19149\nOverall Steps per Second: 1,268.82687\n\nTimestep Collection Time: 22.81553\nTimestep Consumption Time: 8.70965\nPPO Batch Consumption Time: 0.96718\nTotal Iteration Time: 31.52518\n\nCumulative Model Updates: 23,075\nCumulative Timesteps: 115,523,032\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 102.59622\nPolicy Entropy: 5.36549\nValue Function Loss: 0.07483\n\nMean KL Divergence: 0.00122\nSB3 Clip Fraction: 0.03516\nPolicy Update Magnitude: 0.23577\nValue Function Update Magnitude: 0.10448\n\nCollected Steps per Second: 1,750.30291\nOverall Steps per Second: 1,268.63490\n\nTimestep Collection Time: 22.85319\nTimestep Consumption Time: 8.67677\nPPO Batch Consumption Time: 0.97026\nTotal Iteration Time: 31.52995\n\nCumulative Model Updates: 23,083\nCumulative Timesteps: 115,563,032\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 103.78099\nPolicy Entropy: 5.35936\nValue Function Loss: 0.07339\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02705\nPolicy Update Magnitude: 0.22405\nValue Function Update Magnitude: 0.11443\n\nCollected Steps per Second: 1,713.99711\nOverall Steps per Second: 1,247.57823\n\nTimestep Collection Time: 23.33726\nTimestep Consumption Time: 8.72486\nPPO Batch Consumption Time: 0.97262\nTotal Iteration Time: 32.06212\n\nCumulative Model Updates: 23,091\nCumulative Timesteps: 115,603,032\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 122.23676\nPolicy Entropy: 5.36510\nValue Function Loss: 0.07208\n\nMean KL Divergence: 0.00080\nSB3 Clip Fraction: 0.03136\nPolicy Update Magnitude: 0.21852\nValue Function Update Magnitude: 0.11002\n\nCollected Steps per Second: 1,742.93504\nOverall Steps per Second: 1,256.22424\n\nTimestep Collection Time: 22.95094\nTimestep Consumption Time: 8.89210\nPPO Batch Consumption Time: 0.99190\nTotal Iteration Time: 31.84304\n\nCumulative Model Updates: 23,099\nCumulative Timesteps: 115,643,034\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 115.68417\nPolicy Entropy: 5.40332\nValue Function Loss: 0.07112\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.02985\nPolicy Update Magnitude: 0.21797\nValue Function Update Magnitude: 0.10660\n\nCollected Steps per Second: 1,740.17588\nOverall Steps per Second: 1,261.20574\n\nTimestep Collection Time: 22.98618\nTimestep Consumption Time: 8.72950\nPPO Batch Consumption Time: 0.97665\nTotal Iteration Time: 31.71568\n\nCumulative Model Updates: 23,107\nCumulative Timesteps: 115,683,034\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 114.47145\nPolicy Entropy: 5.39779\nValue Function Loss: 0.06973\n\nMean KL Divergence: 0.00079\nSB3 Clip Fraction: 0.02999\nPolicy Update Magnitude: 0.21770\nValue Function Update Magnitude: 0.10908\n\nCollected Steps per Second: 1,706.17524\nOverall Steps per Second: 1,245.17436\n\nTimestep Collection Time: 23.44542\nTimestep Consumption Time: 8.68020\nPPO Batch Consumption Time: 0.96876\nTotal Iteration Time: 32.12562\n\nCumulative Model Updates: 23,115\nCumulative Timesteps: 115,723,036\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 112.62660\nPolicy Entropy: 5.38742\nValue Function Loss: 0.06993\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02592\nPolicy Update Magnitude: 0.22623\nValue Function Update Magnitude: 0.10581\n\nCollected Steps per Second: 1,737.25201\nOverall Steps per Second: 1,263.38782\n\nTimestep Collection Time: 23.02487\nTimestep Consumption Time: 8.63603\nPPO Batch Consumption Time: 0.96534\nTotal Iteration Time: 31.66090\n\nCumulative Model Updates: 23,123\nCumulative Timesteps: 115,763,036\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 82.65696\nPolicy Entropy: 5.37606\nValue Function Loss: 0.06921\n\nMean KL Divergence: 0.00078\nSB3 Clip Fraction: 0.02885\nPolicy Update Magnitude: 0.22060\nValue Function Update Magnitude: 0.10570\n\nCollected Steps per Second: 1,694.28209\nOverall Steps per Second: 1,236.90673\n\nTimestep Collection Time: 23.61000\nTimestep Consumption Time: 8.73035\nPPO Batch Consumption Time: 0.97371\nTotal Iteration Time: 32.34035\n\nCumulative Model Updates: 23,131\nCumulative Timesteps: 115,803,038\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 114.32308\nPolicy Entropy: 5.35421\nValue Function Loss: 0.06947\n\nMean KL Divergence: 0.00082\nSB3 Clip Fraction: 0.03128\nPolicy Update Magnitude: 0.20789\nValue Function Update Magnitude: 0.09541\n\nCollected Steps per Second: 1,748.88835\nOverall Steps per Second: 1,254.60161\n\nTimestep Collection Time: 22.87167\nTimestep Consumption Time: 9.01096\nPPO Batch Consumption Time: 0.97085\nTotal Iteration Time: 31.88263\n\nCumulative Model Updates: 23,139\nCumulative Timesteps: 115,843,038\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 95.05196\nPolicy Entropy: 5.33660\nValue Function Loss: 0.07201\n\nMean KL Divergence: 0.00083\nSB3 Clip Fraction: 0.03239\nPolicy Update Magnitude: 0.20226\nValue Function Update Magnitude: 0.09755\n\nCollected Steps per Second: 1,778.50784\nOverall Steps per Second: 1,262.11151\n\nTimestep Collection Time: 22.49189\nTimestep Consumption Time: 9.20262\nPPO Batch Consumption Time: 0.98994\nTotal Iteration Time: 31.69451\n\nCumulative Model Updates: 23,147\nCumulative Timesteps: 115,883,040\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 112.04596\nPolicy Entropy: 5.33889\nValue Function Loss: 0.06938\n\nMean KL Divergence: 0.00090\nSB3 Clip Fraction: 0.03616\nPolicy Update Magnitude: 0.20225\nValue Function Update Magnitude: 0.09811\n\nCollected Steps per Second: 1,807.82753\nOverall Steps per Second: 1,286.63910\n\nTimestep Collection Time: 22.12711\nTimestep Consumption Time: 8.96319\nPPO Batch Consumption Time: 0.97136\nTotal Iteration Time: 31.09030\n\nCumulative Model Updates: 23,155\nCumulative Timesteps: 115,923,042\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 74.88827\nPolicy Entropy: 5.33190\nValue Function Loss: 0.06389\n\nMean KL Divergence: 0.00071\nSB3 Clip Fraction: 0.02636\nPolicy Update Magnitude: 0.19826\nValue Function Update Magnitude: 0.09451\n\nCollected Steps per Second: 1,732.29227\nOverall Steps per Second: 1,240.90041\n\nTimestep Collection Time: 23.09079\nTimestep Consumption Time: 9.14387\nPPO Batch Consumption Time: 0.98031\nTotal Iteration Time: 32.23466\n\nCumulative Model Updates: 23,163\nCumulative Timesteps: 115,963,042\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 115963042...\nCheckpoint 115963042 saved!\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 103.74709\nPolicy Entropy: 5.35747\nValue Function Loss: 0.06636\n\nMean KL Divergence: 0.00076\nSB3 Clip Fraction: 0.02939\nPolicy Update Magnitude: 0.20270\nValue Function Update Magnitude: 0.09602\n\nCollected Steps per Second: 1,757.73660\nOverall Steps per Second: 1,261.89144\n\nTimestep Collection Time: 22.75654\nTimestep Consumption Time: 8.94191\nPPO Batch Consumption Time: 0.96161\nTotal Iteration Time: 31.69845\n\nCumulative Model Updates: 23,171\nCumulative Timesteps: 116,003,042\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 114.10072\nPolicy Entropy: 5.40259\nValue Function Loss: 0.06890\n\nMean KL Divergence: 0.00082\nSB3 Clip Fraction: 0.03308\nPolicy Update Magnitude: 0.20344\nValue Function Update Magnitude: 0.10216\n\nCollected Steps per Second: 1,764.74382\nOverall Steps per Second: 1,261.71298\n\nTimestep Collection Time: 22.66731\nTimestep Consumption Time: 9.03720\nPPO Batch Consumption Time: 0.96900\nTotal Iteration Time: 31.70452\n\nCumulative Model Updates: 23,179\nCumulative Timesteps: 116,043,044\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 99.60248\nPolicy Entropy: 5.42352\nValue Function Loss: 0.07169\n\nMean KL Divergence: 0.00082\nSB3 Clip Fraction: 0.03154\nPolicy Update Magnitude: 0.21559\nValue Function Update Magnitude: 0.11114\n\nCollected Steps per Second: 1,757.99681\nOverall Steps per Second: 1,255.22605\n\nTimestep Collection Time: 22.75431\nTimestep Consumption Time: 9.11406\nPPO Batch Consumption Time: 0.98321\nTotal Iteration Time: 31.86836\n\nCumulative Model Updates: 23,187\nCumulative Timesteps: 116,083,046\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 86.12895\nPolicy Entropy: 5.40301\nValue Function Loss: 0.07438\n\nMean KL Divergence: 0.00079\nSB3 Clip Fraction: 0.03023\nPolicy Update Magnitude: 0.21298\nValue Function Update Magnitude: 0.10878\n\nCollected Steps per Second: 1,732.19246\nOverall Steps per Second: 1,243.40648\n\nTimestep Collection Time: 23.09212\nTimestep Consumption Time: 9.07757\nPPO Batch Consumption Time: 0.98034\nTotal Iteration Time: 32.16969\n\nCumulative Model Updates: 23,195\nCumulative Timesteps: 116,123,046\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 65.61905\nPolicy Entropy: 5.40045\nValue Function Loss: 0.07226\n\nMean KL Divergence: 0.00087\nSB3 Clip Fraction: 0.03391\nPolicy Update Magnitude: 0.21022\nValue Function Update Magnitude: 0.11039\n\nCollected Steps per Second: 1,683.74688\nOverall Steps per Second: 1,221.19396\n\nTimestep Collection Time: 23.75654\nTimestep Consumption Time: 8.99829\nPPO Batch Consumption Time: 0.96902\nTotal Iteration Time: 32.75483\n\nCumulative Model Updates: 23,203\nCumulative Timesteps: 116,163,046\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 94.43624\nPolicy Entropy: 5.37288\nValue Function Loss: 0.07145\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.02969\nPolicy Update Magnitude: 0.21332\nValue Function Update Magnitude: 0.10225\n\nCollected Steps per Second: 1,721.50025\nOverall Steps per Second: 1,244.38733\n\nTimestep Collection Time: 23.23671\nTimestep Consumption Time: 8.90923\nPPO Batch Consumption Time: 0.99112\nTotal Iteration Time: 32.14594\n\nCumulative Model Updates: 23,211\nCumulative Timesteps: 116,203,048\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 108.70886\nPolicy Entropy: 5.35248\nValue Function Loss: 0.07155\n\nMean KL Divergence: 0.00089\nSB3 Clip Fraction: 0.03595\nPolicy Update Magnitude: 0.20586\nValue Function Update Magnitude: 0.09819\n\nCollected Steps per Second: 1,694.56385\nOverall Steps per Second: 1,234.27920\n\nTimestep Collection Time: 23.60489\nTimestep Consumption Time: 8.80268\nPPO Batch Consumption Time: 0.97911\nTotal Iteration Time: 32.40758\n\nCumulative Model Updates: 23,219\nCumulative Timesteps: 116,243,048\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 98.00798\nPolicy Entropy: 5.36953\nValue Function Loss: 0.07007\n\nMean KL Divergence: 0.00087\nSB3 Clip Fraction: 0.02869\nPolicy Update Magnitude: 0.20539\nValue Function Update Magnitude: 0.09465\n\nCollected Steps per Second: 1,742.66836\nOverall Steps per Second: 1,259.13616\n\nTimestep Collection Time: 22.95331\nTimestep Consumption Time: 8.81451\nPPO Batch Consumption Time: 0.97746\nTotal Iteration Time: 31.76781\n\nCumulative Model Updates: 23,227\nCumulative Timesteps: 116,283,048\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 97.88549\nPolicy Entropy: 5.37440\nValue Function Loss: 0.06770\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.02936\nPolicy Update Magnitude: 0.20145\nValue Function Update Magnitude: 0.09630\n\nCollected Steps per Second: 1,713.45154\nOverall Steps per Second: 1,250.29402\n\nTimestep Collection Time: 23.34586\nTimestep Consumption Time: 8.64821\nPPO Batch Consumption Time: 0.96416\nTotal Iteration Time: 31.99407\n\nCumulative Model Updates: 23,235\nCumulative Timesteps: 116,323,050\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 73.07326\nPolicy Entropy: 5.37878\nValue Function Loss: 0.07124\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02748\nPolicy Update Magnitude: 0.20413\nValue Function Update Magnitude: 0.09641\n\nCollected Steps per Second: 1,711.16352\nOverall Steps per Second: 1,244.71688\n\nTimestep Collection Time: 23.37591\nTimestep Consumption Time: 8.75991\nPPO Batch Consumption Time: 0.97967\nTotal Iteration Time: 32.13582\n\nCumulative Model Updates: 23,243\nCumulative Timesteps: 116,363,050\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 95.27267\nPolicy Entropy: 5.35451\nValue Function Loss: 0.07211\n\nMean KL Divergence: 0.00068\nSB3 Clip Fraction: 0.02429\nPolicy Update Magnitude: 0.21005\nValue Function Update Magnitude: 0.10107\n\nCollected Steps per Second: 1,724.31940\nOverall Steps per Second: 1,250.14922\n\nTimestep Collection Time: 23.19872\nTimestep Consumption Time: 8.79906\nPPO Batch Consumption Time: 0.98131\nTotal Iteration Time: 31.99778\n\nCumulative Model Updates: 23,251\nCumulative Timesteps: 116,403,052\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 116.78627\nPolicy Entropy: 5.36367\nValue Function Loss: 0.06956\n\nMean KL Divergence: 0.00076\nSB3 Clip Fraction: 0.02784\nPolicy Update Magnitude: 0.21141\nValue Function Update Magnitude: 0.10346\n\nCollected Steps per Second: 1,732.43793\nOverall Steps per Second: 1,254.99425\n\nTimestep Collection Time: 23.08885\nTimestep Consumption Time: 8.78381\nPPO Batch Consumption Time: 0.98352\nTotal Iteration Time: 31.87266\n\nCumulative Model Updates: 23,259\nCumulative Timesteps: 116,443,052\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 107.94148\nPolicy Entropy: 5.36794\nValue Function Loss: 0.06843\n\nMean KL Divergence: 0.00070\nSB3 Clip Fraction: 0.02621\nPolicy Update Magnitude: 0.22211\nValue Function Update Magnitude: 0.09841\n\nCollected Steps per Second: 1,719.05600\nOverall Steps per Second: 1,247.47348\n\nTimestep Collection Time: 23.26975\nTimestep Consumption Time: 8.79667\nPPO Batch Consumption Time: 0.97619\nTotal Iteration Time: 32.06641\n\nCumulative Model Updates: 23,267\nCumulative Timesteps: 116,483,054\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 116483054...\nCheckpoint 116483054 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 80.22547\nPolicy Entropy: 5.33902\nValue Function Loss: 0.06890\n\nMean KL Divergence: 0.00082\nSB3 Clip Fraction: 0.03050\nPolicy Update Magnitude: 0.22254\nValue Function Update Magnitude: 0.09588\n\nCollected Steps per Second: 1,694.01205\nOverall Steps per Second: 1,232.00873\n\nTimestep Collection Time: 23.61258\nTimestep Consumption Time: 8.85472\nPPO Batch Consumption Time: 0.98573\nTotal Iteration Time: 32.46730\n\nCumulative Model Updates: 23,275\nCumulative Timesteps: 116,523,054\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 118.25061\nPolicy Entropy: 5.39060\nValue Function Loss: 0.06980\n\nMean KL Divergence: 0.00073\nSB3 Clip Fraction: 0.02831\nPolicy Update Magnitude: 0.22345\nValue Function Update Magnitude: 0.09502\n\nCollected Steps per Second: 1,714.53255\nOverall Steps per Second: 1,249.03212\n\nTimestep Collection Time: 23.33114\nTimestep Consumption Time: 8.69526\nPPO Batch Consumption Time: 0.96605\nTotal Iteration Time: 32.02640\n\nCumulative Model Updates: 23,283\nCumulative Timesteps: 116,563,056\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 97.02193\nPolicy Entropy: 5.40033\nValue Function Loss: 0.06989\n\nMean KL Divergence: 0.00076\nSB3 Clip Fraction: 0.02545\nPolicy Update Magnitude: 0.22399\nValue Function Update Magnitude: 0.11047\n\nCollected Steps per Second: 1,713.73395\nOverall Steps per Second: 1,249.82027\n\nTimestep Collection Time: 23.34201\nTimestep Consumption Time: 8.66419\nPPO Batch Consumption Time: 0.96601\nTotal Iteration Time: 32.00620\n\nCumulative Model Updates: 23,291\nCumulative Timesteps: 116,603,058\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 92.09270\nPolicy Entropy: 5.36505\nValue Function Loss: 0.07405\n\nMean KL Divergence: 0.00075\nSB3 Clip Fraction: 0.02809\nPolicy Update Magnitude: 0.21693\nValue Function Update Magnitude: 0.10039\n\nCollected Steps per Second: 1,663.40885\nOverall Steps per Second: 1,225.99404\n\nTimestep Collection Time: 24.04821\nTimestep Consumption Time: 8.58001\nPPO Batch Consumption Time: 0.95121\nTotal Iteration Time: 32.62822\n\nCumulative Model Updates: 23,299\nCumulative Timesteps: 116,643,060\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 95.47094\nPolicy Entropy: 5.37452\nValue Function Loss: 0.07321\n\nMean KL Divergence: 0.00078\nSB3 Clip Fraction: 0.02874\nPolicy Update Magnitude: 0.22195\nValue Function Update Magnitude: 0.10276\n\nCollected Steps per Second: 1,691.40562\nOverall Steps per Second: 1,231.06622\n\nTimestep Collection Time: 23.65015\nTimestep Consumption Time: 8.84363\nPPO Batch Consumption Time: 0.95821\nTotal Iteration Time: 32.49378\n\nCumulative Model Updates: 23,307\nCumulative Timesteps: 116,683,062\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 84.75598\nPolicy Entropy: 5.36974\nValue Function Loss: 0.06900\n\nMean KL Divergence: 0.00068\nSB3 Clip Fraction: 0.02614\nPolicy Update Magnitude: 0.21092\nValue Function Update Magnitude: 0.09569\n\nCollected Steps per Second: 1,763.92652\nOverall Steps per Second: 1,264.39614\n\nTimestep Collection Time: 22.67782\nTimestep Consumption Time: 8.95942\nPPO Batch Consumption Time: 0.96748\nTotal Iteration Time: 31.63724\n\nCumulative Model Updates: 23,315\nCumulative Timesteps: 116,723,064\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 86.35430\nPolicy Entropy: 5.37366\nValue Function Loss: 0.07029\n\nMean KL Divergence: 0.00080\nSB3 Clip Fraction: 0.03150\nPolicy Update Magnitude: 0.20753\nValue Function Update Magnitude: 0.09520\n\nCollected Steps per Second: 1,714.89331\nOverall Steps per Second: 1,238.64784\n\nTimestep Collection Time: 23.32507\nTimestep Consumption Time: 8.96821\nPPO Batch Consumption Time: 0.97403\nTotal Iteration Time: 32.29328\n\nCumulative Model Updates: 23,323\nCumulative Timesteps: 116,763,064\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 73.50177\nPolicy Entropy: 5.39854\nValue Function Loss: 0.07164\n\nMean KL Divergence: 0.00072\nSB3 Clip Fraction: 0.02655\nPolicy Update Magnitude: 0.21567\nValue Function Update Magnitude: 0.09387\n\nCollected Steps per Second: 1,741.20596\nOverall Steps per Second: 1,246.55378\n\nTimestep Collection Time: 22.97258\nTimestep Consumption Time: 9.11588\nPPO Batch Consumption Time: 0.98010\nTotal Iteration Time: 32.08847\n\nCumulative Model Updates: 23,331\nCumulative Timesteps: 116,803,064\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 62.99801\nPolicy Entropy: 5.39595\nValue Function Loss: 0.06988\n\nMean KL Divergence: 0.00064\nSB3 Clip Fraction: 0.02322\nPolicy Update Magnitude: 0.21891\nValue Function Update Magnitude: 0.10093\n\nCollected Steps per Second: 1,615.11898\nOverall Steps per Second: 1,180.89931\n\nTimestep Collection Time: 24.76598\nTimestep Consumption Time: 9.10651\nPPO Batch Consumption Time: 0.97162\nTotal Iteration Time: 33.87249\n\nCumulative Model Updates: 23,339\nCumulative Timesteps: 116,843,064\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 99.21293\nPolicy Entropy: 5.39590\nValue Function Loss: 0.07122\n\nMean KL Divergence: 0.00075\nSB3 Clip Fraction: 0.02986\nPolicy Update Magnitude: 0.22164\nValue Function Update Magnitude: 0.10352\n\nCollected Steps per Second: 1,754.02856\nOverall Steps per Second: 1,253.71248\n\nTimestep Collection Time: 22.80579\nTimestep Consumption Time: 9.10105\nPPO Batch Consumption Time: 0.98110\nTotal Iteration Time: 31.90684\n\nCumulative Model Updates: 23,347\nCumulative Timesteps: 116,883,066\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 104.12752\nPolicy Entropy: 5.39467\nValue Function Loss: 0.07280\n\nMean KL Divergence: 0.00075\nSB3 Clip Fraction: 0.02862\nPolicy Update Magnitude: 0.21798\nValue Function Update Magnitude: 0.10570\n\nCollected Steps per Second: 1,717.63771\nOverall Steps per Second: 1,247.23073\n\nTimestep Collection Time: 23.28780\nTimestep Consumption Time: 8.78325\nPPO Batch Consumption Time: 0.97418\nTotal Iteration Time: 32.07105\n\nCumulative Model Updates: 23,355\nCumulative Timesteps: 116,923,066\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 82.62953\nPolicy Entropy: 5.38238\nValue Function Loss: 0.07050\n\nMean KL Divergence: 0.00081\nSB3 Clip Fraction: 0.02979\nPolicy Update Magnitude: 0.21246\nValue Function Update Magnitude: 0.10490\n\nCollected Steps per Second: 1,692.26628\nOverall Steps per Second: 1,226.78091\n\nTimestep Collection Time: 23.63694\nTimestep Consumption Time: 8.96872\nPPO Batch Consumption Time: 0.99934\nTotal Iteration Time: 32.60566\n\nCumulative Model Updates: 23,363\nCumulative Timesteps: 116,963,066\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 78.31032\nPolicy Entropy: 5.39548\nValue Function Loss: 0.06876\n\nMean KL Divergence: 0.00082\nSB3 Clip Fraction: 0.03139\nPolicy Update Magnitude: 0.21626\nValue Function Update Magnitude: 0.09886\n\nCollected Steps per Second: 1,718.33428\nOverall Steps per Second: 1,252.20965\n\nTimestep Collection Time: 23.27836\nTimestep Consumption Time: 8.66518\nPPO Batch Consumption Time: 0.95981\nTotal Iteration Time: 31.94353\n\nCumulative Model Updates: 23,371\nCumulative Timesteps: 117,003,066\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 117003066...\nCheckpoint 117003066 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 101.18334\nPolicy Entropy: 5.36147\nValue Function Loss: 0.07071\n\nMean KL Divergence: 0.00101\nSB3 Clip Fraction: 0.03711\nPolicy Update Magnitude: 0.20654\nValue Function Update Magnitude: 0.09981\n\nCollected Steps per Second: 1,767.97894\nOverall Steps per Second: 1,274.63933\n\nTimestep Collection Time: 22.62470\nTimestep Consumption Time: 8.75672\nPPO Batch Consumption Time: 0.97893\nTotal Iteration Time: 31.38143\n\nCumulative Model Updates: 23,379\nCumulative Timesteps: 117,043,066\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 116.70125\nPolicy Entropy: 5.36133\nValue Function Loss: 0.07361\n\nMean KL Divergence: 0.00083\nSB3 Clip Fraction: 0.03142\nPolicy Update Magnitude: 0.20626\nValue Function Update Magnitude: 0.09984\n\nCollected Steps per Second: 1,775.66568\nOverall Steps per Second: 1,280.63332\n\nTimestep Collection Time: 22.52676\nTimestep Consumption Time: 8.70778\nPPO Batch Consumption Time: 0.97154\nTotal Iteration Time: 31.23455\n\nCumulative Model Updates: 23,387\nCumulative Timesteps: 117,083,066\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 98.04997\nPolicy Entropy: 5.37186\nValue Function Loss: 0.07502\n\nMean KL Divergence: 0.00074\nSB3 Clip Fraction: 0.02685\nPolicy Update Magnitude: 0.21955\nValue Function Update Magnitude: 0.09855\n\nCollected Steps per Second: 1,754.27191\nOverall Steps per Second: 1,270.72319\n\nTimestep Collection Time: 22.80148\nTimestep Consumption Time: 8.67666\nPPO Batch Consumption Time: 0.97280\nTotal Iteration Time: 31.47814\n\nCumulative Model Updates: 23,395\nCumulative Timesteps: 117,123,066\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 78.92099\nPolicy Entropy: 5.37560\nValue Function Loss: 0.07359\n\nMean KL Divergence: 0.00084\nSB3 Clip Fraction: 0.02933\nPolicy Update Magnitude: 0.21668\nValue Function Update Magnitude: 0.09882\n\nCollected Steps per Second: 1,784.44751\nOverall Steps per Second: 1,285.44222\n\nTimestep Collection Time: 22.41702\nTimestep Consumption Time: 8.70223\nPPO Batch Consumption Time: 0.97373\nTotal Iteration Time: 31.11925\n\nCumulative Model Updates: 23,403\nCumulative Timesteps: 117,163,068\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 121.61882\nPolicy Entropy: 5.37173\nValue Function Loss: 0.06954\n\nMean KL Divergence: 0.00088\nSB3 Clip Fraction: 0.03486\nPolicy Update Magnitude: 0.20713\nValue Function Update Magnitude: 0.10110\n\nCollected Steps per Second: 1,800.83118\nOverall Steps per Second: 1,292.82716\n\nTimestep Collection Time: 22.21197\nTimestep Consumption Time: 8.72798\nPPO Batch Consumption Time: 0.96626\nTotal Iteration Time: 30.93994\n\nCumulative Model Updates: 23,411\nCumulative Timesteps: 117,203,068\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 100.77451\nPolicy Entropy: 5.38682\nValue Function Loss: 0.07279\n\nMean KL Divergence: 0.00075\nSB3 Clip Fraction: 0.02753\nPolicy Update Magnitude: 0.20354\nValue Function Update Magnitude: 0.10231\n\nCollected Steps per Second: 1,785.36343\nOverall Steps per Second: 1,289.38443\n\nTimestep Collection Time: 22.40552\nTimestep Consumption Time: 8.61858\nPPO Batch Consumption Time: 0.96363\nTotal Iteration Time: 31.02411\n\nCumulative Model Updates: 23,419\nCumulative Timesteps: 117,243,070\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 92.81868\nPolicy Entropy: 5.36736\nValue Function Loss: 0.07378\n\nMean KL Divergence: 0.00085\nSB3 Clip Fraction: 0.03382\nPolicy Update Magnitude: 0.20918\nValue Function Update Magnitude: 0.10574\n\nCollected Steps per Second: 1,765.12231\nOverall Steps per Second: 1,273.76140\n\nTimestep Collection Time: 22.66245\nTimestep Consumption Time: 8.74217\nPPO Batch Consumption Time: 0.97477\nTotal Iteration Time: 31.40463\n\nCumulative Model Updates: 23,427\nCumulative Timesteps: 117,283,072\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 53.51815\nPolicy Entropy: 5.37509\nValue Function Loss: 0.06972\n\nMean KL Divergence: 0.00075\nSB3 Clip Fraction: 0.02747\nPolicy Update Magnitude: 0.20726\nValue Function Update Magnitude: 0.10247\n\nCollected Steps per Second: 1,789.84258\nOverall Steps per Second: 1,285.39601\n\nTimestep Collection Time: 22.34945\nTimestep Consumption Time: 8.77092\nPPO Batch Consumption Time: 0.97938\nTotal Iteration Time: 31.12037\n\nCumulative Model Updates: 23,435\nCumulative Timesteps: 117,323,074\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 126.95218\nPolicy Entropy: 5.38796\nValue Function Loss: 0.06689\n\nMean KL Divergence: 0.00068\nSB3 Clip Fraction: 0.02495\nPolicy Update Magnitude: 0.20484\nValue Function Update Magnitude: 0.10201\n\nCollected Steps per Second: 1,806.94779\nOverall Steps per Second: 1,301.78328\n\nTimestep Collection Time: 22.13788\nTimestep Consumption Time: 8.59073\nPPO Batch Consumption Time: 0.95838\nTotal Iteration Time: 30.72862\n\nCumulative Model Updates: 23,443\nCumulative Timesteps: 117,363,076\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 108.69107\nPolicy Entropy: 5.37615\nValue Function Loss: 0.06787\n\nMean KL Divergence: 0.00073\nSB3 Clip Fraction: 0.02777\nPolicy Update Magnitude: 0.20697\nValue Function Update Magnitude: 0.09362\n\nCollected Steps per Second: 1,803.57769\nOverall Steps per Second: 1,293.26775\n\nTimestep Collection Time: 22.17814\nTimestep Consumption Time: 8.75126\nPPO Batch Consumption Time: 0.97971\nTotal Iteration Time: 30.92940\n\nCumulative Model Updates: 23,451\nCumulative Timesteps: 117,403,076\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 128.53917\nPolicy Entropy: 5.37646\nValue Function Loss: 0.06712\n\nMean KL Divergence: 0.00071\nSB3 Clip Fraction: 0.02491\nPolicy Update Magnitude: 0.19845\nValue Function Update Magnitude: 0.09737\n\nCollected Steps per Second: 1,777.34031\nOverall Steps per Second: 1,277.71555\n\nTimestep Collection Time: 22.50666\nTimestep Consumption Time: 8.80077\nPPO Batch Consumption Time: 0.97490\nTotal Iteration Time: 31.30744\n\nCumulative Model Updates: 23,459\nCumulative Timesteps: 117,443,078\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 106.81530\nPolicy Entropy: 5.36011\nValue Function Loss: 0.07061\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.02975\nPolicy Update Magnitude: 0.19353\nValue Function Update Magnitude: 0.09247\n\nCollected Steps per Second: 1,772.84271\nOverall Steps per Second: 1,269.70211\n\nTimestep Collection Time: 22.56263\nTimestep Consumption Time: 8.94082\nPPO Batch Consumption Time: 0.96999\nTotal Iteration Time: 31.50345\n\nCumulative Model Updates: 23,467\nCumulative Timesteps: 117,483,078\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 75.75232\nPolicy Entropy: 5.36128\nValue Function Loss: 0.07166\n\nMean KL Divergence: 0.00066\nSB3 Clip Fraction: 0.02351\nPolicy Update Magnitude: 0.20048\nValue Function Update Magnitude: 0.09375\n\nCollected Steps per Second: 1,744.37447\nOverall Steps per Second: 1,253.93422\n\nTimestep Collection Time: 22.93086\nTimestep Consumption Time: 8.96874\nPPO Batch Consumption Time: 0.96721\nTotal Iteration Time: 31.89960\n\nCumulative Model Updates: 23,475\nCumulative Timesteps: 117,523,078\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 117523078...\nCheckpoint 117523078 saved!\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 108.33605\nPolicy Entropy: 5.35974\nValue Function Loss: 0.06856\n\nMean KL Divergence: 0.00075\nSB3 Clip Fraction: 0.02791\nPolicy Update Magnitude: 0.19857\nValue Function Update Magnitude: 0.09145\n\nCollected Steps per Second: 1,765.18949\nOverall Steps per Second: 1,256.94498\n\nTimestep Collection Time: 22.66046\nTimestep Consumption Time: 9.16273\nPPO Batch Consumption Time: 0.98458\nTotal Iteration Time: 31.82319\n\nCumulative Model Updates: 23,483\nCumulative Timesteps: 117,563,078\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 111.85748\nPolicy Entropy: 5.36093\nValue Function Loss: 0.06851\n\nMean KL Divergence: 0.00093\nSB3 Clip Fraction: 0.03764\nPolicy Update Magnitude: 0.19306\nValue Function Update Magnitude: 0.09115\n\nCollected Steps per Second: 1,722.58254\nOverall Steps per Second: 1,237.41952\n\nTimestep Collection Time: 23.22095\nTimestep Consumption Time: 9.10439\nPPO Batch Consumption Time: 0.98122\nTotal Iteration Time: 32.32533\n\nCumulative Model Updates: 23,491\nCumulative Timesteps: 117,603,078\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 117.78402\nPolicy Entropy: 5.36186\nValue Function Loss: 0.07045\n\nMean KL Divergence: 0.00070\nSB3 Clip Fraction: 0.02642\nPolicy Update Magnitude: 0.20002\nValue Function Update Magnitude: 0.09021\n\nCollected Steps per Second: 1,727.35639\nOverall Steps per Second: 1,239.40232\n\nTimestep Collection Time: 23.15677\nTimestep Consumption Time: 9.11685\nPPO Batch Consumption Time: 0.98259\nTotal Iteration Time: 32.27362\n\nCumulative Model Updates: 23,499\nCumulative Timesteps: 117,643,078\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 112.90586\nPolicy Entropy: 5.35665\nValue Function Loss: 0.07120\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.02759\nPolicy Update Magnitude: 0.20131\nValue Function Update Magnitude: 0.09229\n\nCollected Steps per Second: 1,769.30490\nOverall Steps per Second: 1,257.65300\n\nTimestep Collection Time: 22.60888\nTimestep Consumption Time: 9.19799\nPPO Batch Consumption Time: 0.99032\nTotal Iteration Time: 31.80687\n\nCumulative Model Updates: 23,507\nCumulative Timesteps: 117,683,080\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 107.34361\nPolicy Entropy: 5.35168\nValue Function Loss: 0.06665\n\nMean KL Divergence: 0.00079\nSB3 Clip Fraction: 0.03009\nPolicy Update Magnitude: 0.19747\nValue Function Update Magnitude: 0.08099\n\nCollected Steps per Second: 1,784.21492\nOverall Steps per Second: 1,271.55037\n\nTimestep Collection Time: 22.41882\nTimestep Consumption Time: 9.03884\nPPO Batch Consumption Time: 0.97874\nTotal Iteration Time: 31.45766\n\nCumulative Model Updates: 23,515\nCumulative Timesteps: 117,723,080\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 102.01093\nPolicy Entropy: 5.36148\nValue Function Loss: 0.06592\n\nMean KL Divergence: 0.00070\nSB3 Clip Fraction: 0.02530\nPolicy Update Magnitude: 0.18884\nValue Function Update Magnitude: 0.08083\n\nCollected Steps per Second: 1,708.32368\nOverall Steps per Second: 1,230.96179\n\nTimestep Collection Time: 23.41477\nTimestep Consumption Time: 9.08015\nPPO Batch Consumption Time: 0.98442\nTotal Iteration Time: 32.49492\n\nCumulative Model Updates: 23,523\nCumulative Timesteps: 117,763,080\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 92.27878\nPolicy Entropy: 5.36271\nValue Function Loss: 0.06866\n\nMean KL Divergence: 0.00069\nSB3 Clip Fraction: 0.02535\nPolicy Update Magnitude: 0.19145\nValue Function Update Magnitude: 0.09446\n\nCollected Steps per Second: 1,731.51448\nOverall Steps per Second: 1,252.76230\n\nTimestep Collection Time: 23.10232\nTimestep Consumption Time: 8.82872\nPPO Batch Consumption Time: 0.94738\nTotal Iteration Time: 31.93104\n\nCumulative Model Updates: 23,531\nCumulative Timesteps: 117,803,082\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 90.72607\nPolicy Entropy: 5.36147\nValue Function Loss: 0.06990\n\nMean KL Divergence: 0.00073\nSB3 Clip Fraction: 0.02806\nPolicy Update Magnitude: 0.19848\nValue Function Update Magnitude: 0.09679\n\nCollected Steps per Second: 1,770.90818\nOverall Steps per Second: 1,263.60571\n\nTimestep Collection Time: 22.58841\nTimestep Consumption Time: 9.06862\nPPO Batch Consumption Time: 0.97785\nTotal Iteration Time: 31.65703\n\nCumulative Model Updates: 23,539\nCumulative Timesteps: 117,843,084\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 78.25534\nPolicy Entropy: 5.36289\nValue Function Loss: 0.06934\n\nMean KL Divergence: 0.00081\nSB3 Clip Fraction: 0.03086\nPolicy Update Magnitude: 0.20174\nValue Function Update Magnitude: 0.09286\n\nCollected Steps per Second: 1,781.69058\nOverall Steps per Second: 1,270.56053\n\nTimestep Collection Time: 22.45059\nTimestep Consumption Time: 9.03158\nPPO Batch Consumption Time: 0.96841\nTotal Iteration Time: 31.48217\n\nCumulative Model Updates: 23,547\nCumulative Timesteps: 117,883,084\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 90.63689\nPolicy Entropy: 5.36778\nValue Function Loss: 0.06764\n\nMean KL Divergence: 0.00089\nSB3 Clip Fraction: 0.03511\nPolicy Update Magnitude: 0.20252\nValue Function Update Magnitude: 0.10158\n\nCollected Steps per Second: 1,766.44350\nOverall Steps per Second: 1,262.84821\n\nTimestep Collection Time: 22.64437\nTimestep Consumption Time: 9.03006\nPPO Batch Consumption Time: 0.97463\nTotal Iteration Time: 31.67443\n\nCumulative Model Updates: 23,555\nCumulative Timesteps: 117,923,084\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 102.03158\nPolicy Entropy: 5.36250\nValue Function Loss: 0.07107\n\nMean KL Divergence: 0.00067\nSB3 Clip Fraction: 0.02378\nPolicy Update Magnitude: 0.20719\nValue Function Update Magnitude: 0.09927\n\nCollected Steps per Second: 1,789.53866\nOverall Steps per Second: 1,272.50011\n\nTimestep Collection Time: 22.35213\nTimestep Consumption Time: 9.08205\nPPO Batch Consumption Time: 0.97471\nTotal Iteration Time: 31.43418\n\nCumulative Model Updates: 23,563\nCumulative Timesteps: 117,963,084\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 103.15460\nPolicy Entropy: 5.38632\nValue Function Loss: 0.07139\n\nMean KL Divergence: 0.00070\nSB3 Clip Fraction: 0.02636\nPolicy Update Magnitude: 0.20519\nValue Function Update Magnitude: 0.09934\n\nCollected Steps per Second: 1,792.97322\nOverall Steps per Second: 1,277.97233\n\nTimestep Collection Time: 22.31043\nTimestep Consumption Time: 8.99072\nPPO Batch Consumption Time: 0.97006\nTotal Iteration Time: 31.30115\n\nCumulative Model Updates: 23,571\nCumulative Timesteps: 118,003,086\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 95.58089\nPolicy Entropy: 5.36854\nValue Function Loss: 0.06957\n\nMean KL Divergence: 0.00082\nSB3 Clip Fraction: 0.03356\nPolicy Update Magnitude: 0.20731\nValue Function Update Magnitude: 0.10007\n\nCollected Steps per Second: 1,691.57497\nOverall Steps per Second: 1,223.64746\n\nTimestep Collection Time: 23.64778\nTimestep Consumption Time: 9.04300\nPPO Batch Consumption Time: 0.96612\nTotal Iteration Time: 32.69079\n\nCumulative Model Updates: 23,579\nCumulative Timesteps: 118,043,088\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 118043088...\nCheckpoint 118043088 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 84.75016\nPolicy Entropy: 5.36578\nValue Function Loss: 0.06990\n\nMean KL Divergence: 0.00079\nSB3 Clip Fraction: 0.03072\nPolicy Update Magnitude: 0.20687\nValue Function Update Magnitude: 0.09654\n\nCollected Steps per Second: 1,702.08664\nOverall Steps per Second: 1,226.98954\n\nTimestep Collection Time: 23.50174\nTimestep Consumption Time: 9.10000\nPPO Batch Consumption Time: 0.97668\nTotal Iteration Time: 32.60174\n\nCumulative Model Updates: 23,587\nCumulative Timesteps: 118,083,090\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 120.62975\nPolicy Entropy: 5.35461\nValue Function Loss: 0.07012\n\nMean KL Divergence: 0.00091\nSB3 Clip Fraction: 0.03519\nPolicy Update Magnitude: 0.21147\nValue Function Update Magnitude: 0.10320\n\nCollected Steps per Second: 1,740.67020\nOverall Steps per Second: 1,249.94227\n\nTimestep Collection Time: 22.97965\nTimestep Consumption Time: 9.02182\nPPO Batch Consumption Time: 0.97465\nTotal Iteration Time: 32.00148\n\nCumulative Model Updates: 23,595\nCumulative Timesteps: 118,123,090\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 94.54130\nPolicy Entropy: 5.34785\nValue Function Loss: 0.06977\n\nMean KL Divergence: 0.00100\nSB3 Clip Fraction: 0.04121\nPolicy Update Magnitude: 0.20372\nValue Function Update Magnitude: 0.08873\n\nCollected Steps per Second: 1,773.02934\nOverall Steps per Second: 1,269.32763\n\nTimestep Collection Time: 22.56026\nTimestep Consumption Time: 8.95249\nPPO Batch Consumption Time: 0.96303\nTotal Iteration Time: 31.51275\n\nCumulative Model Updates: 23,603\nCumulative Timesteps: 118,163,090\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 110.12734\nPolicy Entropy: 5.35384\nValue Function Loss: 0.06846\n\nMean KL Divergence: 0.00080\nSB3 Clip Fraction: 0.02850\nPolicy Update Magnitude: 0.20646\nValue Function Update Magnitude: 0.09045\n\nCollected Steps per Second: 1,770.22670\nOverall Steps per Second: 1,265.11508\n\nTimestep Collection Time: 22.59598\nTimestep Consumption Time: 9.02170\nPPO Batch Consumption Time: 0.97507\nTotal Iteration Time: 31.61768\n\nCumulative Model Updates: 23,611\nCumulative Timesteps: 118,203,090\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 98.02771\nPolicy Entropy: 5.36762\nValue Function Loss: 0.06653\n\nMean KL Divergence: 0.00087\nSB3 Clip Fraction: 0.02803\nPolicy Update Magnitude: 0.21237\nValue Function Update Magnitude: 0.09694\n\nCollected Steps per Second: 1,781.45906\nOverall Steps per Second: 1,269.26770\n\nTimestep Collection Time: 22.45463\nTimestep Consumption Time: 9.06118\nPPO Batch Consumption Time: 0.97416\nTotal Iteration Time: 31.51581\n\nCumulative Model Updates: 23,619\nCumulative Timesteps: 118,243,092\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 94.80914\nPolicy Entropy: 5.37412\nValue Function Loss: 0.06794\n\nMean KL Divergence: 0.00076\nSB3 Clip Fraction: 0.02834\nPolicy Update Magnitude: 0.20736\nValue Function Update Magnitude: 0.10733\n\nCollected Steps per Second: 1,714.97434\nOverall Steps per Second: 1,227.57154\n\nTimestep Collection Time: 23.32396\nTimestep Consumption Time: 9.26069\nPPO Batch Consumption Time: 1.00126\nTotal Iteration Time: 32.58466\n\nCumulative Model Updates: 23,627\nCumulative Timesteps: 118,283,092\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 102.89632\nPolicy Entropy: 5.35235\nValue Function Loss: 0.06748\n\nMean KL Divergence: 0.00085\nSB3 Clip Fraction: 0.03398\nPolicy Update Magnitude: 0.20089\nValue Function Update Magnitude: 0.10237\n\nCollected Steps per Second: 1,776.28815\nOverall Steps per Second: 1,270.36889\n\nTimestep Collection Time: 22.51999\nTimestep Consumption Time: 8.96850\nPPO Batch Consumption Time: 0.96553\nTotal Iteration Time: 31.48849\n\nCumulative Model Updates: 23,635\nCumulative Timesteps: 118,323,094\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 128.50908\nPolicy Entropy: 5.34367\nValue Function Loss: 0.06830\n\nMean KL Divergence: 0.00079\nSB3 Clip Fraction: 0.03013\nPolicy Update Magnitude: 0.18891\nValue Function Update Magnitude: 0.08723\n\nCollected Steps per Second: 1,790.20726\nOverall Steps per Second: 1,272.90300\n\nTimestep Collection Time: 22.34378\nTimestep Consumption Time: 9.08045\nPPO Batch Consumption Time: 0.97850\nTotal Iteration Time: 31.42423\n\nCumulative Model Updates: 23,643\nCumulative Timesteps: 118,363,094\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 117.16104\nPolicy Entropy: 5.37351\nValue Function Loss: 0.06986\n\nMean KL Divergence: 0.00079\nSB3 Clip Fraction: 0.03028\nPolicy Update Magnitude: 0.19331\nValue Function Update Magnitude: 0.09754\n\nCollected Steps per Second: 1,746.18663\nOverall Steps per Second: 1,258.13413\n\nTimestep Collection Time: 22.90706\nTimestep Consumption Time: 8.88605\nPPO Batch Consumption Time: 0.96600\nTotal Iteration Time: 31.79311\n\nCumulative Model Updates: 23,651\nCumulative Timesteps: 118,403,094\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 72.05988\nPolicy Entropy: 5.36936\nValue Function Loss: 0.06956\n\nMean KL Divergence: 0.00082\nSB3 Clip Fraction: 0.03013\nPolicy Update Magnitude: 0.21411\nValue Function Update Magnitude: 0.10166\n\nCollected Steps per Second: 1,721.99057\nOverall Steps per Second: 1,227.56842\n\nTimestep Collection Time: 23.22893\nTimestep Consumption Time: 9.35581\nPPO Batch Consumption Time: 0.99979\nTotal Iteration Time: 32.58474\n\nCumulative Model Updates: 23,659\nCumulative Timesteps: 118,443,094\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 87.28381\nPolicy Entropy: 5.35418\nValue Function Loss: 0.07004\n\nMean KL Divergence: 0.00091\nSB3 Clip Fraction: 0.02710\nPolicy Update Magnitude: 0.21614\nValue Function Update Magnitude: 0.10527\n\nCollected Steps per Second: 1,695.61521\nOverall Steps per Second: 1,221.66222\n\nTimestep Collection Time: 23.59026\nTimestep Consumption Time: 9.15202\nPPO Batch Consumption Time: 0.98714\nTotal Iteration Time: 32.74227\n\nCumulative Model Updates: 23,667\nCumulative Timesteps: 118,483,094\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 103.28888\nPolicy Entropy: 5.35069\nValue Function Loss: 0.07014\n\nMean KL Divergence: 0.00064\nSB3 Clip Fraction: 0.02270\nPolicy Update Magnitude: 0.21133\nValue Function Update Magnitude: 0.09872\n\nCollected Steps per Second: 1,756.76963\nOverall Steps per Second: 1,253.75553\n\nTimestep Collection Time: 22.77020\nTimestep Consumption Time: 9.13554\nPPO Batch Consumption Time: 0.98063\nTotal Iteration Time: 31.90574\n\nCumulative Model Updates: 23,675\nCumulative Timesteps: 118,523,096\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 109.57211\nPolicy Entropy: 5.35762\nValue Function Loss: 0.06901\n\nMean KL Divergence: 0.00076\nSB3 Clip Fraction: 0.02769\nPolicy Update Magnitude: 0.20353\nValue Function Update Magnitude: 0.09969\n\nCollected Steps per Second: 1,741.94108\nOverall Steps per Second: 1,254.09908\n\nTimestep Collection Time: 22.96404\nTimestep Consumption Time: 8.93296\nPPO Batch Consumption Time: 0.96414\nTotal Iteration Time: 31.89700\n\nCumulative Model Updates: 23,683\nCumulative Timesteps: 118,563,098\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 118563098...\nCheckpoint 118563098 saved!\n\n\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 101.27084\nPolicy Entropy: 5.37156\nValue Function Loss: 0.06884\n\nMean KL Divergence: 0.00073\nSB3 Clip Fraction: 0.02764\nPolicy Update Magnitude: 0.20259\nValue Function Update Magnitude: 0.09894\n\nCollected Steps per Second: 1,764.30199\nOverall Steps per Second: 1,262.73297\n\nTimestep Collection Time: 22.67186\nTimestep Consumption Time: 9.00547\nPPO Batch Consumption Time: 0.97453\nTotal Iteration Time: 31.67732\n\nCumulative Model Updates: 23,691\nCumulative Timesteps: 118,603,098\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 109.43042\nPolicy Entropy: 5.37237\nValue Function Loss: 0.07181\n\nMean KL Divergence: 0.00087\nSB3 Clip Fraction: 0.03366\nPolicy Update Magnitude: 0.20578\nValue Function Update Magnitude: 0.09393\n\nCollected Steps per Second: 1,662.04182\nOverall Steps per Second: 1,172.89500\n\nTimestep Collection Time: 24.06799\nTimestep Consumption Time: 10.03737\nPPO Batch Consumption Time: 1.09169\nTotal Iteration Time: 34.10535\n\nCumulative Model Updates: 23,699\nCumulative Timesteps: 118,643,100\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 89.77841\nPolicy Entropy: 5.36173\nValue Function Loss: 0.07304\n\nMean KL Divergence: 0.00084\nSB3 Clip Fraction: 0.03248\nPolicy Update Magnitude: 0.21272\nValue Function Update Magnitude: 0.09944\n\nCollected Steps per Second: 1,702.89641\nOverall Steps per Second: 1,225.92599\n\nTimestep Collection Time: 23.49057\nTimestep Consumption Time: 9.13946\nPPO Batch Consumption Time: 0.97860\nTotal Iteration Time: 32.63003\n\nCumulative Model Updates: 23,707\nCumulative Timesteps: 118,683,102\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 130.61873\nPolicy Entropy: 5.34782\nValue Function Loss: 0.07118\n\nMean KL Divergence: 0.00089\nSB3 Clip Fraction: 0.03469\nPolicy Update Magnitude: 0.20742\nValue Function Update Magnitude: 0.09620\n\nCollected Steps per Second: 1,735.64658\nOverall Steps per Second: 1,238.64193\n\nTimestep Collection Time: 23.04732\nTimestep Consumption Time: 9.24773\nPPO Batch Consumption Time: 0.99150\nTotal Iteration Time: 32.29505\n\nCumulative Model Updates: 23,715\nCumulative Timesteps: 118,723,104\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 104.26858\nPolicy Entropy: 5.34066\nValue Function Loss: 0.06981\n\nMean KL Divergence: 0.00089\nSB3 Clip Fraction: 0.03537\nPolicy Update Magnitude: 0.20118\nValue Function Update Magnitude: 0.09696\n\nCollected Steps per Second: 1,752.76591\nOverall Steps per Second: 1,256.95681\n\nTimestep Collection Time: 22.82107\nTimestep Consumption Time: 9.00182\nPPO Batch Consumption Time: 0.96703\nTotal Iteration Time: 31.82289\n\nCumulative Model Updates: 23,723\nCumulative Timesteps: 118,763,104\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 78.70707\nPolicy Entropy: 5.32351\nValue Function Loss: 0.06992\n\nMean KL Divergence: 0.00079\nSB3 Clip Fraction: 0.03141\nPolicy Update Magnitude: 0.20308\nValue Function Update Magnitude: 0.09222\n\nCollected Steps per Second: 1,684.53731\nOverall Steps per Second: 1,215.22631\n\nTimestep Collection Time: 23.74658\nTimestep Consumption Time: 9.17075\nPPO Batch Consumption Time: 0.98847\nTotal Iteration Time: 32.91733\n\nCumulative Model Updates: 23,731\nCumulative Timesteps: 118,803,106\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 93.74726\nPolicy Entropy: 5.33847\nValue Function Loss: 0.06908\n\nMean KL Divergence: 0.00077\nSB3 Clip Fraction: 0.02855\nPolicy Update Magnitude: 0.20616\nValue Function Update Magnitude: 0.09731\n\nCollected Steps per Second: 1,638.52753\nOverall Steps per Second: 1,190.47233\n\nTimestep Collection Time: 24.41216\nTimestep Consumption Time: 9.18795\nPPO Batch Consumption Time: 0.99417\nTotal Iteration Time: 33.60011\n\nCumulative Model Updates: 23,739\nCumulative Timesteps: 118,843,106\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 94.44428\nPolicy Entropy: 5.34244\nValue Function Loss: 0.06787\n\nMean KL Divergence: 0.00091\nSB3 Clip Fraction: 0.03585\nPolicy Update Magnitude: 0.20769\nValue Function Update Magnitude: 0.09351\n\nCollected Steps per Second: 1,681.28498\nOverall Steps per Second: 1,220.10064\n\nTimestep Collection Time: 23.79252\nTimestep Consumption Time: 8.99330\nPPO Batch Consumption Time: 0.97132\nTotal Iteration Time: 32.78582\n\nCumulative Model Updates: 23,747\nCumulative Timesteps: 118,883,108\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 119.30938\nPolicy Entropy: 5.38222\nValue Function Loss: 0.06665\n\nMean KL Divergence: 0.00106\nSB3 Clip Fraction: 0.04612\nPolicy Update Magnitude: 0.21102\nValue Function Update Magnitude: 0.10092\n\nCollected Steps per Second: 1,666.86432\nOverall Steps per Second: 1,208.86652\n\nTimestep Collection Time: 23.99715\nTimestep Consumption Time: 9.09169\nPPO Batch Consumption Time: 0.98587\nTotal Iteration Time: 33.08885\n\nCumulative Model Updates: 23,755\nCumulative Timesteps: 118,923,108\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 122.61701\nPolicy Entropy: 5.35391\nValue Function Loss: 0.06819\n\nMean KL Divergence: 0.00103\nSB3 Clip Fraction: 0.04200\nPolicy Update Magnitude: 0.21731\nValue Function Update Magnitude: 0.10378\n\nCollected Steps per Second: 1,698.60969\nOverall Steps per Second: 1,220.98223\n\nTimestep Collection Time: 23.54867\nTimestep Consumption Time: 9.21184\nPPO Batch Consumption Time: 0.99301\nTotal Iteration Time: 32.76051\n\nCumulative Model Updates: 23,763\nCumulative Timesteps: 118,963,108\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 124.73927\nPolicy Entropy: 5.32573\nValue Function Loss: 0.06828\n\nMean KL Divergence: 0.00084\nSB3 Clip Fraction: 0.03349\nPolicy Update Magnitude: 0.21181\nValue Function Update Magnitude: 0.09743\n\nCollected Steps per Second: 1,657.97866\nOverall Steps per Second: 1,215.50999\n\nTimestep Collection Time: 24.12576\nTimestep Consumption Time: 8.78223\nPPO Batch Consumption Time: 0.97817\nTotal Iteration Time: 32.90800\n\nCumulative Model Updates: 23,771\nCumulative Timesteps: 119,003,108\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)--------BEGIN ITERATION REPORT--------\nPolicy Reward: 110.77404\nPolicy Entropy: 5.36366\nValue Function Loss: 0.06876\n\nMean KL Divergence: 0.00082\nSB3 Clip Fraction: 0.03096\nPolicy Update Magnitude: 0.21925\nValue Function Update Magnitude: 0.09605\n\nCollected Steps per Second: 1,661.15870\nOverall Steps per Second: 1,212.19227\n\nTimestep Collection Time: 24.07958\nTimestep Consumption Time: 8.91849\nPPO Batch Consumption Time: 0.99385\nTotal Iteration Time: 32.99807\n\nCumulative Model Updates: 23,779\nCumulative Timesteps: 119,043,108\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: 50_50s.npy (20 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.--------BEGIN ITERATION REPORT--------\nPolicy Reward: 95.16157\nPolicy Entropy: 5.38135\nValue Function Loss: 0.06960\n\nMean KL Divergence: 0.00082\nSB3 Clip Fraction: 0.03244\nPolicy Update Magnitude: 0.21244\nValue Function Update Magnitude: 0.09905\n\nCollected Steps per Second: 1,654.88952\nOverall Steps per Second: 1,204.69355\n\nTimestep Collection Time: 24.17080\nTimestep Consumption Time: 9.03267\nPPO Batch Consumption Time: 1.01267\nTotal Iteration Time: 33.20346\n\nCumulative Model Updates: 23,787\nCumulative Timesteps: 119,083,108\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\nSaving checkpoint 119083108...\nCheckpoint 119083108 saved!\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 109.95546\nPolicy Entropy: 5.37696\nValue Function Loss: 0.06757\n\nMean KL Divergence: 0.00089\nSB3 Clip Fraction: 0.03619\nPolicy Update Magnitude: 0.20076\nValue Function Update Magnitude: 0.10068\n\nCollected Steps per Second: 1,691.11411\nOverall Steps per Second: 1,232.11039\n\nTimestep Collection Time: 23.65423\nTimestep Consumption Time: 8.81202\nPPO Batch Consumption Time: 0.98309\nTotal Iteration Time: 32.46625\n\nCumulative Model Updates: 23,795\nCumulative Timesteps: 119,123,110\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 91.61704\nPolicy Entropy: 5.36079\nValue Function Loss: 0.07234\n\nMean KL Divergence: 0.00075\nSB3 Clip Fraction: 0.02762\nPolicy Update Magnitude: 0.19960\nValue Function Update Magnitude: 0.09883\n\nCollected Steps per Second: 1,644.41774\nOverall Steps per Second: 1,205.79500\n\nTimestep Collection Time: 24.32472\nTimestep Consumption Time: 8.84842\nPPO Batch Consumption Time: 0.98430\nTotal Iteration Time: 33.17313\n\nCumulative Model Updates: 23,803\nCumulative Timesteps: 119,163,110\n\nTimesteps Collected: 40,000\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 113.59732\nPolicy Entropy: 5.34160\nValue Function Loss: 0.07477\n\nMean KL Divergence: 0.00078\nSB3 Clip Fraction: 0.02868\nPolicy Update Magnitude: 0.20491\nValue Function Update Magnitude: 0.10330\n\nCollected Steps per Second: 1,657.32039\nOverall Steps per Second: 1,209.08234\n\nTimestep Collection Time: 24.13655\nTimestep Consumption Time: 8.94804\nPPO Batch Consumption Time: 1.00167\nTotal Iteration Time: 33.08460\n\nCumulative Model Updates: 23,811\nCumulative Timesteps: 119,203,112\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n--------BEGIN ITERATION REPORT--------\nPolicy Reward: 67.04480\nPolicy Entropy: 5.33519\nValue Function Loss: 0.07005\n\nMean KL Divergence: 0.00075\nSB3 Clip Fraction: 0.02883\nPolicy Update Magnitude: 0.20950\nValue Function Update Magnitude: 0.10212\n\nCollected Steps per Second: 1,597.74912\nOverall Steps per Second: 1,182.37275\n\nTimestep Collection Time: 25.03647\nTimestep Consumption Time: 8.79550\nPPO Batch Consumption Time: 0.98468\nTotal Iteration Time: 33.83197\n\nCumulative Model Updates: 23,819\nCumulative Timesteps: 119,243,114\n\nTimesteps Collected: 40,002\n--------END ITERATION REPORT--------\n\n\n\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: dribbling.npy (58 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: wall_plays.npy (337 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: no_boost.npy (1423 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: boost_starved_defense.npy (750 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: aerials.npy (852 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: ball_in_air.npy (1711 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: open_nets.npy (3787 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: defense.npy (2252 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: challenging.npy (1889 states)\n[ReplayStateSetter] Chosen state index set in environment.\n[ReplayStateSetter] Sampling from file: saves.npy (1050 states)\n[ReplayStateSetter] Chosen state index set in environment.\n","output_type":"stream"},{"name":"stderr","text":"Process ForkServerProcess-75:\nProcess ForkServerProcess-74:\nTraceback (most recent call last):\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/kaggle/working/rlgym-ppo/rlgym_ppo/batched_agents/batched_agent.py\", line 101, in batched_agent_process\n    message_bytes = pipe.recv(4096)\n                    ^^^^^^^^^^^^^^^\nKeyboardInterrupt\nProcess ForkServerProcess-73:\nTraceback (most recent call last):\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/kaggle/working/rlgym-ppo/rlgym_ppo/batched_agents/batched_agent.py\", line 101, in batched_agent_process\n    message_bytes = pipe.recv(4096)\n                    ^^^^^^^^^^^^^^^\nKeyboardInterrupt\nTraceback (most recent call last):\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/kaggle/working/rlgym-ppo/rlgym_ppo/batched_agents/batched_agent.py\", line 101, in batched_agent_process\n    message_bytes = pipe.recv(4096)\n                    ^^^^^^^^^^^^^^^\nKeyboardInterrupt\nProcess ForkServerProcess-76:\nTraceback (most recent call last):\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/kaggle/working/rlgym-ppo/rlgym_ppo/batched_agents/batched_agent.py\", line 131, in batched_agent_process\n    obs = np.asarray(env.reset(), dtype=np.float32)\n                     ^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/rlgym_sim/gym.py\", line 41, in reset\n    state_str = self._match.get_reset_state()\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/rlgym_sim/envs/match.py\", line 126, in get_reset_state\n    self._state_setter.reset(new_state)\n  File \"/kaggle/working/rlgym-ppo/agent_env.py\", line 391, in reset\n    states_array = np.load(chosen_path, allow_pickle=True)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/numpy/lib/npyio.py\", line 456, in load\n    return format.read_array(fid, allow_pickle=allow_pickle,\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/numpy/lib/format.py\", line 800, in read_array\n    array = pickle.load(fp, **pickle_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nKeyboardInterrupt\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1772425220.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Using {HPARAMS['n_proc']} CPUs.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/1772425220.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;31m# (Rest of methods are direct copies from provided learner.py)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_learn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\nLEARNING LOOP ENCOUNTERED AN ERROR\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_timesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/1772425220.py\u001b[0m in \u001b[0;36m_learn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mepoch_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mexperience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollected_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_collected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollection_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_timesteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mts_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_logger\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollected_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwandb_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_timesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_new_experience\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperience\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/rlgym-ppo/rlgym_ppo/batched_agents/batched_agent_manager.py\u001b[0m in \u001b[0;36mcollect_timesteps\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;31m# to be lying around in the buffer will be collected and used in the next inference step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             (\n\u001b[1;32m    112\u001b[0m                 \u001b[0mcollected_metrics_this_pass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/rlgym-ppo/rlgym_ppo/batched_agents/batched_agent_manager.py\u001b[0m in \u001b[0;36m_send_actions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0minference_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minference_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/rlgym-ppo/rlgym_ppo/ppo/discrete_policy.py\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(self, obs, deterministic)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \"\"\"\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/rlgym-ppo/rlgym_ppo/ppo/discrete_policy.py\u001b[0m in \u001b[0;36mget_output\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mbound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":59},{"cell_type":"code","source":"import os\nimport shutil\n\n# Define source and destination\nsrc = \"/kaggle/working/models/coyote_long_run/-1758662684247525730/118563098/PPO_POLICY_OPTIMIZER.pt\"\ndst_dir = \"/kaggle/output\"\ndst = os.path.join(dst_dir, \"PPO_POLICY_OPTIMIZER.pt\")\n\n# Make sure output directory exists\nos.makedirs(dst_dir, exist_ok=True)\n\n# Copy file\nshutil.copy2(src, dst)\n\nprint(f\"Copied {src} -> {dst}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T04:07:04.910198Z","iopub.execute_input":"2025-09-24T04:07:04.910618Z","iopub.status.idle":"2025-09-24T04:07:04.939492Z","shell.execute_reply.started":"2025-09-24T04:07:04.910592Z","shell.execute_reply":"2025-09-24T04:07:04.938309Z"}},"outputs":[{"name":"stdout","text":"Copied /kaggle/working/models/coyote_long_run/-1758662684247525730/118563098/PPO_POLICY_OPTIMIZER.pt -> /kaggle/output/PPO_POLICY_OPTIMIZER.pt\n","output_type":"stream"}],"execution_count":60}]}